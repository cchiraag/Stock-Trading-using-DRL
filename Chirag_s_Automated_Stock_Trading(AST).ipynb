{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "name": "Chirag's Automated-Stock-Trading(AST).ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XLPb5OhMsIV1"
      },
      "source": [
        "# Reinforcement Learning Project\n",
        "\n",
        "## Automated Stock Trading using Deep Reinforcement Learning\n",
        "#### In this project we implement an Ensemble Strategy using Reinforcement Learning to trade stocks through Open AI Gym environment with an end goal of maximizing total returns.\n",
        "#### Reference Hongyang Yang, Xiao-Yang Liu, Shan Zhong, and Anwar Walid. 2020. Deep Reinforcement Learning for Automated Stock Trading: An Ensemble Strategy. In ICAIF ’20: ACM International Conference on AI in Finance, Oct. 15–16, 2020, Manhattan, NY. ACM, New York, NY, USA."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A5wqqrUEsYe1"
      },
      "source": [
        "## Mount GDrive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mgg2OMQnT8Fp",
        "outputId": "3a105656-a064-4483-daa9-c1280f82994b"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=True)\n",
        "root_dir = \"/content/gdrive/My Drive/AST\""
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sqSxZq5Usbpw"
      },
      "source": [
        "## Install required libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_5Dxloq409GQ",
        "outputId": "d93f547c-c266-42f9-bc0f-f43e49d636a0"
      },
      "source": [
        "!pip install stockstats"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting stockstats\n",
            "  Downloading https://files.pythonhosted.org/packages/32/41/d3828c5bc0a262cb3112a4024108a3b019c183fa3b3078bff34bf25abf91/stockstats-0.3.2-py2.py3-none-any.whl\n",
            "Collecting int-date>=0.1.7\n",
            "  Downloading https://files.pythonhosted.org/packages/43/27/31803df15173ab341fe7548c14154b54227dfd8f630daa09a1c6e7db52f7/int_date-0.1.8-py2.py3-none-any.whl\n",
            "Requirement already satisfied: pandas>=0.18.1 in /usr/local/lib/python3.7/dist-packages (from stockstats) (1.1.5)\n",
            "Requirement already satisfied: numpy>=1.9.2 in /usr/local/lib/python3.7/dist-packages (from stockstats) (1.19.5)\n",
            "Requirement already satisfied: python-dateutil>=2.4.2 in /usr/local/lib/python3.7/dist-packages (from int-date>=0.1.7->stockstats) (2.8.1)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from int-date>=0.1.7->stockstats) (1.15.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.18.1->stockstats) (2018.9)\n",
            "Installing collected packages: int-date, stockstats\n",
            "Successfully installed int-date-0.1.8 stockstats-0.3.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VhihNn731FAi",
        "outputId": "27f08871-1899-4400-e84e-ff9d248f3e40"
      },
      "source": [
        "!pip install yfinance"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting yfinance\n",
            "  Downloading https://files.pythonhosted.org/packages/a7/ee/315752b9ef281ba83c62aa7ec2e2074f85223da6e7e74efb4d3e11c0f510/yfinance-0.1.59.tar.gz\n",
            "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.7/dist-packages (from yfinance) (1.1.5)\n",
            "Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.7/dist-packages (from yfinance) (1.19.5)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.7/dist-packages (from yfinance) (2.23.0)\n",
            "Requirement already satisfied: multitasking>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from yfinance) (0.0.9)\n",
            "Collecting lxml>=4.5.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/30/c0/d0526314971fc661b083ab135747dc68446a3022686da8c16d25fcf6ef07/lxml-4.6.3-cp37-cp37m-manylinux2014_x86_64.whl (6.3MB)\n",
            "\u001b[K     |████████████████████████████████| 6.3MB 8.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24->yfinance) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24->yfinance) (2018.9)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20->yfinance) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20->yfinance) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20->yfinance) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20->yfinance) (3.0.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=0.24->yfinance) (1.15.0)\n",
            "Building wheels for collected packages: yfinance\n",
            "  Building wheel for yfinance (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for yfinance: filename=yfinance-0.1.59-py2.py3-none-any.whl size=23442 sha256=f139c8aac9571a8abf738e9c99e066947be0183d0a0c4f5cb496b80fee45b56c\n",
            "  Stored in directory: /root/.cache/pip/wheels/f8/2a/0f/4b5a86e1d52e451757eb6bc17fd899629f0925c777741b6d04\n",
            "Successfully built yfinance\n",
            "Installing collected packages: lxml, yfinance\n",
            "  Found existing installation: lxml 4.2.6\n",
            "    Uninstalling lxml-4.2.6:\n",
            "      Successfully uninstalled lxml-4.2.6\n",
            "Successfully installed lxml-4.6.3 yfinance-0.1.59\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZWh9GwHQ1JCu",
        "outputId": "72c4351b-93bf-4390-faaf-ede0ec5c8bb9"
      },
      "source": [
        "!pip install git+https://github.com/quantopian/pyfolio"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/quantopian/pyfolio\n",
            "  Cloning https://github.com/quantopian/pyfolio to /tmp/pip-req-build-w59ld050\n",
            "  Running command git clone -q https://github.com/quantopian/pyfolio /tmp/pip-req-build-w59ld050\n",
            "Requirement already satisfied: ipython>=3.2.3 in /usr/local/lib/python3.7/dist-packages (from pyfolio==0.9.2+75.g4b901f6) (5.5.0)\n",
            "Requirement already satisfied: matplotlib>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from pyfolio==0.9.2+75.g4b901f6) (3.2.2)\n",
            "Requirement already satisfied: numpy>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from pyfolio==0.9.2+75.g4b901f6) (1.19.5)\n",
            "Requirement already satisfied: pandas>=0.18.1 in /usr/local/lib/python3.7/dist-packages (from pyfolio==0.9.2+75.g4b901f6) (1.1.5)\n",
            "Requirement already satisfied: pytz>=2014.10 in /usr/local/lib/python3.7/dist-packages (from pyfolio==0.9.2+75.g4b901f6) (2018.9)\n",
            "Requirement already satisfied: scipy>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from pyfolio==0.9.2+75.g4b901f6) (1.4.1)\n",
            "Requirement already satisfied: scikit-learn>=0.16.1 in /usr/local/lib/python3.7/dist-packages (from pyfolio==0.9.2+75.g4b901f6) (0.22.2.post1)\n",
            "Requirement already satisfied: seaborn>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from pyfolio==0.9.2+75.g4b901f6) (0.11.1)\n",
            "Collecting empyrical>=0.5.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/74/43/1b997c21411c6ab7c96dc034e160198272c7a785aeea7654c9bcf98bec83/empyrical-0.5.5.tar.gz (52kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 3.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from ipython>=3.2.3->pyfolio==0.9.2+75.g4b901f6) (1.0.18)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython>=3.2.3->pyfolio==0.9.2+75.g4b901f6) (2.6.1)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from ipython>=3.2.3->pyfolio==0.9.2+75.g4b901f6) (5.0.5)\n",
            "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.7/dist-packages (from ipython>=3.2.3->pyfolio==0.9.2+75.g4b901f6) (4.8.0)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython>=3.2.3->pyfolio==0.9.2+75.g4b901f6) (56.1.0)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython>=3.2.3->pyfolio==0.9.2+75.g4b901f6) (0.8.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython>=3.2.3->pyfolio==0.9.2+75.g4b901f6) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython>=3.2.3->pyfolio==0.9.2+75.g4b901f6) (0.7.5)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=1.4.0->pyfolio==0.9.2+75.g4b901f6) (2.8.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=1.4.0->pyfolio==0.9.2+75.g4b901f6) (1.3.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=1.4.0->pyfolio==0.9.2+75.g4b901f6) (2.4.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=1.4.0->pyfolio==0.9.2+75.g4b901f6) (0.10.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.16.1->pyfolio==0.9.2+75.g4b901f6) (1.0.1)\n",
            "Requirement already satisfied: pandas-datareader>=0.2 in /usr/local/lib/python3.7/dist-packages (from empyrical>=0.5.0->pyfolio==0.9.2+75.g4b901f6) (0.9.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython>=3.2.3->pyfolio==0.9.2+75.g4b901f6) (1.15.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython>=3.2.3->pyfolio==0.9.2+75.g4b901f6) (0.2.5)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.7/dist-packages (from traitlets>=4.2->ipython>=3.2.3->pyfolio==0.9.2+75.g4b901f6) (0.2.0)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect; sys_platform != \"win32\"->ipython>=3.2.3->pyfolio==0.9.2+75.g4b901f6) (0.7.0)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from pandas-datareader>=0.2->empyrical>=0.5.0->pyfolio==0.9.2+75.g4b901f6) (2.23.0)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (from pandas-datareader>=0.2->empyrical>=0.5.0->pyfolio==0.9.2+75.g4b901f6) (4.6.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pandas-datareader>=0.2->empyrical>=0.5.0->pyfolio==0.9.2+75.g4b901f6) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pandas-datareader>=0.2->empyrical>=0.5.0->pyfolio==0.9.2+75.g4b901f6) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pandas-datareader>=0.2->empyrical>=0.5.0->pyfolio==0.9.2+75.g4b901f6) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pandas-datareader>=0.2->empyrical>=0.5.0->pyfolio==0.9.2+75.g4b901f6) (3.0.4)\n",
            "Building wheels for collected packages: pyfolio, empyrical\n",
            "  Building wheel for pyfolio (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyfolio: filename=pyfolio-0.9.2+75.g4b901f6-cp37-none-any.whl size=75764 sha256=6c19b7f212cf9a9def3404a3842d02077fbf36b0955898f8201796e6e83b6d02\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-l5_z5y23/wheels/62/7d/a7/3e462442ba7d63c35414176627c886340521dc3dbc0893ce9f\n",
            "  Building wheel for empyrical (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for empyrical: filename=empyrical-0.5.5-cp37-none-any.whl size=39764 sha256=4d6eff1b2345bb2a950b254e763a64bf023f864cc3737ccda1dea624666d7c49\n",
            "  Stored in directory: /root/.cache/pip/wheels/ea/b2/c8/6769d8444d2f2e608fae2641833110668d0ffd1abeb2e9f3fc\n",
            "Successfully built pyfolio empyrical\n",
            "Installing collected packages: empyrical, pyfolio\n",
            "Successfully installed empyrical-0.5.5 pyfolio-0.9.2+75.g4b901f6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D-9VeWyb1aYj",
        "outputId": "b491f357-99b2-4402-87cf-31cc75185369"
      },
      "source": [
        "!pip install gym    "
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gym in /usr/local/lib/python3.7/dist-packages (0.17.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from gym) (1.4.1)\n",
            "Requirement already satisfied: cloudpickle<1.7.0,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from gym) (1.3.0)\n",
            "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from gym) (1.5.0)\n",
            "Requirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.7/dist-packages (from gym) (1.19.5)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pyglet<=1.5.0,>=1.4.0->gym) (0.16.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g32_IC-N1kBl",
        "outputId": "b0c07bad-a7b4-4aea-ebae-1c483b7a977d"
      },
      "source": [
        "!pip install stable-baselines[mpi]"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting stable-baselines[mpi]\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a2/c5/a60adb848f86219d19dd2d2bc4223b80e8d42802cc9e816955b6cfeffbdb/stable_baselines-2.10.2-py3-none-any.whl (240kB)\n",
            "\u001b[K     |████████████████████████████████| 245kB 6.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: cloudpickle>=0.5.5 in /usr/local/lib/python3.7/dist-packages (from stable-baselines[mpi]) (1.3.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from stable-baselines[mpi]) (1.0.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from stable-baselines[mpi]) (1.4.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from stable-baselines[mpi]) (1.19.5)\n",
            "Requirement already satisfied: gym[atari,classic_control]>=0.11 in /usr/local/lib/python3.7/dist-packages (from stable-baselines[mpi]) (0.17.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from stable-baselines[mpi]) (3.2.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from stable-baselines[mpi]) (1.1.5)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (from stable-baselines[mpi]) (4.1.2.30)\n",
            "Collecting mpi4py; extra == \"mpi\"\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ec/8f/bbd8de5ba566dd77e408d8136e2bab7fdf2b97ce06cab830ba8b50a2f588/mpi4py-3.0.3.tar.gz (1.4MB)\n",
            "\u001b[K     |████████████████████████████████| 1.4MB 9.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from gym[atari,classic_control]>=0.11->stable-baselines[mpi]) (1.5.0)\n",
            "Requirement already satisfied: atari-py~=0.2.0; extra == \"atari\" in /usr/local/lib/python3.7/dist-packages (from gym[atari,classic_control]>=0.11->stable-baselines[mpi]) (0.2.9)\n",
            "Requirement already satisfied: Pillow; extra == \"atari\" in /usr/local/lib/python3.7/dist-packages (from gym[atari,classic_control]>=0.11->stable-baselines[mpi]) (7.1.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->stable-baselines[mpi]) (0.10.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->stable-baselines[mpi]) (2.8.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->stable-baselines[mpi]) (1.3.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->stable-baselines[mpi]) (2.4.7)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->stable-baselines[mpi]) (2018.9)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pyglet<=1.5.0,>=1.4.0->gym[atari,classic_control]>=0.11->stable-baselines[mpi]) (0.16.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from atari-py~=0.2.0; extra == \"atari\"->gym[atari,classic_control]>=0.11->stable-baselines[mpi]) (1.15.0)\n",
            "Building wheels for collected packages: mpi4py\n",
            "  Building wheel for mpi4py (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mpi4py: filename=mpi4py-3.0.3-cp37-cp37m-linux_x86_64.whl size=2065196 sha256=ea038dde047b9f31d1cab9d262a7765e06293f420632fe735181aaf9c10d969f\n",
            "  Stored in directory: /root/.cache/pip/wheels/18/e0/86/2b713dd512199096012ceca61429e12b960888de59818871d6\n",
            "Successfully built mpi4py\n",
            "Installing collected packages: mpi4py, stable-baselines\n",
            "Successfully installed mpi4py-3.0.3 stable-baselines-2.10.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "pTRGB1OX1mrS",
        "outputId": "de38d56a-2850-49aa-dbdb-f6d9826d31ed"
      },
      "source": [
        "!pip install tensorflow==1.15.4"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow==1.15.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/04/9f/18e031f52c46b4c63f6a6f064cd2dd85a2f730ca5dc44ef2f25375990dce/tensorflow-1.15.4-cp37-cp37m-manylinux2010_x86_64.whl (110.5MB)\n",
            "\u001b[K     |████████████████████████████████| 110.5MB 103kB/s \n",
            "\u001b[?25hRequirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.4) (3.3.0)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.4) (0.36.2)\n",
            "Collecting keras-applications>=1.0.8\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 5.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.4) (0.2.0)\n",
            "Collecting tensorboard<1.16.0,>=1.15.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1e/e9/d3d747a97f7188f48aa5eda486907f3b345cd409f0a0850468ba867db246/tensorboard-1.15.0-py3-none-any.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8MB 28.7MB/s \n",
            "\u001b[?25hCollecting tensorflow-estimator==1.15.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/de/62/2ee9cd74c9fa2fa450877847ba560b260f5d0fb70ee0595203082dafcc9d/tensorflow_estimator-1.15.1-py2.py3-none-any.whl (503kB)\n",
            "\u001b[K     |████████████████████████████████| 512kB 29.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.4) (1.1.2)\n",
            "Collecting numpy<1.19.0,>=1.16.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d6/c6/58e517e8b1fb192725cfa23c01c2e60e4e6699314ee9684a1c5f5c9b27e1/numpy-1.18.5-cp37-cp37m-manylinux1_x86_64.whl (20.1MB)\n",
            "\u001b[K     |████████████████████████████████| 20.1MB 1.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.4) (0.8.1)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.4) (1.1.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.4) (1.15.0)\n",
            "Collecting gast==0.2.2\n",
            "  Downloading https://files.pythonhosted.org/packages/4e/35/11749bf99b2d4e3cceb4d55ca22590b0d7c2c62b9de38ac4a4a7f4687421/gast-0.2.2.tar.gz\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.4) (3.12.4)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.4) (1.12.1)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.4) (1.34.1)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.4) (0.12.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications>=1.0.8->tensorflow==1.15.4) (3.1.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.4) (56.1.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.4) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.4) (3.3.4)\n",
            "Requirement already satisfied: cached-property; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from h5py->keras-applications>=1.0.8->tensorflow==1.15.4) (1.5.2)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.4) (4.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.4) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.4) (3.4.1)\n",
            "Building wheels for collected packages: gast\n",
            "  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gast: filename=gast-0.2.2-cp37-none-any.whl size=7540 sha256=9ffd30cac5393996a0bd8463c2aaf4b27c1493dd32a6dd0dab2b467570c93659\n",
            "  Stored in directory: /root/.cache/pip/wheels/5c/2e/7e/a1d4d4fcebe6c381f378ce7743a3ced3699feb89bcfbdadadd\n",
            "Successfully built gast\n",
            "\u001b[31mERROR: tensorflow-probability 0.12.1 has requirement gast>=0.3.2, but you'll have gast 0.2.2 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: kapre 0.3.5 has requirement tensorflow>=2.0.0, but you'll have tensorflow 1.15.4 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Installing collected packages: numpy, keras-applications, tensorboard, tensorflow-estimator, gast, tensorflow\n",
            "  Found existing installation: numpy 1.19.5\n",
            "    Uninstalling numpy-1.19.5:\n",
            "      Successfully uninstalled numpy-1.19.5\n",
            "  Found existing installation: tensorboard 2.5.0\n",
            "    Uninstalling tensorboard-2.5.0:\n",
            "      Successfully uninstalled tensorboard-2.5.0\n",
            "  Found existing installation: tensorflow-estimator 2.5.0\n",
            "    Uninstalling tensorflow-estimator-2.5.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.5.0\n",
            "  Found existing installation: gast 0.4.0\n",
            "    Uninstalling gast-0.4.0:\n",
            "      Successfully uninstalled gast-0.4.0\n",
            "  Found existing installation: tensorflow 2.5.0\n",
            "    Uninstalling tensorflow-2.5.0:\n",
            "      Successfully uninstalled tensorflow-2.5.0\n",
            "Successfully installed gast-0.2.2 keras-applications-1.0.8 numpy-1.18.5 tensorboard-1.15.0 tensorflow-1.15.4 tensorflow-estimator-1.15.1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1CstwA99sfoQ"
      },
      "source": [
        "## Import required Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5WpB6I-vcuHx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "756a3bfc-0d83-49a0-e9c1-cf3a5800f65a"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from gym.utils import seeding\n",
        "import gym\n",
        "from gym import spaces\n",
        "\n",
        "import matplotlib\n",
        "matplotlib.use('Agg')\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import pickle\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "from stockstats import StockDataFrame as Sdf\n",
        "import yfinance as yf\n",
        "import pyfolio\n",
        "\n",
        "from stable_baselines import PPO2, DDPG, A2C, ACKTR, TD3, TRPO\n",
        "from stable_baselines import DDPG\n",
        "from stable_baselines import A2C\n",
        "from stable_baselines import SAC\n",
        "from stable_baselines.common.vec_env import DummyVecEnv\n",
        "from stable_baselines.common.policies import MlpPolicy\n",
        "from stable_baselines.common.noise import NormalActionNoise, OrnsteinUhlenbeckActionNoise, AdaptiveParamNoiseSpec"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N3v2pX2gskQL"
      },
      "source": [
        "## Data Files Path"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hi3yJ3AWT9d-"
      },
      "source": [
        "TRAINING_DATA_FILE = root_dir + '/data/dow_30_2009_2020.csv'\n",
        "TURBULENCE_DATA = root_dir + '/data/dow30_turbulence_index.csv'\n",
        "TRAINED_MODEL_DIR = root_dir + '/trained_models'"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IspIiTKesnM2"
      },
      "source": [
        "## List of Stocks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hv7nqVMWwgB7"
      },
      "source": [
        "dow_30_ticker = ['AAPL','MSFT','JPM','V','RTX','PG','GS','NKE','DIS','AXP',\n",
        "                  'HD','INTC','WMT','IBM','MRK','UNH','KO','CAT','TRV','JNJ',\n",
        "                  'CVX','MCD','VZ','CSCO','XOM','BA','MMM','PFE','WBA','DD']"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oG34UqUbsq8F"
      },
      "source": [
        "## Loading the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "847VqrEeYzgM"
      },
      "source": [
        "from datetime import datetime as dt"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qVKwXq0hwjW5"
      },
      "source": [
        "def load_dataset_dow30() -> pd.DataFrame:\n",
        "  dow_30 = pd.DataFrame()\n",
        "  for tic in dow_30_ticker:\n",
        "      data_df = yf.download(tic, start=\"2010-01-01\", end=\"2021-05-23\")\n",
        "      data_df['tic'] = tic\n",
        "      dow_30=dow_30.append(data_df)\n",
        "\n",
        "  dow_30=dow_30.reset_index()\n",
        "  print(dow_30.columns)\n",
        "  dow_30.rename(columns={\"Date\": \"datadate\", \"Open\": \"open\", \"High\": \"high\", \"Low\": \"low\", \"Close\": \"close\", \"Adj Close\": \"adjcp\", \"Volume\": \"volume\", \"tic\": \"tic\"}, inplace = True)\n",
        "  print(dow_30.columns)\n",
        "  dow_30.datadate = dow_30.datadate.dt.strftime(\"%Y%m%d\").astype(int)\n",
        "  #dow_30.columns = ['datadate','prcod','prchd','prcld','prccd','adjcp','cshtrd','tic']\n",
        "  #['Date', 'Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume', 'tic']\n",
        "  return dow_30"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LnNuvQnKclFN"
      },
      "source": [
        "def load_dataset(file_name: str) -> pd.DataFrame:\n",
        "    _data = pd.read_csv(file_name)\n",
        "    return _data"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h5wyV4iTstzo"
      },
      "source": [
        "## Data split based on dates"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QnCFrv2krVM2"
      },
      "source": [
        "def data_split(df,start,end):\n",
        "    data = df[(df.datadate >= start) & (df.datadate < end)]\n",
        "    data=data.sort_values(['datadate','tic'],ignore_index=True)\n",
        "    data.index = data.datadate.factorize()[0]\n",
        "    return data"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cR05OZdgs0kK"
      },
      "source": [
        "## Calculate values - datadate, tic, adjcp, open, high, low, volume"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ahzIq5CgrZsR"
      },
      "source": [
        "def calcualte_price(df):\n",
        "    data = df.copy()\n",
        "    data = data[['datadate', 'tic', 'prccd', 'ajexdi', 'prcod', 'prchd', 'prcld', 'cshtrd']]\n",
        "    data['ajexdi'] = data['ajexdi'].apply(lambda x: 1 if x == 0 else x)\n",
        "    data['adjcp'] = data['prccd'] / data['ajexdi']\n",
        "    data['open'] = data['prcod'] / data['ajexdi']\n",
        "    data['high'] = data['prchd'] / data['ajexdi']\n",
        "    data['low'] = data['prcld'] / data['ajexdi']\n",
        "    data['volume'] = data['cshtrd']\n",
        "    data = data[['datadate', 'tic', 'adjcp', 'open', 'high', 'low', 'volume']]\n",
        "    data = data.sort_values(['tic', 'datadate'], ignore_index=True)\n",
        "    return data"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Si7wRzrF9E3W"
      },
      "source": [
        "def calcualte_price_dow30(df):\n",
        "    data = df.copy()\n",
        "    data = data[['datadate', 'tic', 'adjcp', 'open', 'high', 'low', 'volume']]\n",
        "    data = data.sort_values(['tic', 'datadate'], ignore_index=True)\n",
        "    return data"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l8uVD9HLtBE1"
      },
      "source": [
        "## Including Technical indicators"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QuWH-eMXrhFS"
      },
      "source": [
        "def add_technical_indicator(df):\n",
        "    stock = Sdf.retype(df.copy())\n",
        "    stock['close'] = stock['adjcp']\n",
        "    unique_ticker = stock.tic.unique()\n",
        "    macd = pd.DataFrame()\n",
        "    rsi = pd.DataFrame()\n",
        "    cci = pd.DataFrame()\n",
        "    dx = pd.DataFrame()\n",
        "\n",
        "    for i in range(len(unique_ticker)):\n",
        "        ## macd\n",
        "        temp_macd = stock[stock.tic == unique_ticker[i]]['macd']\n",
        "        temp_macd = pd.DataFrame(temp_macd)\n",
        "        macd = macd.append(temp_macd, ignore_index=True)\n",
        "        ## rsi\n",
        "        temp_rsi = stock[stock.tic == unique_ticker[i]]['rsi_30']\n",
        "        temp_rsi = pd.DataFrame(temp_rsi)\n",
        "        rsi = rsi.append(temp_rsi, ignore_index=True)\n",
        "        ## cci\n",
        "        temp_cci = stock[stock.tic == unique_ticker[i]]['cci_30']\n",
        "        temp_cci = pd.DataFrame(temp_cci)\n",
        "        cci = cci.append(temp_cci, ignore_index=True)\n",
        "        ## adx\n",
        "        temp_dx = stock[stock.tic == unique_ticker[i]]['dx_30']\n",
        "        temp_dx = pd.DataFrame(temp_dx)\n",
        "        dx = dx.append(temp_dx, ignore_index=True)\n",
        "\n",
        "\n",
        "    df['macd'] = macd\n",
        "    df['rsi'] = rsi\n",
        "    df['cci'] = cci\n",
        "    df['adx'] = dx\n",
        "\n",
        "    return df"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yUBI9tNutFoh"
      },
      "source": [
        "## Preprocess data \n",
        "### Removing null values, filling values that are empty in technical indicators"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RkZJl0QdrqMc"
      },
      "source": [
        "def preprocess_data():\n",
        "    # df = load_dataset(TRAINING_DATA_FILE)\n",
        "    df = load_dataset_dow30()\n",
        "\n",
        "    print(df.head(2))\n",
        "\n",
        "    # Null checks\n",
        "    print(df.isnull().values.any())\n",
        "    df = df.dropna()\n",
        "    print(df.tic.value_counts())\n",
        "    print(df.isnull().values.any())\n",
        "    \n",
        "    # get data after 2009\n",
        "    # df = df[df.datadate>=20090000]\n",
        "    #df = df[df.datadate>=\"2009-01-01\"]\n",
        "    \n",
        "    # calcualte adjusted price\n",
        "    # df_preprocess = calcualte_price(df)\n",
        "    df_preprocess = calcualte_price_dow30(df)\n",
        "    # add technical indicators using stockstats\n",
        "\n",
        "    df_final=add_technical_indicator(df_preprocess)\n",
        "    print(df_final.isnull().values.any())\n",
        "    print(df_final.isna().any())\n",
        "    print(df_final.tail(3))\n",
        "    \n",
        "    # fill the missing values at the beginning\n",
        "    df_final.fillna(method='bfill',inplace=True)\n",
        "    print(df_final.tail(3))\n",
        "    \n",
        "    return df_final"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sUQ6atyxtVzl"
      },
      "source": [
        "## Calculation for adding turbulence index to data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9pv5cpVsrvY0"
      },
      "source": [
        "\n",
        "def add_turbulence(df):\n",
        "    turbulence_index = calcualte_turbulence(df)\n",
        "    df = df.merge(turbulence_index, on='datadate')\n",
        "    df = df.sort_values(['datadate','tic']).reset_index(drop=True)\n",
        "    return df"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "irqZB1Kjry_5"
      },
      "source": [
        "def calcualte_turbulence(df):\n",
        "    df_price_pivot=df.pivot(index='datadate', columns='tic', values='adjcp')\n",
        "    unique_date = df.datadate.unique()\n",
        "    # start after a year\n",
        "    start = 252\n",
        "    turbulence_index = [0]*start\n",
        "    #turbulence_index = [0]\n",
        "    count=0\n",
        "    for i in range(start,len(unique_date)):\n",
        "        current_price = df_price_pivot[df_price_pivot.index == unique_date[i]]\n",
        "        hist_price = df_price_pivot[[n in unique_date[0:i] for n in df_price_pivot.index ]]\n",
        "        cov_temp = hist_price.cov()\n",
        "        current_temp=(current_price - np.mean(hist_price,axis=0))\n",
        "        temp = current_temp.values.dot(np.linalg.inv(cov_temp)).dot(current_temp.values.T)\n",
        "        if temp>0:\n",
        "            count+=1\n",
        "            if count>2:\n",
        "                turbulence_temp = temp[0][0]\n",
        "            else:\n",
        "                #avoid large outlier because of the calculation just begins\n",
        "                turbulence_temp=0\n",
        "        else:\n",
        "            turbulence_temp=0\n",
        "        turbulence_index.append(turbulence_temp)\n",
        "    \n",
        "    \n",
        "    turbulence_index = pd.DataFrame({'datadate':df_price_pivot.index, 'turbulence':turbulence_index})\n",
        "    return turbulence_index"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QGy-7TGTirWI"
      },
      "source": [
        "import time"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tU76Vc5Gdp_X"
      },
      "source": [
        "# 100 shares per trade\n",
        "MAX_NORMALIZE = 100\n",
        "# initial amount of money we have in account\n",
        "INITIAL_ACC_BAL=1000000\n",
        "# total number of stocks in  portfolio\n",
        "TOTAL_STOCKS = 30\n",
        "# transaction fee: 1/1000 reasonable percentage\n",
        "TRANSACTION_FEE_PERCENT = 0.001\n",
        "REWARD_SCALING = 1e-4"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KxHWCaoZuNGW"
      },
      "source": [
        "## Gym Environments"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yo7DwGmleT-p"
      },
      "source": [
        "class StockTrainEnv(gym.Env):\n",
        "    \"\"\"A stock trading environment for OpenAI gym\"\"\"\n",
        "    metadata = {'render.modes': ['human']}\n",
        "\n",
        "    def __init__(self, df,day = 0):\n",
        "        #money = 10 , scope = 1\n",
        "        self.day = day\n",
        "        self.df = df\n",
        "\n",
        "        # action_space \n",
        "        self.action_space = spaces.Box(low = -1, high = 1,shape = (TOTAL_STOCKS,)) \n",
        "        \n",
        "        # Shape = 181: [Current Balance]+[prices 1-30]+[owned shares 1-30] \n",
        "        # +[macd 1-30]+ [rsi 1-30] + [cci 1-30] + [adx 1-30]\n",
        "        self.observation_space = spaces.Box(low=0, high=np.inf, shape = (181,))\n",
        "        \n",
        "        # load data from a pandas dataframe\n",
        "        self.data = self.df.loc[self.day,:]\n",
        "        self.terminal = False             \n",
        "        \n",
        "        # initalize state\n",
        "        self.state = [INITIAL_ACC_BAL] + \\\n",
        "                      self.data.adjcp.values.tolist() + \\\n",
        "                      [0]*TOTAL_STOCKS + \\\n",
        "                      self.data.macd.values.tolist() + \\\n",
        "                      self.data.rsi.values.tolist() + \\\n",
        "                      self.data.cci.values.tolist() + \\\n",
        "                      self.data.adx.values.tolist()\n",
        "        # initialize reward\n",
        "        self.reward = 0\n",
        "        self.cost = 0\n",
        "        # memorize all the total balance change\n",
        "        self.asset_memory = [INITIAL_ACC_BAL]\n",
        "        self.rewards_memory = []\n",
        "        self.trades = 0\n",
        "        #self.reset()\n",
        "        self._seed()\n",
        "\n",
        "\n",
        "    def _sell_stock(self, index, action):\n",
        "        # perform sell action based on the sign of the action\n",
        "        if self.state[index+TOTAL_STOCKS+1] > 0:\n",
        "            #update balance\n",
        "            self.state[0] += \\\n",
        "            self.state[index+1]*min(abs(action),self.state[index+TOTAL_STOCKS+1]) * \\\n",
        "             (1- TRANSACTION_FEE_PERCENT)\n",
        "\n",
        "            self.state[index+TOTAL_STOCKS+1] -= min(abs(action), self.state[index+TOTAL_STOCKS+1])\n",
        "            self.cost +=self.state[index+1]*min(abs(action),self.state[index+TOTAL_STOCKS+1]) * \\\n",
        "             TRANSACTION_FEE_PERCENT\n",
        "            self.trades+=1\n",
        "        else:\n",
        "            pass\n",
        "\n",
        "    \n",
        "    def _buy_stock(self, index, action):\n",
        "        # perform buy action based on the sign of the action\n",
        "        available_amount = self.state[0] // self.state[index+1]\n",
        "        # print('available_amount:{}'.format(available_amount))\n",
        "\n",
        "        #update balance\n",
        "        self.state[0] -= self.state[index+1]*min(available_amount, action)* \\\n",
        "                          (1+ TRANSACTION_FEE_PERCENT)\n",
        "\n",
        "        self.state[index+TOTAL_STOCKS+1] += min(available_amount, action)\n",
        "\n",
        "        self.cost+=self.state[index+1]*min(available_amount, action)* \\\n",
        "                          TRANSACTION_FEE_PERCENT\n",
        "        self.trades+=1\n",
        "        \n",
        "    def step(self, actions):\n",
        "        # print(self.day)\n",
        "        self.terminal = self.day >= len(self.df.index.unique())-1\n",
        "        # print(actions)\n",
        "\n",
        "        if self.terminal:\n",
        "            plt.plot(self.asset_memory,'r')\n",
        "            plt.savefig('account_value_train.png')\n",
        "            plt.close()\n",
        "            end_total_asset = self.state[0]+ \\\n",
        "            sum(np.array(self.state[1:(TOTAL_STOCKS+1)])*np.array(self.state[(TOTAL_STOCKS+1):(TOTAL_STOCKS*2+1)]))\n",
        "            \n",
        "            #print(\"end_total_asset:{}\".format(end_total_asset))\n",
        "            df_total_value = pd.DataFrame(self.asset_memory)\n",
        "            df_total_value.to_csv('account_value_train.csv')\n",
        "            #print(\"total_reward:{}\".format(self.state[0]+sum(np.array(self.state[1:(TOTAL_STOCKS+1)])*np.array(self.state[(TOTAL_STOCKS+1):61]))- INITIAL_ACCOUNT_BALANCE ))\n",
        "            #print(\"total_cost: \", self.cost)\n",
        "            #print(\"total_trades: \", self.trades)\n",
        "            df_total_value.columns = ['account_value']\n",
        "            df_total_value['daily_return']=df_total_value.pct_change(1)\n",
        "            sharpe = (252**0.5)*df_total_value['daily_return'].mean()/ \\\n",
        "                  df_total_value['daily_return'].std()\n",
        "            #print(\"Sharpe: \",sharpe)\n",
        "            #print(\"=================================\")\n",
        "            df_rewards = pd.DataFrame(self.rewards_memory)\n",
        "            df_rewards.to_csv('account_rewards_train.csv')\n",
        "            \n",
        "            # print('total asset: {}'.format(self.state[0]+ sum(np.array(self.state[1:29])*np.array(self.state[29:]))))\n",
        "            #with open('obs.pkl', 'wb') as f:  \n",
        "            #    pickle.dump(self.state, f)\n",
        "            \n",
        "            return self.state, self.reward, self.terminal,{}\n",
        "\n",
        "        else:\n",
        "            # print(np.array(self.state[1:29]))\n",
        "\n",
        "            actions = actions * MAX_NORMALIZE\n",
        "            #actions = (actions.astype(int))\n",
        "            \n",
        "            begin_total_asset = self.state[0]+ \\\n",
        "            sum(np.array(self.state[1:(TOTAL_STOCKS+1)])*np.array(self.state[(TOTAL_STOCKS+1):(TOTAL_STOCKS*2+1)]))\n",
        "            #print(\"begin_total_asset:{}\".format(begin_total_asset))\n",
        "            \n",
        "            argsort_actions = np.argsort(actions)\n",
        "            \n",
        "            sell_index = argsort_actions[:np.where(actions < 0)[0].shape[0]]\n",
        "            buy_index = argsort_actions[::-1][:np.where(actions > 0)[0].shape[0]]\n",
        "\n",
        "            for index in sell_index:\n",
        "                # print('take sell action'.format(actions[index]))\n",
        "                self._sell_stock(index, actions[index])\n",
        "\n",
        "            for index in buy_index:\n",
        "                # print('take buy action: {}'.format(actions[index]))\n",
        "                self._buy_stock(index, actions[index])\n",
        "\n",
        "            self.day += 1\n",
        "            self.data = self.df.loc[self.day,:]         \n",
        "            #load next state\n",
        "            # print(\"stock_shares:{}\".format(self.state[29:]))\n",
        "            self.state =  [self.state[0]] + \\\n",
        "                    self.data.adjcp.values.tolist() + \\\n",
        "                    list(self.state[(TOTAL_STOCKS+1):(TOTAL_STOCKS*2+1)]) + \\\n",
        "                    self.data.macd.values.tolist() + \\\n",
        "                    self.data.rsi.values.tolist() + \\\n",
        "                    self.data.cci.values.tolist() + \\\n",
        "                    self.data.adx.values.tolist()\n",
        "            \n",
        "            end_total_asset = self.state[0]+ \\\n",
        "            sum(np.array(self.state[1:(TOTAL_STOCKS+1)])*np.array(self.state[(TOTAL_STOCKS+1):(TOTAL_STOCKS*2+1)]))\n",
        "            self.asset_memory.append(end_total_asset)\n",
        "            #print(\"end_total_asset:{}\".format(end_total_asset))\n",
        "            \n",
        "            self.reward = end_total_asset - begin_total_asset            \n",
        "            # print(\"step_reward:{}\".format(self.reward))\n",
        "            self.rewards_memory.append(self.reward)\n",
        "            \n",
        "            self.reward = self.reward*REWARD_SCALING\n",
        "\n",
        "\n",
        "\n",
        "        return self.state, self.reward, self.terminal, {}\n",
        "\n",
        "    def reset(self):\n",
        "        self.asset_memory = [INITIAL_ACC_BAL]\n",
        "        self.day = 0\n",
        "        self.data = self.df.loc[self.day,:]\n",
        "        self.cost = 0\n",
        "        self.trades = 0\n",
        "        self.terminal = False \n",
        "        self.rewards_memory = []\n",
        "        #initiate state\n",
        "        self.state = [INITIAL_ACC_BAL] + \\\n",
        "                      self.data.adjcp.values.tolist() + \\\n",
        "                      [0]*TOTAL_STOCKS + \\\n",
        "                      self.data.macd.values.tolist() + \\\n",
        "                      self.data.rsi.values.tolist() + \\\n",
        "                      self.data.cci.values.tolist() + \\\n",
        "                      self.data.adx.values.tolist() \n",
        "        # iteration += 1 \n",
        "        return self.state\n",
        "    \n",
        "    def render(self, mode='human'):\n",
        "        return self.state\n",
        "\n",
        "    def _seed(self, seed=None):\n",
        "        self.np_random, seed = seeding.np_random(seed)\n",
        "        return [seed]"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Whz5WMXbeWED"
      },
      "source": [
        "class StockValidationEnv(gym.Env):\n",
        "    \"\"\"A stock trading environment for OpenAI gym\"\"\"\n",
        "    metadata = {'render.modes': ['human']}\n",
        "\n",
        "    def __init__(self, df, day = 0, turbulence_threshold=140, iteration=''):\n",
        "        \n",
        "        #money = 10 , scope = 1\n",
        "        self.day = day\n",
        "        self.df = df\n",
        "        \n",
        "        # action_space normalization and shape is TOTAL_STOCKS\n",
        "        self.action_space = spaces.Box(low = -1, high = 1,shape = (TOTAL_STOCKS,)) \n",
        "        \n",
        "        # Shape = 181: [Current Balance]+[prices 1-30]+[owned shares 1-30] \n",
        "        # +[macd 1-30]+ [rsi 1-30] + [cci 1-30] + [adx 1-30]\n",
        "        self.observation_space = spaces.Box(low=0, high=np.inf, shape = (181,))\n",
        "        # load data from a pandas dataframe\n",
        "        self.data = self.df.loc[self.day,:]\n",
        "        self.terminal = False     \n",
        "        self.turbulence_threshold = turbulence_threshold\n",
        "        \n",
        "        # initalize state\n",
        "        self.state = [INITIAL_ACC_BAL] + \\\n",
        "                      self.data.adjcp.values.tolist() + \\\n",
        "                      [0]*TOTAL_STOCKS + \\\n",
        "                      self.data.macd.values.tolist() + \\\n",
        "                      self.data.rsi.values.tolist() + \\\n",
        "                      self.data.cci.values.tolist() + \\\n",
        "                      self.data.adx.values.tolist()\n",
        "        # initialize reward\n",
        "        self.reward = 0\n",
        "        self.turbulence = 0\n",
        "        self.cost = 0\n",
        "        self.trades = 0\n",
        "        # memorize all the total balance change\n",
        "        self.asset_memory = [INITIAL_ACC_BAL]\n",
        "        self.rewards_memory = []\n",
        "        #self.reset()\n",
        "        self._seed()\n",
        "        \n",
        "        self.iteration=iteration\n",
        "\n",
        "\n",
        "    def _sell_stock(self, index, action):\n",
        "        # perform sell action based on the sign of the action\n",
        "        if self.turbulence<self.turbulence_threshold:\n",
        "            if self.state[index+TOTAL_STOCKS+1] > 0:\n",
        "                #update balance\n",
        "                self.state[0] += \\\n",
        "                self.state[index+1]*min(abs(action),self.state[index+TOTAL_STOCKS+1]) * \\\n",
        "                 (1- TRANSACTION_FEE_PERCENT)\n",
        "                \n",
        "                self.state[index+TOTAL_STOCKS+1] -= min(abs(action), self.state[index+TOTAL_STOCKS+1])\n",
        "                self.cost +=self.state[index+1]*min(abs(action),self.state[index+TOTAL_STOCKS+1]) * \\\n",
        "                 TRANSACTION_FEE_PERCENT\n",
        "                self.trades+=1\n",
        "            else:\n",
        "                pass\n",
        "        else:\n",
        "            # if turbulence goes over threshold, just clear out all positions \n",
        "            if self.state[index+TOTAL_STOCKS+1] > 0:\n",
        "                #update balance\n",
        "                self.state[0] += self.state[index+1]*self.state[index+TOTAL_STOCKS+1]* \\\n",
        "                              (1- TRANSACTION_FEE_PERCENT)\n",
        "                self.state[index+TOTAL_STOCKS+1] =0\n",
        "                self.cost += self.state[index+1]*self.state[index+TOTAL_STOCKS+1]* \\\n",
        "                              TRANSACTION_FEE_PERCENT\n",
        "                self.trades+=1\n",
        "            else:\n",
        "                pass\n",
        "    \n",
        "    def _buy_stock(self, index, action):\n",
        "        # perform buy action based on the sign of the action\n",
        "        if self.turbulence< self.turbulence_threshold:\n",
        "            available_amount = self.state[0] // self.state[index+1]\n",
        "            # print('available_amount:{}'.format(available_amount))\n",
        "            \n",
        "            #update balance\n",
        "            self.state[0] -= self.state[index+1]*min(available_amount, action)* \\\n",
        "                              (1+ TRANSACTION_FEE_PERCENT)\n",
        "\n",
        "            self.state[index+TOTAL_STOCKS+1] += min(available_amount, action)\n",
        "            \n",
        "            self.cost+=self.state[index+1]*min(available_amount, action)* \\\n",
        "                              TRANSACTION_FEE_PERCENT\n",
        "            self.trades+=1\n",
        "        else:\n",
        "            # if turbulence goes over threshold, just stop buying\n",
        "            pass\n",
        "        \n",
        "    def step(self, actions):\n",
        "        # print(self.day)\n",
        "        self.terminal = self.day >= len(self.df.index.unique())-1\n",
        "        # print(actions)\n",
        "\n",
        "        if self.terminal:\n",
        "            plt.plot(self.asset_memory,'r')\n",
        "            plt.savefig('account_value_validation_{}.png'.format(self.iteration))\n",
        "            plt.close()\n",
        "            df_total_value = pd.DataFrame(self.asset_memory)\n",
        "            df_total_value.to_csv('account_value_validation_{}.csv'.format(self.iteration))\n",
        "            end_total_asset = self.state[0]+ \\\n",
        "            sum(np.array(self.state[1:(TOTAL_STOCKS+1)])*np.array(self.state[(TOTAL_STOCKS+1):(TOTAL_STOCKS*2+1)]))\n",
        "            #print(\"previous_total_asset:{}\".format(self.asset_memory[0]))           \n",
        "\n",
        "            #print(\"end_total_asset:{}\".format(end_total_asset))\n",
        "            #print(\"total_reward:{}\".format(self.state[0]+sum(np.array(self.state[1:(TOTAL_STOCKS+1)])*np.array(self.state[(TOTAL_STOCKS+1):61]))- self.asset_memory[0] ))\n",
        "            #print(\"total_cost: \", self.cost)\n",
        "            #print(\"total trades: \", self.trades)\n",
        "\n",
        "            df_total_value.columns = ['account_value']\n",
        "            df_total_value['daily_return']=df_total_value.pct_change(1)\n",
        "            sharpe = (4**0.5)*df_total_value['daily_return'].mean()/ \\\n",
        "                  df_total_value['daily_return'].std()\n",
        "            #print(\"Sharpe: \",sharpe)\n",
        "            \n",
        "            df_rewards = pd.DataFrame(self.rewards_memory)\n",
        "            df_rewards.to_csv('account_rewards_trade_{}.csv'.format(self.iteration))\n",
        "            \n",
        "            # print('total asset: {}'.format(self.state[0]+ sum(np.array(self.state[1:29])*np.array(self.state[29:]))))\n",
        "            #with open('obs.pkl', 'wb') as f:  \n",
        "            #    pickle.dump(self.state, f)\n",
        "            \n",
        "            return self.state, self.reward, self.terminal,{}\n",
        "\n",
        "        else:\n",
        "            # print(np.array(self.state[1:29]))\n",
        "\n",
        "            actions = actions * MAX_NORMALIZE\n",
        "            #actions = (actions.astype(int))\n",
        "            if self.turbulence>=self.turbulence_threshold:\n",
        "                actions=np.array([-MAX_NORMALIZE]*TOTAL_STOCKS)\n",
        "            begin_total_asset = self.state[0]+ \\\n",
        "            sum(np.array(self.state[1:(TOTAL_STOCKS+1)])*np.array(self.state[(TOTAL_STOCKS+1):(TOTAL_STOCKS*2+1)]))\n",
        "            #print(\"begin_total_asset:{}\".format(begin_total_asset))\n",
        "            \n",
        "            argsort_actions = np.argsort(actions)\n",
        "            \n",
        "            sell_index = argsort_actions[:np.where(actions < 0)[0].shape[0]]\n",
        "            buy_index = argsort_actions[::-1][:np.where(actions > 0)[0].shape[0]]\n",
        "\n",
        "            for index in sell_index:\n",
        "                # print('take sell action'.format(actions[index]))\n",
        "                self._sell_stock(index, actions[index])\n",
        "\n",
        "            for index in buy_index:\n",
        "                # print('take buy action: {}'.format(actions[index]))\n",
        "                self._buy_stock(index, actions[index])\n",
        "\n",
        "            self.day += 1\n",
        "            self.data = self.df.loc[self.day,:]         \n",
        "            self.turbulence = self.data['turbulence'].values[0]\n",
        "            #print(self.turbulence)\n",
        "            #load next state\n",
        "            # print(\"stock_shares:{}\".format(self.state[29:]))\n",
        "            self.state =  [self.state[0]] + \\\n",
        "                    self.data.adjcp.values.tolist() + \\\n",
        "                    list(self.state[(TOTAL_STOCKS+1):(TOTAL_STOCKS*2+1)]) + \\\n",
        "                    self.data.macd.values.tolist() + \\\n",
        "                    self.data.rsi.values.tolist() + \\\n",
        "                    self.data.cci.values.tolist() + \\\n",
        "                    self.data.adx.values.tolist()\n",
        "            \n",
        "            end_total_asset = self.state[0]+ \\\n",
        "            sum(np.array(self.state[1:(TOTAL_STOCKS+1)])*np.array(self.state[(TOTAL_STOCKS+1):(TOTAL_STOCKS*2+1)]))\n",
        "            self.asset_memory.append(end_total_asset)\n",
        "            #print(\"end_total_asset:{}\".format(end_total_asset))\n",
        "            \n",
        "            self.reward = end_total_asset - begin_total_asset            \n",
        "            # print(\"step_reward:{}\".format(self.reward))\n",
        "            self.rewards_memory.append(self.reward)\n",
        "            \n",
        "            self.reward = self.reward*REWARD_SCALING\n",
        "\n",
        "        return self.state, self.reward, self.terminal, {}\n",
        "\n",
        "    def reset(self):  \n",
        "        self.asset_memory = [INITIAL_ACC_BAL]\n",
        "        self.day = 0\n",
        "        self.data = self.df.loc[self.day,:]\n",
        "        self.turbulence = 0\n",
        "        self.cost = 0\n",
        "        self.trades = 0\n",
        "        self.terminal = False \n",
        "        #self.iteration=self.iteration\n",
        "        self.rewards_memory = []\n",
        "        #initiate state\n",
        "        self.state = [INITIAL_ACC_BAL] + \\\n",
        "                      self.data.adjcp.values.tolist() + \\\n",
        "                      [0]*TOTAL_STOCKS + \\\n",
        "                      self.data.macd.values.tolist() + \\\n",
        "                      self.data.rsi.values.tolist()  + \\\n",
        "                      self.data.cci.values.tolist()  + \\\n",
        "                      self.data.adx.values.tolist() \n",
        "            \n",
        "        return self.state\n",
        "    \n",
        "    def render(self, mode='human',close=False):\n",
        "        return self.state\n",
        "    \n",
        "\n",
        "    def _seed(self, seed=None):\n",
        "        self.np_random, seed = seeding.np_random(seed)\n",
        "        return [seed]"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_c3qjJUVeYo6"
      },
      "source": [
        "class StockTradeEnv(gym.Env):\n",
        "    \"\"\"A stock trading environment for OpenAI gym\"\"\"\n",
        "    metadata = {'render.modes': ['human']}\n",
        "\n",
        "    def __init__(self, df,day = 0,turbulence_threshold=140\n",
        "                 ,initial=True, previous_state=[], model_name='', iteration=''):\n",
        "        #money = 10 , scope = 1\n",
        "        self.day = day\n",
        "        self.df = df\n",
        "        self.initial = initial\n",
        "        self.previous_state = previous_state\n",
        "        \n",
        "        # action_space normalization and shape is TOTAL_STOCKS\n",
        "        self.action_space = spaces.Box(low = -1, high = 1,shape = (TOTAL_STOCKS,)) \n",
        "        \n",
        "        # Shape = 181: [Current Balance]+[prices 1-30]+[owned shares 1-30] \n",
        "        # +[macd 1-30]+ [rsi 1-30] + [cci 1-30] + [adx 1-30]\n",
        "        self.observation_space = spaces.Box(low=0, high=np.inf, shape = (181,))\n",
        "        \n",
        "        # load data from a pandas dataframe\n",
        "        self.data = self.df.loc[self.day,:]\n",
        "        self.terminal = False     \n",
        "        self.turbulence_threshold = turbulence_threshold\n",
        "        \n",
        "        # initalize state\n",
        "        self.state = [INITIAL_ACC_BAL] + \\\n",
        "                      self.data.adjcp.values.tolist() + \\\n",
        "                      [0]*TOTAL_STOCKS + \\\n",
        "                      self.data.macd.values.tolist() + \\\n",
        "                      self.data.rsi.values.tolist() + \\\n",
        "                      self.data.cci.values.tolist() + \\\n",
        "                      self.data.adx.values.tolist()\n",
        "        # initialize reward\n",
        "        self.reward = 0\n",
        "        self.turbulence = 0\n",
        "        self.cost = 0\n",
        "        self.trades = 0\n",
        "        # memorize all the total balance change\n",
        "        self.asset_memory = [INITIAL_ACC_BAL]\n",
        "        self.rewards_memory = []\n",
        "        #self.reset()\n",
        "        self._seed()\n",
        "        self.model_name=model_name        \n",
        "        self.iteration=iteration\n",
        "\n",
        "\n",
        "    def _sell_stock(self, index, action):\n",
        "        # perform sell action based on the sign of the action\n",
        "        if self.turbulence<self.turbulence_threshold:\n",
        "            if self.state[index+TOTAL_STOCKS+1] > 0:\n",
        "                #update balance\n",
        "                self.state[0] += \\\n",
        "                self.state[index+1]*min(abs(action),self.state[index+TOTAL_STOCKS+1]) * \\\n",
        "                 (1- TRANSACTION_FEE_PERCENT)\n",
        "                \n",
        "                self.state[index+TOTAL_STOCKS+1] -= min(abs(action), self.state[index+TOTAL_STOCKS+1])\n",
        "                self.cost +=self.state[index+1]*min(abs(action),self.state[index+TOTAL_STOCKS+1]) * \\\n",
        "                 TRANSACTION_FEE_PERCENT\n",
        "                self.trades+=1\n",
        "            else:\n",
        "                pass\n",
        "        else:\n",
        "            # if turbulence goes over threshold, just clear out all positions \n",
        "            if self.state[index+TOTAL_STOCKS+1] > 0:\n",
        "                #update balance\n",
        "                self.state[0] += self.state[index+1]*self.state[index+TOTAL_STOCKS+1]* \\\n",
        "                              (1- TRANSACTION_FEE_PERCENT)\n",
        "                self.state[index+TOTAL_STOCKS+1] =0\n",
        "                self.cost += self.state[index+1]*self.state[index+TOTAL_STOCKS+1]* \\\n",
        "                              TRANSACTION_FEE_PERCENT\n",
        "                self.trades+=1\n",
        "            else:\n",
        "                pass\n",
        "    \n",
        "    def _buy_stock(self, index, action):\n",
        "        # perform buy action based on the sign of the action\n",
        "        if self.turbulence< self.turbulence_threshold:\n",
        "            available_amount = self.state[0] // self.state[index+1]\n",
        "            # print('available_amount:{}'.format(available_amount))\n",
        "            \n",
        "            #update balance\n",
        "            self.state[0] -= self.state[index+1]*min(available_amount, action)* \\\n",
        "                              (1+ TRANSACTION_FEE_PERCENT)\n",
        "\n",
        "            self.state[index+TOTAL_STOCKS+1] += min(available_amount, action)\n",
        "            \n",
        "            self.cost+=self.state[index+1]*min(available_amount, action)* \\\n",
        "                              TRANSACTION_FEE_PERCENT\n",
        "            self.trades+=1\n",
        "        else:\n",
        "            # if turbulence goes over threshold, just stop buying\n",
        "            pass\n",
        "        \n",
        "    def step(self, actions):\n",
        "        # print(self.day)\n",
        "        self.terminal = self.day >= len(self.df.index.unique())-1\n",
        "        # print(actions)\n",
        "\n",
        "        if self.terminal:\n",
        "            plt.plot(self.asset_memory,'r')\n",
        "            plt.savefig('account_value_trade_{}_{}.png'.format(self.model_name, self.iteration))\n",
        "            plt.close()\n",
        "            df_total_value = pd.DataFrame(self.asset_memory)\n",
        "            df_total_value.to_csv('account_value_trade_{}_{}.csv'.format(self.model_name, self.iteration))\n",
        "            end_total_asset = self.state[0]+ \\\n",
        "            sum(np.array(self.state[1:(TOTAL_STOCKS+1)])*np.array(self.state[(TOTAL_STOCKS+1):(TOTAL_STOCKS*2+1)]))\n",
        "            print(\"previous_total_asset:{}\".format(self.asset_memory[0]))           \n",
        "\n",
        "            print(\"end_total_asset:{}\".format(end_total_asset))\n",
        "            print(\"total_reward:{}\".format(self.state[0]+sum(np.array(self.state[1:(TOTAL_STOCKS+1)])*np.array(self.state[(TOTAL_STOCKS+1):(TOTAL_STOCKS*2+1)]))- self.asset_memory[0] ))\n",
        "            print(\"total_cost: \", self.cost)\n",
        "            print(\"total trades: \", self.trades)\n",
        "\n",
        "            df_total_value.columns = ['account_value']\n",
        "            df_total_value['daily_return']=df_total_value.pct_change(1)\n",
        "            sharpe = (4**0.5)*df_total_value['daily_return'].mean()/ \\\n",
        "                  df_total_value['daily_return'].std()\n",
        "            print(\"Sharpe: \",sharpe)\n",
        "            \n",
        "            df_rewards = pd.DataFrame(self.rewards_memory)\n",
        "            df_rewards.to_csv('account_rewards_trade_{}_{}.csv'.format(self.model_name, self.iteration))\n",
        "            \n",
        "            # print('total asset: {}'.format(self.state[0]+ sum(np.array(self.state[1:29])*np.array(self.state[29:]))))\n",
        "            #with open('obs.pkl', 'wb') as f:  \n",
        "            #    pickle.dump(self.state, f)\n",
        "            \n",
        "            return self.state, self.reward, self.terminal,{}\n",
        "\n",
        "        else:\n",
        "            # print(np.array(self.state[1:29]))\n",
        "\n",
        "            actions = actions * MAX_NORMALIZE\n",
        "            #actions = (actions.astype(int))\n",
        "            if self.turbulence>=self.turbulence_threshold:\n",
        "                actions=np.array([-MAX_NORMALIZE]*TOTAL_STOCKS)\n",
        "                \n",
        "            begin_total_asset = self.state[0]+ \\\n",
        "            sum(np.array(self.state[1:(TOTAL_STOCKS+1)])*np.array(self.state[(TOTAL_STOCKS+1):(TOTAL_STOCKS*2+1)]))\n",
        "            #print(\"begin_total_asset:{}\".format(begin_total_asset))\n",
        "            \n",
        "            argsort_actions = np.argsort(actions)\n",
        "            \n",
        "            sell_index = argsort_actions[:np.where(actions < 0)[0].shape[0]]\n",
        "            buy_index = argsort_actions[::-1][:np.where(actions > 0)[0].shape[0]]\n",
        "\n",
        "            for index in sell_index:\n",
        "                # print('take sell action'.format(actions[index]))\n",
        "                self._sell_stock(index, actions[index])\n",
        "\n",
        "            for index in buy_index:\n",
        "                # print('take buy action: {}'.format(actions[index]))\n",
        "                self._buy_stock(index, actions[index])\n",
        "\n",
        "            self.day += 1\n",
        "            self.data = self.df.loc[self.day,:]         \n",
        "            self.turbulence = self.data['turbulence'].values[0]\n",
        "            #print(self.turbulence)\n",
        "            #load next state\n",
        "            # print(\"stock_shares:{}\".format(self.state[29:]))\n",
        "            self.state =  [self.state[0]] + \\\n",
        "                    self.data.adjcp.values.tolist() + \\\n",
        "                    list(self.state[(TOTAL_STOCKS+1):(TOTAL_STOCKS*2+1)]) + \\\n",
        "                    self.data.macd.values.tolist() + \\\n",
        "                    self.data.rsi.values.tolist() + \\\n",
        "                    self.data.cci.values.tolist() + \\\n",
        "                    self.data.adx.values.tolist()\n",
        "            \n",
        "            end_total_asset = self.state[0]+ \\\n",
        "            sum(np.array(self.state[1:(TOTAL_STOCKS+1)])*np.array(self.state[(TOTAL_STOCKS+1):(TOTAL_STOCKS*2+1)]))\n",
        "            self.asset_memory.append(end_total_asset)\n",
        "            #print(\"end_total_asset:{}\".format(end_total_asset))\n",
        "            \n",
        "            self.reward = end_total_asset - begin_total_asset            \n",
        "            # print(\"step_reward:{}\".format(self.reward))\n",
        "            self.rewards_memory.append(self.reward)\n",
        "            \n",
        "            self.reward = self.reward*REWARD_SCALING\n",
        "\n",
        "\n",
        "        return self.state, self.reward, self.terminal, {}\n",
        "\n",
        "    def reset(self):  \n",
        "        if self.initial:\n",
        "            self.asset_memory = [INITIAL_ACC_BAL]\n",
        "            self.day = 0\n",
        "            self.data = self.df.loc[self.day,:]\n",
        "            self.turbulence = 0\n",
        "            self.cost = 0\n",
        "            self.trades = 0\n",
        "            self.terminal = False \n",
        "            #self.iteration=self.iteration\n",
        "            self.rewards_memory = []\n",
        "            #initiate state\n",
        "            self.state = [INITIAL_ACC_BAL] + \\\n",
        "                          self.data.adjcp.values.tolist() + \\\n",
        "                          [0]*TOTAL_STOCKS + \\\n",
        "                          self.data.macd.values.tolist() + \\\n",
        "                          self.data.rsi.values.tolist()  + \\\n",
        "                          self.data.cci.values.tolist()  + \\\n",
        "                          self.data.adx.values.tolist() \n",
        "        else:\n",
        "            previous_total_asset = self.previous_state[0]+ \\\n",
        "            sum(np.array(self.previous_state[1:(TOTAL_STOCKS+1)])*np.array(self.previous_state[(TOTAL_STOCKS+1):(TOTAL_STOCKS*2+1)]))\n",
        "            self.asset_memory = [previous_total_asset]\n",
        "            #self.asset_memory = [self.previous_state[0]]\n",
        "            self.day = 0\n",
        "            self.data = self.df.loc[self.day,:]\n",
        "            self.turbulence = 0\n",
        "            self.cost = 0\n",
        "            self.trades = 0\n",
        "            self.terminal = False \n",
        "            #self.iteration=iteration\n",
        "            self.rewards_memory = []\n",
        "            #initiate state\n",
        "            #self.previous_state[(TOTAL_STOCKS+1):(TOTAL_STOCKS*2+1)]\n",
        "            #[0]*TOTAL_STOCKS + \\\n",
        "\n",
        "            self.state = [ self.previous_state[0]] + \\\n",
        "                          self.data.adjcp.values.tolist() + \\\n",
        "                          self.previous_state[(TOTAL_STOCKS+1):(TOTAL_STOCKS*2+1)]+ \\\n",
        "                          self.data.macd.values.tolist() + \\\n",
        "                          self.data.rsi.values.tolist()  + \\\n",
        "                          self.data.cci.values.tolist()  + \\\n",
        "                          self.data.adx.values.tolist() \n",
        "            \n",
        "        return self.state\n",
        "    \n",
        "    def render(self, mode='human',close=False):\n",
        "        return self.state\n",
        "    \n",
        "\n",
        "    def _seed(self, seed=None):\n",
        "        self.np_random, seed = seeding.np_random(seed)\n",
        "        return [seed]"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E_8q_FafuXCW"
      },
      "source": [
        "## Models used in  Ensemble Strategy - A2C, DDPG, PPO\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UInF7UItea9p"
      },
      "source": [
        " def train_A2C(env_train, model_name, timesteps=50000):\n",
        "    start = time.time()\n",
        "    model = A2C('MlpPolicy', env_train, verbose=1)\n",
        "    model.learn(total_timesteps=timesteps)\n",
        "    end = time.time()\n",
        "\n",
        "    model.save(f\"{TRAINED_MODEL_DIR}/{model_name}\")\n",
        "    print('Training time (A2C): ', (end - start) / 60, ' minutes')\n",
        "    return model"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KR84ZncHeguM"
      },
      "source": [
        "def train_DDPG(env_train, model_name, timesteps=10000):\n",
        "    # add the noise objects for DDPG\n",
        "    n_actions = env_train.action_space.shape[-1]\n",
        "    param_noise = None\n",
        "    action_noise = OrnsteinUhlenbeckActionNoise(mean=np.zeros(n_actions), sigma=float(0.5) * np.ones(n_actions))\n",
        "    start = time.time()\n",
        "    model = DDPG('MlpPolicy', env_train, param_noise=param_noise, action_noise=action_noise)\n",
        "    model.learn(total_timesteps=timesteps)\n",
        "    end = time.time()\n",
        "\n",
        "    model.save(f\"{TRAINED_MODEL_DIR}/{model_name}\")\n",
        "    print('Training time (DDPG): ', (end-start)/60,' minutes')\n",
        "    return model"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sOsQQD_pek0D"
      },
      "source": [
        "def train_PPO(env_train, model_name, timesteps=50000):  \n",
        "    start = time.time()\n",
        "    model = PPO2('MlpPolicy', env_train, ent_coef = 0.005, nminibatches = 8)\n",
        "    model.learn(total_timesteps=timesteps)\n",
        "    end = time.time()\n",
        "\n",
        "    model.save(f\"{TRAINED_MODEL_DIR}/{model_name}\")\n",
        "    print('Training time (PPO): ', (end - start) / 60, ' minutes')\n",
        "    return model"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WeO818RTel9F"
      },
      "source": [
        "def DRL_prediction(df,\n",
        "                   model,\n",
        "                   name,\n",
        "                   last_state,\n",
        "                   iter_num,\n",
        "                   unique_trade_date,\n",
        "                   rebalance_window,\n",
        "                   turbulence_threshold,\n",
        "                   initial):\n",
        "    ### make a prediction based on trained model### \n",
        "\n",
        "    ## trading env\n",
        "    trade_data = data_split(df, start=unique_trade_date[iter_num - rebalance_window], end=unique_trade_date[iter_num])\n",
        "    env_trade = DummyVecEnv([lambda: StockTradeEnv(trade_data,\n",
        "                                                   turbulence_threshold=turbulence_threshold,\n",
        "                                                   initial=initial,\n",
        "                                                   previous_state=last_state,\n",
        "                                                   model_name=name,\n",
        "                                                   iteration=iter_num)])\n",
        "    obs_trade = env_trade.reset()\n",
        "\n",
        "    for i in range(len(trade_data.index.unique())):\n",
        "        action, _states = model.predict(obs_trade)\n",
        "        obs_trade, rewards, dones, info = env_trade.step(action)\n",
        "        if i == (len(trade_data.index.unique()) - 2):\n",
        "            # print(env_test.render())\n",
        "            last_state = env_trade.render()\n",
        "\n",
        "    df_last_state = pd.DataFrame({'last_state': last_state})\n",
        "    df_last_state.to_csv('last_state_{}_{}.csv'.format(name, i), index=False)\n",
        "    return last_state"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "klb1A70nezYC"
      },
      "source": [
        "def DRL_validation(model, test_data, test_env, test_obs) -> None:\n",
        "    ###validation process###\n",
        "    for i in range(len(test_data.index.unique())):\n",
        "        action, _states = model.predict(test_obs)\n",
        "        test_obs, rewards, dones, info = test_env.step(action)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nH0h8SHKe3aa"
      },
      "source": [
        "def get_validation_sharpe(iteration):\n",
        "    ###Calculate Sharpe ratio based on validation results###\n",
        "    df_total_value = pd.read_csv('account_value_validation_{}.csv'.format(iteration), index_col=0)\n",
        "    df_total_value.columns = ['account_value_train']\n",
        "    df_total_value['daily_return'] = df_total_value.pct_change(1)\n",
        "    sharpe = (4 ** 0.5) * df_total_value['daily_return'].mean() / \\\n",
        "             df_total_value['daily_return'].std()\n",
        "    return sharpe"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p_PZK3Ctt7gB"
      },
      "source": [
        "## Running the Ensemble Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NO1NJi3Ke6_d"
      },
      "source": [
        "def run_ensemble_strategy(df, unique_trade_date, rebalance_window, validation_window) -> None:\n",
        "    \"\"\"Ensemble Strategy that combines PPO, A2C and DDPG\"\"\"\n",
        "    print(\"============Start Ensemble Strategy============\")\n",
        "    # for ensemble model, it's necessary to feed the last state\n",
        "    # of the previous model to the current model as the initial state\n",
        "    last_state_ensemble = []\n",
        "\n",
        "    ppo_sharpe_list = []\n",
        "    ddpg_sharpe_list = []\n",
        "    a2c_sharpe_list = []\n",
        "\n",
        "    model_use = []\n",
        "\n",
        "    # based on the analysis of the in-sample data\n",
        "    #turbulence_threshold = 140\n",
        "    insample_turbulence = df[(df.datadate<20160500) & (df.datadate>=20100000)]\n",
        "    insample_turbulence = insample_turbulence.drop_duplicates(subset=['datadate'])\n",
        "    insample_turbulence_threshold = np.quantile(insample_turbulence.turbulence.values, .90)\n",
        "\n",
        "    start = time.time()\n",
        "    for i in range(rebalance_window + validation_window, len(unique_trade_date), rebalance_window):\n",
        "        print(\"============================================\")\n",
        "        ## initial state is empty\n",
        "        if i - rebalance_window - validation_window == 0:\n",
        "            # inital state\n",
        "            initial = True\n",
        "        else:\n",
        "            # previous state\n",
        "            initial = False\n",
        "\n",
        "        # Tuning trubulence index based on historical data\n",
        "        # Turbulence lookback window is one quarter\n",
        "        historical_turbulence = df[(df.datadate<unique_trade_date[i - rebalance_window - validation_window]) & (df.datadate>=(unique_trade_date[i - rebalance_window - validation_window-63]))]\n",
        "        historical_turbulence = historical_turbulence.drop_duplicates(subset=['datadate'])\n",
        "        historical_turbulence_mean = np.mean(historical_turbulence.turbulence.values)   \n",
        "\n",
        "        if historical_turbulence_mean > insample_turbulence_threshold:\n",
        "            # if the mean of the historical data is greater than the 90% quantile of insample turbulence data\n",
        "            # then we assume that the current market is volatile, \n",
        "            # therefore we set the 90% quantile of insample turbulence data as the turbulence threshold \n",
        "            # meaning the current turbulence can't exceed the 90% quantile of insample turbulence data\n",
        "            turbulence_threshold = insample_turbulence_threshold\n",
        "        else:\n",
        "            # if the mean of the historical data is less than the 90% quantile of insample turbulence data\n",
        "            # then we tune up the turbulence_threshold, meaning we lower the risk \n",
        "            turbulence_threshold = np.quantile(insample_turbulence.turbulence.values, 1)\n",
        "        print(\"turbulence_threshold: \", turbulence_threshold)\n",
        "\n",
        "        ############## Environment Setup starts ##############\n",
        "        ## training env\n",
        "        train = data_split(df, start=20100000, end=unique_trade_date[i - rebalance_window - validation_window])\n",
        "        env_train = DummyVecEnv([lambda: StockTrainEnv(train)])\n",
        "\n",
        "        ## validation env\n",
        "        validation = data_split(df, start=unique_trade_date[i - rebalance_window - validation_window],\n",
        "                                end=unique_trade_date[i - rebalance_window])\n",
        "        env_val = DummyVecEnv([lambda: StockValidationEnv(validation,\n",
        "                                                          turbulence_threshold=turbulence_threshold,\n",
        "                                                          iteration=i)])\n",
        "        obs_val = env_val.reset()\n",
        "        ############## Environment Setup ends ##############\n",
        "\n",
        "        ############## Training and Validation starts ##############\n",
        "        print(\"======Model training from: \", 20100000, \"to \",\n",
        "              unique_trade_date[i - rebalance_window - validation_window])\n",
        "        # print(\"training: \",len(data_split(df, start=20090000, end=test.datadate.unique()[i-rebalance_window]) ))\n",
        "        # print(\"==============Model Training===========\")\n",
        "        print(\"======A2C Training========\")\n",
        "        model_a2c = train_A2C(env_train, model_name=\"A2C_30k_dow_{}\".format(i), timesteps=30000)\n",
        "        print(\"======A2C Validation from: \", unique_trade_date[i - rebalance_window - validation_window], \"to \",\n",
        "              unique_trade_date[i - rebalance_window])\n",
        "        DRL_validation(model=model_a2c, test_data=validation, test_env=env_val, test_obs=obs_val)\n",
        "        sharpe_a2c = get_validation_sharpe(i)\n",
        "        print(\"A2C Sharpe Ratio: \", sharpe_a2c)\n",
        "\n",
        "        print(\"======PPO Training========\")\n",
        "        model_ppo = train_PPO(env_train, model_name=\"PPO_100k_dow_{}\".format(i), timesteps=100000)\n",
        "        print(\"======PPO Validation from: \", unique_trade_date[i - rebalance_window - validation_window], \"to \",\n",
        "              unique_trade_date[i - rebalance_window])\n",
        "        DRL_validation(model=model_ppo, test_data=validation, test_env=env_val, test_obs=obs_val)\n",
        "        sharpe_ppo = get_validation_sharpe(i)\n",
        "        print(\"PPO Sharpe Ratio: \", sharpe_ppo)\n",
        "\n",
        "        print(\"======DDPG Training========\")\n",
        "        model_ddpg = train_DDPG(env_train, model_name=\"DDPG_10k_dow_{}\".format(i), timesteps=10000)\n",
        "        #model_ddpg = train_TD3(env_train, model_name=\"DDPG_10k_dow_{}\".format(i), timesteps=20000)\n",
        "        print(\"======DDPG Validation from: \", unique_trade_date[i - rebalance_window - validation_window], \"to \",\n",
        "              unique_trade_date[i - rebalance_window])\n",
        "        DRL_validation(model=model_ddpg, test_data=validation, test_env=env_val, test_obs=obs_val)\n",
        "        sharpe_ddpg = get_validation_sharpe(i)\n",
        "\n",
        "        ppo_sharpe_list.append(sharpe_ppo)\n",
        "        a2c_sharpe_list.append(sharpe_a2c)\n",
        "        ddpg_sharpe_list.append(sharpe_ddpg)\n",
        "\n",
        "        # Model Selection based on sharpe ratio\n",
        "        if (sharpe_ppo >= sharpe_a2c) & (sharpe_ppo >= sharpe_ddpg):\n",
        "            model_ensemble = model_ppo\n",
        "            model_use.append('PPO')\n",
        "        elif (sharpe_a2c > sharpe_ppo) & (sharpe_a2c > sharpe_ddpg):\n",
        "            model_ensemble = model_a2c\n",
        "            model_use.append('A2C')\n",
        "        else:\n",
        "            model_ensemble = model_ddpg\n",
        "            model_use.append('DDPG')\n",
        "        ############## Training and Validation ends ##############    \n",
        "\n",
        "        ############## Trading starts ##############    \n",
        "        print(\"======Trading from: \", unique_trade_date[i - rebalance_window], \"to \", unique_trade_date[i])\n",
        "        #print(\"Used Model: \", model_ensemble)\n",
        "        last_state_ensemble = DRL_prediction(df=df, model=model_ensemble, name=\"ensemble\",\n",
        "                                             last_state=last_state_ensemble, iter_num=i,\n",
        "                                             unique_trade_date=unique_trade_date,\n",
        "                                             rebalance_window=rebalance_window,\n",
        "                                             turbulence_threshold=turbulence_threshold,\n",
        "                                             initial=initial)\n",
        "        # print(\"============Trading Done============\")\n",
        "        ############## Trading ends ##############    \n",
        "\n",
        "    end = time.time()\n",
        "    print(\"Ensemble Strategy took: \", (end - start) / 60, \" minutes\")"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XlRrFn87fHDt",
        "outputId": "dd2db1e8-70b1-4a59-bfa6-72444e4060ac"
      },
      "source": [
        "def run_model() -> None:\n",
        "    \"\"\"Train the model.\"\"\"\n",
        "\n",
        "    # read and preprocess data\n",
        "    data = preprocess_data()\n",
        "    data = add_turbulence(data) \n",
        "    # 2016/05/01 is the date that validation starts\n",
        "    # 2017/01/01 is the date that real trading starts\n",
        "    # unique_trade_date needs to start from 2016/05/01 for validation purpose\n",
        "    unique_trade_date = data[(data.datadate > 20160501)&(data.datadate <= 20210207)].datadate.unique()\n",
        "\n",
        "    # rebalance_window is the number of months to retrain the model\n",
        "    # validation_window is the number of months to validation the model and select for trading\n",
        "    rebalance_window = 63\n",
        "    validation_window = 63\n",
        "    \n",
        "    ## Ensemble Strategy\n",
        "    run_ensemble_strategy(df=data, \n",
        "                          unique_trade_date= unique_trade_date,\n",
        "                          rebalance_window = rebalance_window,\n",
        "                          validation_window=validation_window)\n",
        "\n",
        "    #_logger.info(f\"saving model version: {_version}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    run_model()\n"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "| policy_entropy     | 43       |\n",
            "| total_timesteps    | 17000    |\n",
            "| value_loss         | 15.6     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | -0.136   |\n",
            "| fps                | 300      |\n",
            "| nupdates           | 3500     |\n",
            "| policy_entropy     | 43       |\n",
            "| total_timesteps    | 17500    |\n",
            "| value_loss         | 2.41     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0.002    |\n",
            "| fps                | 300      |\n",
            "| nupdates           | 3600     |\n",
            "| policy_entropy     | 43       |\n",
            "| total_timesteps    | 18000    |\n",
            "| value_loss         | 2.27     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | -0.273   |\n",
            "| fps                | 300      |\n",
            "| nupdates           | 3700     |\n",
            "| policy_entropy     | 43       |\n",
            "| total_timesteps    | 18500    |\n",
            "| value_loss         | 1.27     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0        |\n",
            "| fps                | 300      |\n",
            "| nupdates           | 3800     |\n",
            "| policy_entropy     | 43       |\n",
            "| total_timesteps    | 19000    |\n",
            "| value_loss         | 1.2      |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0.0541   |\n",
            "| fps                | 300      |\n",
            "| nupdates           | 3900     |\n",
            "| policy_entropy     | 43       |\n",
            "| total_timesteps    | 19500    |\n",
            "| value_loss         | 7.08     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0.000462 |\n",
            "| fps                | 301      |\n",
            "| nupdates           | 4000     |\n",
            "| policy_entropy     | 43.1     |\n",
            "| total_timesteps    | 20000    |\n",
            "| value_loss         | 7.76     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0        |\n",
            "| fps                | 301      |\n",
            "| nupdates           | 4100     |\n",
            "| policy_entropy     | 43.2     |\n",
            "| total_timesteps    | 20500    |\n",
            "| value_loss         | 37.6     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0.232    |\n",
            "| fps                | 301      |\n",
            "| nupdates           | 4200     |\n",
            "| policy_entropy     | 43.2     |\n",
            "| total_timesteps    | 21000    |\n",
            "| value_loss         | 0.647    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0.0836   |\n",
            "| fps                | 301      |\n",
            "| nupdates           | 4300     |\n",
            "| policy_entropy     | 43.2     |\n",
            "| total_timesteps    | 21500    |\n",
            "| value_loss         | 0.385    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0        |\n",
            "| fps                | 301      |\n",
            "| nupdates           | 4400     |\n",
            "| policy_entropy     | 43.2     |\n",
            "| total_timesteps    | 22000    |\n",
            "| value_loss         | 0.71     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0.105    |\n",
            "| fps                | 302      |\n",
            "| nupdates           | 4500     |\n",
            "| policy_entropy     | 43.2     |\n",
            "| total_timesteps    | 22500    |\n",
            "| value_loss         | 35.6     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | -0.00805 |\n",
            "| fps                | 302      |\n",
            "| nupdates           | 4600     |\n",
            "| policy_entropy     | 43.3     |\n",
            "| total_timesteps    | 23000    |\n",
            "| value_loss         | 85.4     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0        |\n",
            "| fps                | 301      |\n",
            "| nupdates           | 4700     |\n",
            "| policy_entropy     | 43.2     |\n",
            "| total_timesteps    | 23500    |\n",
            "| value_loss         | 10.5     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0        |\n",
            "| fps                | 302      |\n",
            "| nupdates           | 4800     |\n",
            "| policy_entropy     | 43.3     |\n",
            "| total_timesteps    | 24000    |\n",
            "| value_loss         | 3.28     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0        |\n",
            "| fps                | 302      |\n",
            "| nupdates           | 4900     |\n",
            "| policy_entropy     | 43.3     |\n",
            "| total_timesteps    | 24500    |\n",
            "| value_loss         | 18.8     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0        |\n",
            "| fps                | 303      |\n",
            "| nupdates           | 5000     |\n",
            "| policy_entropy     | 43.2     |\n",
            "| total_timesteps    | 25000    |\n",
            "| value_loss         | 2.3      |\n",
            "---------------------------------\n",
            "----------------------------------\n",
            "| explained_variance | -1.19e-07 |\n",
            "| fps                | 303       |\n",
            "| nupdates           | 5100      |\n",
            "| policy_entropy     | 43.2      |\n",
            "| total_timesteps    | 25500     |\n",
            "| value_loss         | 0.888     |\n",
            "----------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | -0.0441  |\n",
            "| fps                | 303      |\n",
            "| nupdates           | 5200     |\n",
            "| policy_entropy     | 43.3     |\n",
            "| total_timesteps    | 26000    |\n",
            "| value_loss         | 6.55     |\n",
            "---------------------------------\n",
            "----------------------------------\n",
            "| explained_variance | -1.19e-07 |\n",
            "| fps                | 304       |\n",
            "| nupdates           | 5300      |\n",
            "| policy_entropy     | 43.3      |\n",
            "| total_timesteps    | 26500     |\n",
            "| value_loss         | 2.47      |\n",
            "----------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0.243    |\n",
            "| fps                | 304      |\n",
            "| nupdates           | 5400     |\n",
            "| policy_entropy     | 43.3     |\n",
            "| total_timesteps    | 27000    |\n",
            "| value_loss         | 1.63     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0        |\n",
            "| fps                | 304      |\n",
            "| nupdates           | 5500     |\n",
            "| policy_entropy     | 43.3     |\n",
            "| total_timesteps    | 27500    |\n",
            "| value_loss         | 0.965    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0        |\n",
            "| fps                | 304      |\n",
            "| nupdates           | 5600     |\n",
            "| policy_entropy     | 43.4     |\n",
            "| total_timesteps    | 28000    |\n",
            "| value_loss         | 8.7      |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0        |\n",
            "| fps                | 304      |\n",
            "| nupdates           | 5700     |\n",
            "| policy_entropy     | 43.4     |\n",
            "| total_timesteps    | 28500    |\n",
            "| value_loss         | 44       |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0        |\n",
            "| fps                | 304      |\n",
            "| nupdates           | 5800     |\n",
            "| policy_entropy     | 43.5     |\n",
            "| total_timesteps    | 29000    |\n",
            "| value_loss         | 1.14     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 1.19e-07 |\n",
            "| fps                | 304      |\n",
            "| nupdates           | 5900     |\n",
            "| policy_entropy     | 43.5     |\n",
            "| total_timesteps    | 29500    |\n",
            "| value_loss         | 2.03     |\n",
            "---------------------------------\n",
            "----------------------------------\n",
            "| explained_variance | -1.19e-07 |\n",
            "| fps                | 304       |\n",
            "| nupdates           | 6000      |\n",
            "| policy_entropy     | 43.5      |\n",
            "| total_timesteps    | 30000     |\n",
            "| value_loss         | 3.39      |\n",
            "----------------------------------\n",
            "Training time (A2C):  1.6533344268798829  minutes\n",
            "======A2C Validation from:  20180502 to  20180801\n",
            "A2C Sharpe Ratio:  0.11463294235638993\n",
            "======PPO Training========\n",
            "Training time (PPO):  5.668112123012543  minutes\n",
            "======PPO Validation from:  20180502 to  20180801\n",
            "PPO Sharpe Ratio:  0.13578185396536413\n",
            "======DDPG Training========\n",
            "Training time (DDPG):  1.0126322825749716  minutes\n",
            "======DDPG Validation from:  20180502 to  20180801\n",
            "======Trading from:  20180801 to  20181030\n",
            "previous_total_asset:1264442.3212291624\n",
            "end_total_asset:1272523.7901934595\n",
            "total_reward:8081.468964297092\n",
            "total_cost:  4296.572329312228\n",
            "total trades:  567\n",
            "Sharpe:  0.12771591963472576\n",
            "============================================\n",
            "turbulence_threshold:  212.63534492887965\n",
            "======Model training from:  20100000 to  20180801\n",
            "======A2C Training========\n",
            "--------------------------------------\n",
            "| explained_variance      | 0        |\n",
            "| fps                     | 19       |\n",
            "| nupdates                | 1        |\n",
            "| policy_entropy          | 42.6     |\n",
            "| reference_Q_mean        | 3.25     |\n",
            "| reference_Q_std         | 2.14     |\n",
            "| reference_action_mean   | 0.0747   |\n",
            "| reference_action_std    | 0.962    |\n",
            "| reference_actor_Q_mean  | 4.17     |\n",
            "| reference_actor_Q_std   | 2.22     |\n",
            "| rollout/Q_mean          | 1.98     |\n",
            "| rollout/actions_mean    | 0.0419   |\n",
            "| rollout/actions_std     | 0.802    |\n",
            "| rollout/episode_steps   | 2.1e+03  |\n",
            "| rollout/episodes        | 4        |\n",
            "| rollout/return          | 125      |\n",
            "| rollout/return_history  | 125      |\n",
            "| total/duration          | 60       |\n",
            "| total/episodes          | 4        |\n",
            "| total/epochs            | 1        |\n",
            "| total/steps             | 9998     |\n",
            "| total/steps_per_second  | 167      |\n",
            "| total_timesteps         | 5        |\n",
            "| train/loss_actor        | -3.75    |\n",
            "| train/loss_critic       | 0.961    |\n",
            "| train/param_noise_di... | 0        |\n",
            "| value_loss              | 0.000413 |\n",
            "--------------------------------------\n",
            "----------------------------------\n",
            "| explained_variance | -1.19e-07 |\n",
            "| fps                | 251       |\n",
            "| nupdates           | 100       |\n",
            "| policy_entropy     | 42.6      |\n",
            "| total_timesteps    | 500       |\n",
            "| value_loss         | 5.4       |\n",
            "----------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | -0.421   |\n",
            "| fps                | 270      |\n",
            "| nupdates           | 200      |\n",
            "| policy_entropy     | 42.6     |\n",
            "| total_timesteps    | 1000     |\n",
            "| value_loss         | 8.43     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0.0927   |\n",
            "| fps                | 276      |\n",
            "| nupdates           | 300      |\n",
            "| policy_entropy     | 42.6     |\n",
            "| total_timesteps    | 1500     |\n",
            "| value_loss         | 1.56     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0.304    |\n",
            "| fps                | 281      |\n",
            "| nupdates           | 400      |\n",
            "| policy_entropy     | 42.6     |\n",
            "| total_timesteps    | 2000     |\n",
            "| value_loss         | 9.29     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | -0.375   |\n",
            "| fps                | 280      |\n",
            "| nupdates           | 500      |\n",
            "| policy_entropy     | 42.6     |\n",
            "| total_timesteps    | 2500     |\n",
            "| value_loss         | 0.557    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0.0154   |\n",
            "| fps                | 283      |\n",
            "| nupdates           | 600      |\n",
            "| policy_entropy     | 42.6     |\n",
            "| total_timesteps    | 3000     |\n",
            "| value_loss         | 3.98     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | -0.164   |\n",
            "| fps                | 285      |\n",
            "| nupdates           | 700      |\n",
            "| policy_entropy     | 42.6     |\n",
            "| total_timesteps    | 3500     |\n",
            "| value_loss         | 2.74     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0.00385  |\n",
            "| fps                | 287      |\n",
            "| nupdates           | 800      |\n",
            "| policy_entropy     | 42.6     |\n",
            "| total_timesteps    | 4000     |\n",
            "| value_loss         | 1.63     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0        |\n",
            "| fps                | 285      |\n",
            "| nupdates           | 900      |\n",
            "| policy_entropy     | 42.7     |\n",
            "| total_timesteps    | 4500     |\n",
            "| value_loss         | 0.22     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | -0.0373  |\n",
            "| fps                | 286      |\n",
            "| nupdates           | 1000     |\n",
            "| policy_entropy     | 42.7     |\n",
            "| total_timesteps    | 5000     |\n",
            "| value_loss         | 5.78     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0.117    |\n",
            "| fps                | 286      |\n",
            "| nupdates           | 1100     |\n",
            "| policy_entropy     | 42.7     |\n",
            "| total_timesteps    | 5500     |\n",
            "| value_loss         | 0.497    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | -0.231   |\n",
            "| fps                | 287      |\n",
            "| nupdates           | 1200     |\n",
            "| policy_entropy     | 42.8     |\n",
            "| total_timesteps    | 6000     |\n",
            "| value_loss         | 0.919    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0        |\n",
            "| fps                | 287      |\n",
            "| nupdates           | 1300     |\n",
            "| policy_entropy     | 42.8     |\n",
            "| total_timesteps    | 6500     |\n",
            "| value_loss         | 0.19     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0.229    |\n",
            "| fps                | 288      |\n",
            "| nupdates           | 1400     |\n",
            "| policy_entropy     | 42.8     |\n",
            "| total_timesteps    | 7000     |\n",
            "| value_loss         | 0.73     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | -0.202   |\n",
            "| fps                | 290      |\n",
            "| nupdates           | 1500     |\n",
            "| policy_entropy     | 42.7     |\n",
            "| total_timesteps    | 7500     |\n",
            "| value_loss         | 12.4     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | -0.0112  |\n",
            "| fps                | 291      |\n",
            "| nupdates           | 1600     |\n",
            "| policy_entropy     | 42.7     |\n",
            "| total_timesteps    | 8000     |\n",
            "| value_loss         | 19       |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | -0.12    |\n",
            "| fps                | 292      |\n",
            "| nupdates           | 1700     |\n",
            "| policy_entropy     | 42.7     |\n",
            "| total_timesteps    | 8500     |\n",
            "| value_loss         | 2.2      |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | -1.55    |\n",
            "| fps                | 293      |\n",
            "| nupdates           | 1800     |\n",
            "| policy_entropy     | 42.7     |\n",
            "| total_timesteps    | 9000     |\n",
            "| value_loss         | 1.37     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0        |\n",
            "| fps                | 293      |\n",
            "| nupdates           | 1900     |\n",
            "| policy_entropy     | 42.8     |\n",
            "| total_timesteps    | 9500     |\n",
            "| value_loss         | 3.08     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 1.19e-07 |\n",
            "| fps                | 294      |\n",
            "| nupdates           | 2000     |\n",
            "| policy_entropy     | 42.8     |\n",
            "| total_timesteps    | 10000    |\n",
            "| value_loss         | 1.74     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0.0428   |\n",
            "| fps                | 295      |\n",
            "| nupdates           | 2100     |\n",
            "| policy_entropy     | 42.8     |\n",
            "| total_timesteps    | 10500    |\n",
            "| value_loss         | 6.52     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0.285    |\n",
            "| fps                | 295      |\n",
            "| nupdates           | 2200     |\n",
            "| policy_entropy     | 42.8     |\n",
            "| total_timesteps    | 11000    |\n",
            "| value_loss         | 0.549    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0        |\n",
            "| fps                | 296      |\n",
            "| nupdates           | 2300     |\n",
            "| policy_entropy     | 42.7     |\n",
            "| total_timesteps    | 11500    |\n",
            "| value_loss         | 1.22     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0.165    |\n",
            "| fps                | 297      |\n",
            "| nupdates           | 2400     |\n",
            "| policy_entropy     | 42.8     |\n",
            "| total_timesteps    | 12000    |\n",
            "| value_loss         | 4.09     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 5.96e-08 |\n",
            "| fps                | 298      |\n",
            "| nupdates           | 2500     |\n",
            "| policy_entropy     | 42.9     |\n",
            "| total_timesteps    | 12500    |\n",
            "| value_loss         | 2.26     |\n",
            "---------------------------------\n",
            "----------------------------------\n",
            "| explained_variance | -1.19e-07 |\n",
            "| fps                | 298       |\n",
            "| nupdates           | 2600      |\n",
            "| policy_entropy     | 42.9      |\n",
            "| total_timesteps    | 13000     |\n",
            "| value_loss         | 2.14      |\n",
            "----------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | -0.258   |\n",
            "| fps                | 299      |\n",
            "| nupdates           | 2700     |\n",
            "| policy_entropy     | 42.9     |\n",
            "| total_timesteps    | 13500    |\n",
            "| value_loss         | 0.0622   |\n",
            "---------------------------------\n",
            "----------------------------------\n",
            "| explained_variance | -1.19e-07 |\n",
            "| fps                | 300       |\n",
            "| nupdates           | 2800      |\n",
            "| policy_entropy     | 42.9      |\n",
            "| total_timesteps    | 14000     |\n",
            "| value_loss         | 3.19      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| explained_variance | -1.19e-07 |\n",
            "| fps                | 300       |\n",
            "| nupdates           | 2900      |\n",
            "| policy_entropy     | 43        |\n",
            "| total_timesteps    | 14500     |\n",
            "| value_loss         | 3.58      |\n",
            "----------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 5.96e-08 |\n",
            "| fps                | 301      |\n",
            "| nupdates           | 3000     |\n",
            "| policy_entropy     | 43       |\n",
            "| total_timesteps    | 15000    |\n",
            "| value_loss         | 57.3     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0.0615   |\n",
            "| fps                | 300      |\n",
            "| nupdates           | 3100     |\n",
            "| policy_entropy     | 43.2     |\n",
            "| total_timesteps    | 15500    |\n",
            "| value_loss         | 0.108    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | -0.0324  |\n",
            "| fps                | 301      |\n",
            "| nupdates           | 3200     |\n",
            "| policy_entropy     | 43.2     |\n",
            "| total_timesteps    | 16000    |\n",
            "| value_loss         | 0.795    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 5.96e-08 |\n",
            "| fps                | 302      |\n",
            "| nupdates           | 3300     |\n",
            "| policy_entropy     | 43.3     |\n",
            "| total_timesteps    | 16500    |\n",
            "| value_loss         | 0.627    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | -0.104   |\n",
            "| fps                | 302      |\n",
            "| nupdates           | 3400     |\n",
            "| policy_entropy     | 43.3     |\n",
            "| total_timesteps    | 17000    |\n",
            "| value_loss         | 7.12     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0        |\n",
            "| fps                | 302      |\n",
            "| nupdates           | 3500     |\n",
            "| policy_entropy     | 43.3     |\n",
            "| total_timesteps    | 17500    |\n",
            "| value_loss         | 1.2      |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0        |\n",
            "| fps                | 303      |\n",
            "| nupdates           | 3600     |\n",
            "| policy_entropy     | 43.3     |\n",
            "| total_timesteps    | 18000    |\n",
            "| value_loss         | 9.79     |\n",
            "---------------------------------\n",
            "----------------------------------\n",
            "| explained_variance | -1.19e-07 |\n",
            "| fps                | 304       |\n",
            "| nupdates           | 3700      |\n",
            "| policy_entropy     | 43.4      |\n",
            "| total_timesteps    | 18500     |\n",
            "| value_loss         | 2.33      |\n",
            "----------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | -0.0285  |\n",
            "| fps                | 304      |\n",
            "| nupdates           | 3800     |\n",
            "| policy_entropy     | 43.4     |\n",
            "| total_timesteps    | 19000    |\n",
            "| value_loss         | 6.49     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0.0582   |\n",
            "| fps                | 304      |\n",
            "| nupdates           | 3900     |\n",
            "| policy_entropy     | 43.5     |\n",
            "| total_timesteps    | 19500    |\n",
            "| value_loss         | 1.64     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0        |\n",
            "| fps                | 304      |\n",
            "| nupdates           | 4000     |\n",
            "| policy_entropy     | 43.5     |\n",
            "| total_timesteps    | 20000    |\n",
            "| value_loss         | 0.582    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0        |\n",
            "| fps                | 304      |\n",
            "| nupdates           | 4100     |\n",
            "| policy_entropy     | 43.5     |\n",
            "| total_timesteps    | 20500    |\n",
            "| value_loss         | 2.16     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0.0184   |\n",
            "| fps                | 304      |\n",
            "| nupdates           | 4200     |\n",
            "| policy_entropy     | 43.5     |\n",
            "| total_timesteps    | 21000    |\n",
            "| value_loss         | 9.05     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0.0234   |\n",
            "| fps                | 305      |\n",
            "| nupdates           | 4300     |\n",
            "| policy_entropy     | 43.5     |\n",
            "| total_timesteps    | 21500    |\n",
            "| value_loss         | 107      |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0        |\n",
            "| fps                | 305      |\n",
            "| nupdates           | 4400     |\n",
            "| policy_entropy     | 43.6     |\n",
            "| total_timesteps    | 22000    |\n",
            "| value_loss         | 10.5     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0        |\n",
            "| fps                | 305      |\n",
            "| nupdates           | 4500     |\n",
            "| policy_entropy     | 43.6     |\n",
            "| total_timesteps    | 22500    |\n",
            "| value_loss         | 15.9     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0        |\n",
            "| fps                | 305      |\n",
            "| nupdates           | 4600     |\n",
            "| policy_entropy     | 43.6     |\n",
            "| total_timesteps    | 23000    |\n",
            "| value_loss         | 2.09     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0        |\n",
            "| fps                | 306      |\n",
            "| nupdates           | 4700     |\n",
            "| policy_entropy     | 43.6     |\n",
            "| total_timesteps    | 23500    |\n",
            "| value_loss         | 2.27     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0        |\n",
            "| fps                | 306      |\n",
            "| nupdates           | 4800     |\n",
            "| policy_entropy     | 43.7     |\n",
            "| total_timesteps    | 24000    |\n",
            "| value_loss         | 0.246    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0.176    |\n",
            "| fps                | 306      |\n",
            "| nupdates           | 4900     |\n",
            "| policy_entropy     | 43.7     |\n",
            "| total_timesteps    | 24500    |\n",
            "| value_loss         | 1.17     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0        |\n",
            "| fps                | 306      |\n",
            "| nupdates           | 5000     |\n",
            "| policy_entropy     | 43.7     |\n",
            "| total_timesteps    | 25000    |\n",
            "| value_loss         | 29       |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0        |\n",
            "| fps                | 306      |\n",
            "| nupdates           | 5100     |\n",
            "| policy_entropy     | 43.8     |\n",
            "| total_timesteps    | 25500    |\n",
            "| value_loss         | 1.46     |\n",
            "---------------------------------\n",
            "----------------------------------\n",
            "| explained_variance | -0.000966 |\n",
            "| fps                | 306       |\n",
            "| nupdates           | 5200      |\n",
            "| policy_entropy     | 43.8      |\n",
            "| total_timesteps    | 26000     |\n",
            "| value_loss         | 6.39      |\n",
            "----------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | -0.033   |\n",
            "| fps                | 306      |\n",
            "| nupdates           | 5300     |\n",
            "| policy_entropy     | 43.8     |\n",
            "| total_timesteps    | 26500    |\n",
            "| value_loss         | 12.4     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | -1.68    |\n",
            "| fps                | 306      |\n",
            "| nupdates           | 5400     |\n",
            "| policy_entropy     | 43.8     |\n",
            "| total_timesteps    | 27000    |\n",
            "| value_loss         | 8.03     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | -0.118   |\n",
            "| fps                | 306      |\n",
            "| nupdates           | 5500     |\n",
            "| policy_entropy     | 43.8     |\n",
            "| total_timesteps    | 27500    |\n",
            "| value_loss         | 2.44     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0        |\n",
            "| fps                | 306      |\n",
            "| nupdates           | 5600     |\n",
            "| policy_entropy     | 43.8     |\n",
            "| total_timesteps    | 28000    |\n",
            "| value_loss         | 20.7     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | -0.12    |\n",
            "| fps                | 306      |\n",
            "| nupdates           | 5700     |\n",
            "| policy_entropy     | 43.8     |\n",
            "| total_timesteps    | 28500    |\n",
            "| value_loss         | 14.2     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0        |\n",
            "| fps                | 306      |\n",
            "| nupdates           | 5800     |\n",
            "| policy_entropy     | 43.8     |\n",
            "| total_timesteps    | 29000    |\n",
            "| value_loss         | 16.2     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0        |\n",
            "| fps                | 306      |\n",
            "| nupdates           | 5900     |\n",
            "| policy_entropy     | 43.9     |\n",
            "| total_timesteps    | 29500    |\n",
            "| value_loss         | 2.37     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 7.75e-07 |\n",
            "| fps                | 306      |\n",
            "| nupdates           | 6000     |\n",
            "| policy_entropy     | 43.9     |\n",
            "| total_timesteps    | 30000    |\n",
            "| value_loss         | 8.86     |\n",
            "---------------------------------\n",
            "Training time (A2C):  1.6419867157936097  minutes\n",
            "======A2C Validation from:  20180801 to  20181030\n",
            "A2C Sharpe Ratio:  -0.1459775820665046\n",
            "======PPO Training========\n",
            "Training time (PPO):  5.609140725930532  minutes\n",
            "======PPO Validation from:  20180801 to  20181030\n",
            "PPO Sharpe Ratio:  -0.20508733778541702\n",
            "======DDPG Training========\n",
            "Training time (DDPG):  1.004341995716095  minutes\n",
            "======DDPG Validation from:  20180801 to  20181030\n",
            "======Trading from:  20181030 to  20190201\n",
            "previous_total_asset:1272523.7901934595\n",
            "end_total_asset:1233372.0671824727\n",
            "total_reward:-39151.72301098681\n",
            "total_cost:  2533.4012081850287\n",
            "total trades:  766\n",
            "Sharpe:  -0.0502066940792075\n",
            "============================================\n",
            "turbulence_threshold:  109.91299670003775\n",
            "======Model training from:  20100000 to  20181030\n",
            "======A2C Training========\n",
            "--------------------------------------\n",
            "| explained_variance      | 0        |\n",
            "| fps                     | 19       |\n",
            "| nupdates                | 1        |\n",
            "| policy_entropy          | 42.6     |\n",
            "| reference_Q_mean        | 3.6      |\n",
            "| reference_Q_std         | 2.29     |\n",
            "| reference_action_mean   | -0.195   |\n",
            "| reference_action_std    | 0.936    |\n",
            "| reference_actor_Q_mean  | 4.44     |\n",
            "| reference_actor_Q_std   | 2.35     |\n",
            "| rollout/Q_mean          | 2.07     |\n",
            "| rollout/actions_mean    | -0.0944  |\n",
            "| rollout/actions_std     | 0.816    |\n",
            "| rollout/episode_steps   | 2.16e+03 |\n",
            "| rollout/episodes        | 4        |\n",
            "| rollout/return          | 280      |\n",
            "| rollout/return_history  | 280      |\n",
            "| total/duration          | 59.5     |\n",
            "| total/episodes          | 4        |\n",
            "| total/epochs            | 1        |\n",
            "| total/steps             | 9998     |\n",
            "| total/steps_per_second  | 168      |\n",
            "| total_timesteps         | 5        |\n",
            "| train/loss_actor        | -4.14    |\n",
            "| train/loss_critic       | 1.5      |\n",
            "| train/param_noise_di... | 0        |\n",
            "| value_loss              | 0.00114  |\n",
            "--------------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0.0793   |\n",
            "| fps                | 242      |\n",
            "| nupdates           | 100      |\n",
            "| policy_entropy     | 42.6     |\n",
            "| total_timesteps    | 500      |\n",
            "| value_loss         | 4.76     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | -0.112   |\n",
            "| fps                | 258      |\n",
            "| nupdates           | 200      |\n",
            "| policy_entropy     | 42.6     |\n",
            "| total_timesteps    | 1000     |\n",
            "| value_loss         | 6.19     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | -0.0311  |\n",
            "| fps                | 266      |\n",
            "| nupdates           | 300      |\n",
            "| policy_entropy     | 42.6     |\n",
            "| total_timesteps    | 1500     |\n",
            "| value_loss         | 2.51     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0.00823  |\n",
            "| fps                | 270      |\n",
            "| nupdates           | 400      |\n",
            "| policy_entropy     | 42.6     |\n",
            "| total_timesteps    | 2000     |\n",
            "| value_loss         | 21.2     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0.191    |\n",
            "| fps                | 268      |\n",
            "| nupdates           | 500      |\n",
            "| policy_entropy     | 42.6     |\n",
            "| total_timesteps    | 2500     |\n",
            "| value_loss         | 1.38     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | -0.0672  |\n",
            "| fps                | 269      |\n",
            "| nupdates           | 600      |\n",
            "| policy_entropy     | 42.6     |\n",
            "| total_timesteps    | 3000     |\n",
            "| value_loss         | 1.31     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | -0.243   |\n",
            "| fps                | 271      |\n",
            "| nupdates           | 700      |\n",
            "| policy_entropy     | 42.6     |\n",
            "| total_timesteps    | 3500     |\n",
            "| value_loss         | 3.81     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | -0.805   |\n",
            "| fps                | 273      |\n",
            "| nupdates           | 800      |\n",
            "| policy_entropy     | 42.6     |\n",
            "| total_timesteps    | 4000     |\n",
            "| value_loss         | 0.433    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0        |\n",
            "| fps                | 272      |\n",
            "| nupdates           | 900      |\n",
            "| policy_entropy     | 42.6     |\n",
            "| total_timesteps    | 4500     |\n",
            "| value_loss         | 0.048    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | -0.479   |\n",
            "| fps                | 273      |\n",
            "| nupdates           | 1000     |\n",
            "| policy_entropy     | 42.6     |\n",
            "| total_timesteps    | 5000     |\n",
            "| value_loss         | 1.69     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0.391    |\n",
            "| fps                | 274      |\n",
            "| nupdates           | 1100     |\n",
            "| policy_entropy     | 42.7     |\n",
            "| total_timesteps    | 5500     |\n",
            "| value_loss         | 2.69     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0        |\n",
            "| fps                | 276      |\n",
            "| nupdates           | 1200     |\n",
            "| policy_entropy     | 42.7     |\n",
            "| total_timesteps    | 6000     |\n",
            "| value_loss         | 4.05     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | -0.135   |\n",
            "| fps                | 278      |\n",
            "| nupdates           | 1300     |\n",
            "| policy_entropy     | 42.7     |\n",
            "| total_timesteps    | 6500     |\n",
            "| value_loss         | 10.8     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0.0431   |\n",
            "| fps                | 277      |\n",
            "| nupdates           | 1400     |\n",
            "| policy_entropy     | 42.7     |\n",
            "| total_timesteps    | 7000     |\n",
            "| value_loss         | 3.64     |\n",
            "---------------------------------\n",
            "----------------------------------\n",
            "| explained_variance | -1.19e-07 |\n",
            "| fps                | 277       |\n",
            "| nupdates           | 1500      |\n",
            "| policy_entropy     | 42.7      |\n",
            "| total_timesteps    | 7500      |\n",
            "| value_loss         | 1.28      |\n",
            "----------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0        |\n",
            "| fps                | 279      |\n",
            "| nupdates           | 1600     |\n",
            "| policy_entropy     | 42.7     |\n",
            "| total_timesteps    | 8000     |\n",
            "| value_loss         | 2.28     |\n",
            "---------------------------------\n",
            "----------------------------------\n",
            "| explained_variance | -1.19e-07 |\n",
            "| fps                | 280       |\n",
            "| nupdates           | 1700      |\n",
            "| policy_entropy     | 42.8      |\n",
            "| total_timesteps    | 8500      |\n",
            "| value_loss         | 3.54      |\n",
            "----------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | -0.465   |\n",
            "| fps                | 280      |\n",
            "| nupdates           | 1800     |\n",
            "| policy_entropy     | 42.8     |\n",
            "| total_timesteps    | 9000     |\n",
            "| value_loss         | 3.31     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0.278    |\n",
            "| fps                | 281      |\n",
            "| nupdates           | 1900     |\n",
            "| policy_entropy     | 42.9     |\n",
            "| total_timesteps    | 9500     |\n",
            "| value_loss         | 2.79     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | -0.181   |\n",
            "| fps                | 281      |\n",
            "| nupdates           | 2000     |\n",
            "| policy_entropy     | 42.9     |\n",
            "| total_timesteps    | 10000    |\n",
            "| value_loss         | 3.51     |\n",
            "---------------------------------\n",
            "----------------------------------\n",
            "| explained_variance | -1.19e-07 |\n",
            "| fps                | 282       |\n",
            "| nupdates           | 2100      |\n",
            "| policy_entropy     | 42.8      |\n",
            "| total_timesteps    | 10500     |\n",
            "| value_loss         | 1.46      |\n",
            "----------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | -0.0166  |\n",
            "| fps                | 283      |\n",
            "| nupdates           | 2200     |\n",
            "| policy_entropy     | 42.9     |\n",
            "| total_timesteps    | 11000    |\n",
            "| value_loss         | 0.751    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0.547    |\n",
            "| fps                | 283      |\n",
            "| nupdates           | 2300     |\n",
            "| policy_entropy     | 43       |\n",
            "| total_timesteps    | 11500    |\n",
            "| value_loss         | 1.69     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0        |\n",
            "| fps                | 283      |\n",
            "| nupdates           | 2400     |\n",
            "| policy_entropy     | 42.9     |\n",
            "| total_timesteps    | 12000    |\n",
            "| value_loss         | 1.22     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | -0.00267 |\n",
            "| fps                | 284      |\n",
            "| nupdates           | 2500     |\n",
            "| policy_entropy     | 42.9     |\n",
            "| total_timesteps    | 12500    |\n",
            "| value_loss         | 9.65     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0        |\n",
            "| fps                | 284      |\n",
            "| nupdates           | 2600     |\n",
            "| policy_entropy     | 43       |\n",
            "| total_timesteps    | 13000    |\n",
            "| value_loss         | 0.648    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0.117    |\n",
            "| fps                | 284      |\n",
            "| nupdates           | 2700     |\n",
            "| policy_entropy     | 43       |\n",
            "| total_timesteps    | 13500    |\n",
            "| value_loss         | 6.51     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0.132    |\n",
            "| fps                | 283      |\n",
            "| nupdates           | 2800     |\n",
            "| policy_entropy     | 43.1     |\n",
            "| total_timesteps    | 14000    |\n",
            "| value_loss         | 0.321    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | -0.262   |\n",
            "| fps                | 284      |\n",
            "| nupdates           | 2900     |\n",
            "| policy_entropy     | 43.1     |\n",
            "| total_timesteps    | 14500    |\n",
            "| value_loss         | 0.647    |\n",
            "---------------------------------\n",
            "----------------------------------\n",
            "| explained_variance | -1.19e-07 |\n",
            "| fps                | 284       |\n",
            "| nupdates           | 3000      |\n",
            "| policy_entropy     | 43.1      |\n",
            "| total_timesteps    | 15000     |\n",
            "| value_loss         | 0.338     |\n",
            "----------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0.0341   |\n",
            "| fps                | 285      |\n",
            "| nupdates           | 3100     |\n",
            "| policy_entropy     | 43.1     |\n",
            "| total_timesteps    | 15500    |\n",
            "| value_loss         | 1.99     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0.278    |\n",
            "| fps                | 283      |\n",
            "| nupdates           | 3200     |\n",
            "| policy_entropy     | 43.2     |\n",
            "| total_timesteps    | 16000    |\n",
            "| value_loss         | 16.1     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | -0.319   |\n",
            "| fps                | 283      |\n",
            "| nupdates           | 3300     |\n",
            "| policy_entropy     | 43.3     |\n",
            "| total_timesteps    | 16500    |\n",
            "| value_loss         | 11.2     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0        |\n",
            "| fps                | 284      |\n",
            "| nupdates           | 3400     |\n",
            "| policy_entropy     | 43.3     |\n",
            "| total_timesteps    | 17000    |\n",
            "| value_loss         | 4.81     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0        |\n",
            "| fps                | 284      |\n",
            "| nupdates           | 3500     |\n",
            "| policy_entropy     | 43.2     |\n",
            "| total_timesteps    | 17500    |\n",
            "| value_loss         | 9.72     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | -0.119   |\n",
            "| fps                | 284      |\n",
            "| nupdates           | 3600     |\n",
            "| policy_entropy     | 43.2     |\n",
            "| total_timesteps    | 18000    |\n",
            "| value_loss         | 0.831    |\n",
            "---------------------------------\n",
            "----------------------------------\n",
            "| explained_variance | -1.19e-07 |\n",
            "| fps                | 285       |\n",
            "| nupdates           | 3700      |\n",
            "| policy_entropy     | 43.2      |\n",
            "| total_timesteps    | 18500     |\n",
            "| value_loss         | 4.91      |\n",
            "----------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0.0212   |\n",
            "| fps                | 285      |\n",
            "| nupdates           | 3800     |\n",
            "| policy_entropy     | 43.2     |\n",
            "| total_timesteps    | 19000    |\n",
            "| value_loss         | 0.375    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0        |\n",
            "| fps                | 286      |\n",
            "| nupdates           | 3900     |\n",
            "| policy_entropy     | 43.2     |\n",
            "| total_timesteps    | 19500    |\n",
            "| value_loss         | 7.89     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | -0.615   |\n",
            "| fps                | 286      |\n",
            "| nupdates           | 4000     |\n",
            "| policy_entropy     | 43.2     |\n",
            "| total_timesteps    | 20000    |\n",
            "| value_loss         | 137      |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0.498    |\n",
            "| fps                | 286      |\n",
            "| nupdates           | 4100     |\n",
            "| policy_entropy     | 43.2     |\n",
            "| total_timesteps    | 20500    |\n",
            "| value_loss         | 0.499    |\n",
            "---------------------------------\n",
            "----------------------------------\n",
            "| explained_variance | -1.19e-07 |\n",
            "| fps                | 286       |\n",
            "| nupdates           | 4200      |\n",
            "| policy_entropy     | 43.2      |\n",
            "| total_timesteps    | 21000     |\n",
            "| value_loss         | 5.24      |\n",
            "----------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | -0.28    |\n",
            "| fps                | 287      |\n",
            "| nupdates           | 4300     |\n",
            "| policy_entropy     | 43.2     |\n",
            "| total_timesteps    | 21500    |\n",
            "| value_loss         | 10.3     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | -0.0444  |\n",
            "| fps                | 287      |\n",
            "| nupdates           | 4400     |\n",
            "| policy_entropy     | 43.2     |\n",
            "| total_timesteps    | 22000    |\n",
            "| value_loss         | 0.884    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0.0172   |\n",
            "| fps                | 287      |\n",
            "| nupdates           | 4500     |\n",
            "| policy_entropy     | 43.3     |\n",
            "| total_timesteps    | 22500    |\n",
            "| value_loss         | 0.357    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | -2.36    |\n",
            "| fps                | 287      |\n",
            "| nupdates           | 4600     |\n",
            "| policy_entropy     | 43.3     |\n",
            "| total_timesteps    | 23000    |\n",
            "| value_loss         | 0.999    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | -0.0489  |\n",
            "| fps                | 287      |\n",
            "| nupdates           | 4700     |\n",
            "| policy_entropy     | 43.3     |\n",
            "| total_timesteps    | 23500    |\n",
            "| value_loss         | 38.5     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0.388    |\n",
            "| fps                | 287      |\n",
            "| nupdates           | 4800     |\n",
            "| policy_entropy     | 43.3     |\n",
            "| total_timesteps    | 24000    |\n",
            "| value_loss         | 5.81     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | -4.59    |\n",
            "| fps                | 287      |\n",
            "| nupdates           | 4900     |\n",
            "| policy_entropy     | 43.4     |\n",
            "| total_timesteps    | 24500    |\n",
            "| value_loss         | 0.525    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | -0.272   |\n",
            "| fps                | 287      |\n",
            "| nupdates           | 5000     |\n",
            "| policy_entropy     | 43.5     |\n",
            "| total_timesteps    | 25000    |\n",
            "| value_loss         | 0.915    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0.101    |\n",
            "| fps                | 287      |\n",
            "| nupdates           | 5100     |\n",
            "| policy_entropy     | 43.6     |\n",
            "| total_timesteps    | 25500    |\n",
            "| value_loss         | 1.71     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0        |\n",
            "| fps                | 287      |\n",
            "| nupdates           | 5200     |\n",
            "| policy_entropy     | 43.5     |\n",
            "| total_timesteps    | 26000    |\n",
            "| value_loss         | 3.29     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0        |\n",
            "| fps                | 287      |\n",
            "| nupdates           | 5300     |\n",
            "| policy_entropy     | 43.6     |\n",
            "| total_timesteps    | 26500    |\n",
            "| value_loss         | 6.34     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | -0.0917  |\n",
            "| fps                | 287      |\n",
            "| nupdates           | 5400     |\n",
            "| policy_entropy     | 43.6     |\n",
            "| total_timesteps    | 27000    |\n",
            "| value_loss         | 3.65     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | -1.32    |\n",
            "| fps                | 287      |\n",
            "| nupdates           | 5500     |\n",
            "| policy_entropy     | 43.5     |\n",
            "| total_timesteps    | 27500    |\n",
            "| value_loss         | 8.9      |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0.0317   |\n",
            "| fps                | 287      |\n",
            "| nupdates           | 5600     |\n",
            "| policy_entropy     | 43.6     |\n",
            "| total_timesteps    | 28000    |\n",
            "| value_loss         | 1.77     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0        |\n",
            "| fps                | 287      |\n",
            "| nupdates           | 5700     |\n",
            "| policy_entropy     | 43.7     |\n",
            "| total_timesteps    | 28500    |\n",
            "| value_loss         | 5.29     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0.0159   |\n",
            "| fps                | 287      |\n",
            "| nupdates           | 5800     |\n",
            "| policy_entropy     | 43.7     |\n",
            "| total_timesteps    | 29000    |\n",
            "| value_loss         | 2.71     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | -0.177   |\n",
            "| fps                | 287      |\n",
            "| nupdates           | 5900     |\n",
            "| policy_entropy     | 43.7     |\n",
            "| total_timesteps    | 29500    |\n",
            "| value_loss         | 6.98     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0        |\n",
            "| fps                | 288      |\n",
            "| nupdates           | 6000     |\n",
            "| policy_entropy     | 43.7     |\n",
            "| total_timesteps    | 30000    |\n",
            "| value_loss         | 3.29     |\n",
            "---------------------------------\n",
            "Training time (A2C):  1.7474629481633503  minutes\n",
            "======A2C Validation from:  20181030 to  20190201\n",
            "A2C Sharpe Ratio:  0.14333259215691838\n",
            "======PPO Training========\n",
            "Training time (PPO):  5.82538492679596  minutes\n",
            "======PPO Validation from:  20181030 to  20190201\n",
            "PPO Sharpe Ratio:  0.10422858803981103\n",
            "======DDPG Training========\n",
            "Training time (DDPG):  1.0382536371548972  minutes\n",
            "======DDPG Validation from:  20181030 to  20190201\n",
            "======Trading from:  20190201 to  20190503\n",
            "previous_total_asset:1233372.0671824727\n",
            "end_total_asset:1258683.3584546004\n",
            "total_reward:25311.291272127768\n",
            "total_cost:  2679.762168792051\n",
            "total trades:  407\n",
            "Sharpe:  0.3036730173595381\n",
            "============================================\n",
            "turbulence_threshold:  109.91299670003775\n",
            "======Model training from:  20100000 to  20190201\n",
            "======A2C Training========\n",
            "--------------------------------------\n",
            "| explained_variance      | 0        |\n",
            "| fps                     | 18       |\n",
            "| nupdates                | 1        |\n",
            "| policy_entropy          | 42.6     |\n",
            "| reference_Q_mean        | 2.24     |\n",
            "| reference_Q_std         | 2.46     |\n",
            "| reference_action_mean   | 0.0677   |\n",
            "| reference_action_std    | 0.973    |\n",
            "| reference_actor_Q_mean  | 2.9      |\n",
            "| reference_actor_Q_std   | 2.54     |\n",
            "| rollout/Q_mean          | 1.44     |\n",
            "| rollout/actions_mean    | 0.107    |\n",
            "| rollout/actions_std     | 0.803    |\n",
            "| rollout/episode_steps   | 2.22e+03 |\n",
            "| rollout/episodes        | 4        |\n",
            "| rollout/return          | 133      |\n",
            "| rollout/return_history  | 133      |\n",
            "| total/duration          | 61.5     |\n",
            "| total/episodes          | 4        |\n",
            "| total/epochs            | 1        |\n",
            "| total/steps             | 9998     |\n",
            "| total/steps_per_second  | 163      |\n",
            "| total_timesteps         | 5        |\n",
            "| train/loss_actor        | -2.82    |\n",
            "| train/loss_critic       | 0.943    |\n",
            "| train/param_noise_di... | 0        |\n",
            "| value_loss              | 0.00971  |\n",
            "--------------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0.0358   |\n",
            "| fps                | 253      |\n",
            "| nupdates           | 100      |\n",
            "| policy_entropy     | 42.6     |\n",
            "| total_timesteps    | 500      |\n",
            "| value_loss         | 7.62     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0.587    |\n",
            "| fps                | 272      |\n",
            "| nupdates           | 200      |\n",
            "| policy_entropy     | 42.6     |\n",
            "| total_timesteps    | 1000     |\n",
            "| value_loss         | 6.1      |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | -0.0493  |\n",
            "| fps                | 280      |\n",
            "| nupdates           | 300      |\n",
            "| policy_entropy     | 42.6     |\n",
            "| total_timesteps    | 1500     |\n",
            "| value_loss         | 4.16     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0.353    |\n",
            "| fps                | 285      |\n",
            "| nupdates           | 400      |\n",
            "| policy_entropy     | 42.6     |\n",
            "| total_timesteps    | 2000     |\n",
            "| value_loss         | 12.9     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0        |\n",
            "| fps                | 281      |\n",
            "| nupdates           | 500      |\n",
            "| policy_entropy     | 42.6     |\n",
            "| total_timesteps    | 2500     |\n",
            "| value_loss         | 0.487    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | -0.146   |\n",
            "| fps                | 278      |\n",
            "| nupdates           | 600      |\n",
            "| policy_entropy     | 42.6     |\n",
            "| total_timesteps    | 3000     |\n",
            "| value_loss         | 0.45     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | -0.58    |\n",
            "| fps                | 278      |\n",
            "| nupdates           | 700      |\n",
            "| policy_entropy     | 42.6     |\n",
            "| total_timesteps    | 3500     |\n",
            "| value_loss         | 7.17     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | -0.386   |\n",
            "| fps                | 278      |\n",
            "| nupdates           | 800      |\n",
            "| policy_entropy     | 42.6     |\n",
            "| total_timesteps    | 4000     |\n",
            "| value_loss         | 4.28     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | -0.29    |\n",
            "| fps                | 279      |\n",
            "| nupdates           | 900      |\n",
            "| policy_entropy     | 42.6     |\n",
            "| total_timesteps    | 4500     |\n",
            "| value_loss         | 9.16     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | -0.17    |\n",
            "| fps                | 278      |\n",
            "| nupdates           | 1000     |\n",
            "| policy_entropy     | 42.6     |\n",
            "| total_timesteps    | 5000     |\n",
            "| value_loss         | 19.4     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | -0.0366  |\n",
            "| fps                | 279      |\n",
            "| nupdates           | 1100     |\n",
            "| policy_entropy     | 42.6     |\n",
            "| total_timesteps    | 5500     |\n",
            "| value_loss         | 3.98     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0.0331   |\n",
            "| fps                | 280      |\n",
            "| nupdates           | 1200     |\n",
            "| policy_entropy     | 42.7     |\n",
            "| total_timesteps    | 6000     |\n",
            "| value_loss         | 3.05     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0.384    |\n",
            "| fps                | 281      |\n",
            "| nupdates           | 1300     |\n",
            "| policy_entropy     | 42.7     |\n",
            "| total_timesteps    | 6500     |\n",
            "| value_loss         | 0.0443   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | -0.369   |\n",
            "| fps                | 280      |\n",
            "| nupdates           | 1400     |\n",
            "| policy_entropy     | 42.7     |\n",
            "| total_timesteps    | 7000     |\n",
            "| value_loss         | 1.2      |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | -0.278   |\n",
            "| fps                | 281      |\n",
            "| nupdates           | 1500     |\n",
            "| policy_entropy     | 42.7     |\n",
            "| total_timesteps    | 7500     |\n",
            "| value_loss         | 1.75     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | -0.0383  |\n",
            "| fps                | 282      |\n",
            "| nupdates           | 1600     |\n",
            "| policy_entropy     | 42.8     |\n",
            "| total_timesteps    | 8000     |\n",
            "| value_loss         | 5.97     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | -0.16    |\n",
            "| fps                | 282      |\n",
            "| nupdates           | 1700     |\n",
            "| policy_entropy     | 42.7     |\n",
            "| total_timesteps    | 8500     |\n",
            "| value_loss         | 6.4      |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | -0.0378  |\n",
            "| fps                | 283      |\n",
            "| nupdates           | 1800     |\n",
            "| policy_entropy     | 42.8     |\n",
            "| total_timesteps    | 9000     |\n",
            "| value_loss         | 14.1     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | -0.0057  |\n",
            "| fps                | 283      |\n",
            "| nupdates           | 1900     |\n",
            "| policy_entropy     | 42.8     |\n",
            "| total_timesteps    | 9500     |\n",
            "| value_loss         | 1.84     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | -0.0479  |\n",
            "| fps                | 284      |\n",
            "| nupdates           | 2000     |\n",
            "| policy_entropy     | 42.9     |\n",
            "| total_timesteps    | 10000    |\n",
            "| value_loss         | 7.38     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0.0484   |\n",
            "| fps                | 285      |\n",
            "| nupdates           | 2100     |\n",
            "| policy_entropy     | 42.9     |\n",
            "| total_timesteps    | 10500    |\n",
            "| value_loss         | 2.63     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0.0228   |\n",
            "| fps                | 285      |\n",
            "| nupdates           | 2200     |\n",
            "| policy_entropy     | 42.9     |\n",
            "| total_timesteps    | 11000    |\n",
            "| value_loss         | 2.51     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | -1.26    |\n",
            "| fps                | 285      |\n",
            "| nupdates           | 2300     |\n",
            "| policy_entropy     | 42.9     |\n",
            "| total_timesteps    | 11500    |\n",
            "| value_loss         | 0.351    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0.497    |\n",
            "| fps                | 285      |\n",
            "| nupdates           | 2400     |\n",
            "| policy_entropy     | 42.9     |\n",
            "| total_timesteps    | 12000    |\n",
            "| value_loss         | 0.529    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0        |\n",
            "| fps                | 286      |\n",
            "| nupdates           | 2500     |\n",
            "| policy_entropy     | 43       |\n",
            "| total_timesteps    | 12500    |\n",
            "| value_loss         | 1.14     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0.218    |\n",
            "| fps                | 286      |\n",
            "| nupdates           | 2600     |\n",
            "| policy_entropy     | 43       |\n",
            "| total_timesteps    | 13000    |\n",
            "| value_loss         | 0.637    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | -0.0797  |\n",
            "| fps                | 286      |\n",
            "| nupdates           | 2700     |\n",
            "| policy_entropy     | 43.1     |\n",
            "| total_timesteps    | 13500    |\n",
            "| value_loss         | 9.35     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 1.19e-07 |\n",
            "| fps                | 286      |\n",
            "| nupdates           | 2800     |\n",
            "| policy_entropy     | 43.1     |\n",
            "| total_timesteps    | 14000    |\n",
            "| value_loss         | 4.81     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | -0.0671  |\n",
            "| fps                | 286      |\n",
            "| nupdates           | 2900     |\n",
            "| policy_entropy     | 43.2     |\n",
            "| total_timesteps    | 14500    |\n",
            "| value_loss         | 21.3     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 5.96e-08 |\n",
            "| fps                | 287      |\n",
            "| nupdates           | 3000     |\n",
            "| policy_entropy     | 43.2     |\n",
            "| total_timesteps    | 15000    |\n",
            "| value_loss         | 12.1     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 4.17e-07 |\n",
            "| fps                | 287      |\n",
            "| nupdates           | 3100     |\n",
            "| policy_entropy     | 43.2     |\n",
            "| total_timesteps    | 15500    |\n",
            "| value_loss         | 4.46     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0        |\n",
            "| fps                | 286      |\n",
            "| nupdates           | 3200     |\n",
            "| policy_entropy     | 43.2     |\n",
            "| total_timesteps    | 16000    |\n",
            "| value_loss         | 0.00696  |\n",
            "---------------------------------\n",
            "----------------------------------\n",
            "| explained_variance | -1.19e-07 |\n",
            "| fps                | 286       |\n",
            "| nupdates           | 3300      |\n",
            "| policy_entropy     | 43.2      |\n",
            "| total_timesteps    | 16500     |\n",
            "| value_loss         | 3.45      |\n",
            "----------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0.061    |\n",
            "| fps                | 287      |\n",
            "| nupdates           | 3400     |\n",
            "| policy_entropy     | 43.2     |\n",
            "| total_timesteps    | 17000    |\n",
            "| value_loss         | 5.13     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0.021    |\n",
            "| fps                | 287      |\n",
            "| nupdates           | 3500     |\n",
            "| policy_entropy     | 43.3     |\n",
            "| total_timesteps    | 17500    |\n",
            "| value_loss         | 21       |\n",
            "---------------------------------\n",
            "----------------------------------\n",
            "| explained_variance | -1.19e-07 |\n",
            "| fps                | 287       |\n",
            "| nupdates           | 3600      |\n",
            "| policy_entropy     | 43.3      |\n",
            "| total_timesteps    | 18000     |\n",
            "| value_loss         | 11.5      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| explained_variance | -2.38e-07 |\n",
            "| fps                | 286       |\n",
            "| nupdates           | 3700      |\n",
            "| policy_entropy     | 43.3      |\n",
            "| total_timesteps    | 18500     |\n",
            "| value_loss         | 11.1      |\n",
            "----------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 1.19e-07 |\n",
            "| fps                | 287      |\n",
            "| nupdates           | 3800     |\n",
            "| policy_entropy     | 43.3     |\n",
            "| total_timesteps    | 19000    |\n",
            "| value_loss         | 2.01     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0        |\n",
            "| fps                | 287      |\n",
            "| nupdates           | 3900     |\n",
            "| policy_entropy     | 43.2     |\n",
            "| total_timesteps    | 19500    |\n",
            "| value_loss         | 53.5     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | -0.00285 |\n",
            "| fps                | 287      |\n",
            "| nupdates           | 4000     |\n",
            "| policy_entropy     | 43.3     |\n",
            "| total_timesteps    | 20000    |\n",
            "| value_loss         | 4.82     |\n",
            "---------------------------------\n",
            "----------------------------------\n",
            "| explained_variance | -1.19e-07 |\n",
            "| fps                | 288       |\n",
            "| nupdates           | 4100      |\n",
            "| policy_entropy     | 43.3      |\n",
            "| total_timesteps    | 20500     |\n",
            "| value_loss         | 54.7      |\n",
            "----------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | -0.095   |\n",
            "| fps                | 288      |\n",
            "| nupdates           | 4200     |\n",
            "| policy_entropy     | 43.2     |\n",
            "| total_timesteps    | 21000    |\n",
            "| value_loss         | 38.1     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0        |\n",
            "| fps                | 288      |\n",
            "| nupdates           | 4300     |\n",
            "| policy_entropy     | 43.3     |\n",
            "| total_timesteps    | 21500    |\n",
            "| value_loss         | 3.64     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | -0.0641  |\n",
            "| fps                | 288      |\n",
            "| nupdates           | 4400     |\n",
            "| policy_entropy     | 43.2     |\n",
            "| total_timesteps    | 22000    |\n",
            "| value_loss         | 13       |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0        |\n",
            "| fps                | 288      |\n",
            "| nupdates           | 4500     |\n",
            "| policy_entropy     | 43.2     |\n",
            "| total_timesteps    | 22500    |\n",
            "| value_loss         | 5.07     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0.473    |\n",
            "| fps                | 288      |\n",
            "| nupdates           | 4600     |\n",
            "| policy_entropy     | 43.2     |\n",
            "| total_timesteps    | 23000    |\n",
            "| value_loss         | 0.286    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | -0.379   |\n",
            "| fps                | 289      |\n",
            "| nupdates           | 4700     |\n",
            "| policy_entropy     | 43.2     |\n",
            "| total_timesteps    | 23500    |\n",
            "| value_loss         | 5.34     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0        |\n",
            "| fps                | 289      |\n",
            "| nupdates           | 4800     |\n",
            "| policy_entropy     | 43.2     |\n",
            "| total_timesteps    | 24000    |\n",
            "| value_loss         | 1.96     |\n",
            "---------------------------------\n",
            "----------------------------------\n",
            "| explained_variance | -1.19e-07 |\n",
            "| fps                | 289       |\n",
            "| nupdates           | 4900      |\n",
            "| policy_entropy     | 43.2      |\n",
            "| total_timesteps    | 24500     |\n",
            "| value_loss         | 1.77      |\n",
            "----------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0        |\n",
            "| fps                | 290      |\n",
            "| nupdates           | 5000     |\n",
            "| policy_entropy     | 43.3     |\n",
            "| total_timesteps    | 25000    |\n",
            "| value_loss         | 9.46     |\n",
            "---------------------------------\n",
            "----------------------------------\n",
            "| explained_variance | -0.000412 |\n",
            "| fps                | 289       |\n",
            "| nupdates           | 5100      |\n",
            "| policy_entropy     | 43.3      |\n",
            "| total_timesteps    | 25500     |\n",
            "| value_loss         | 8.33      |\n",
            "----------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 1.79e-07 |\n",
            "| fps                | 289      |\n",
            "| nupdates           | 5200     |\n",
            "| policy_entropy     | 43.4     |\n",
            "| total_timesteps    | 26000    |\n",
            "| value_loss         | 4.24     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 5.96e-08 |\n",
            "| fps                | 289      |\n",
            "| nupdates           | 5300     |\n",
            "| policy_entropy     | 43.4     |\n",
            "| total_timesteps    | 26500    |\n",
            "| value_loss         | 18.8     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 1.19e-07 |\n",
            "| fps                | 289      |\n",
            "| nupdates           | 5400     |\n",
            "| policy_entropy     | 43.5     |\n",
            "| total_timesteps    | 27000    |\n",
            "| value_loss         | 9.22     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0.0487   |\n",
            "| fps                | 289      |\n",
            "| nupdates           | 5500     |\n",
            "| policy_entropy     | 43.5     |\n",
            "| total_timesteps    | 27500    |\n",
            "| value_loss         | 0.94     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 2.68e-06 |\n",
            "| fps                | 289      |\n",
            "| nupdates           | 5600     |\n",
            "| policy_entropy     | 43.5     |\n",
            "| total_timesteps    | 28000    |\n",
            "| value_loss         | 1.08     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0        |\n",
            "| fps                | 289      |\n",
            "| nupdates           | 5700     |\n",
            "| policy_entropy     | 43.4     |\n",
            "| total_timesteps    | 28500    |\n",
            "| value_loss         | 7.64     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0        |\n",
            "| fps                | 290      |\n",
            "| nupdates           | 5800     |\n",
            "| policy_entropy     | 43.4     |\n",
            "| total_timesteps    | 29000    |\n",
            "| value_loss         | 4.12     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0        |\n",
            "| fps                | 290      |\n",
            "| nupdates           | 5900     |\n",
            "| policy_entropy     | 43.4     |\n",
            "| total_timesteps    | 29500    |\n",
            "| value_loss         | 64.8     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0        |\n",
            "| fps                | 290      |\n",
            "| nupdates           | 6000     |\n",
            "| policy_entropy     | 43.4     |\n",
            "| total_timesteps    | 30000    |\n",
            "| value_loss         | 1.37     |\n",
            "---------------------------------\n",
            "Training time (A2C):  1.7385090668996175  minutes\n",
            "======A2C Validation from:  20190201 to  20190503\n",
            "A2C Sharpe Ratio:  0.04230300990240251\n",
            "======PPO Training========\n",
            "Training time (PPO):  5.79539452791214  minutes\n",
            "======PPO Validation from:  20190201 to  20190503\n",
            "PPO Sharpe Ratio:  0.4294786552272316\n",
            "======DDPG Training========\n",
            "Training time (DDPG):  1.0558792193730673  minutes\n",
            "======DDPG Validation from:  20190201 to  20190503\n",
            "======Trading from:  20190503 to  20190802\n",
            "previous_total_asset:1258683.3584546004\n",
            "end_total_asset:1284811.4109282775\n",
            "total_reward:26128.05247367709\n",
            "total_cost:  2567.4440589731535\n",
            "total trades:  631\n",
            "Sharpe:  0.24144321055386497\n",
            "============================================\n",
            "turbulence_threshold:  109.91299670003775\n",
            "======Model training from:  20100000 to  20190503\n",
            "======A2C Training========\n",
            "--------------------------------------\n",
            "| explained_variance      | 0        |\n",
            "| fps                     | 17       |\n",
            "| nupdates                | 1        |\n",
            "| policy_entropy          | 42.6     |\n",
            "| reference_Q_mean        | 2.53     |\n",
            "| reference_Q_std         | 2.26     |\n",
            "| reference_action_mean   | 0.347    |\n",
            "| reference_action_std    | 0.904    |\n",
            "| reference_actor_Q_mean  | 3.28     |\n",
            "| reference_actor_Q_std   | 2.28     |\n",
            "| rollout/Q_mean          | 1.77     |\n",
            "| rollout/actions_mean    | 0.183    |\n",
            "| rollout/actions_std     | 0.793    |\n",
            "| rollout/episode_steps   | 2.28e+03 |\n",
            "| rollout/episodes        | 4        |\n",
            "| rollout/return          | 157      |\n",
            "| rollout/return_history  | 157      |\n",
            "| total/duration          | 62.6     |\n",
            "| total/episodes          | 4        |\n",
            "| total/epochs            | 1        |\n",
            "| total/steps             | 9998     |\n",
            "| total/steps_per_second  | 160      |\n",
            "| total_timesteps         | 5        |\n",
            "| train/loss_actor        | -3.77    |\n",
            "| train/loss_critic       | 0.954    |\n",
            "| train/param_noise_di... | 0        |\n",
            "| value_loss              | 8.75e-05 |\n",
            "--------------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | -0.336   |\n",
            "| fps                | 237      |\n",
            "| nupdates           | 100      |\n",
            "| policy_entropy     | 42.6     |\n",
            "| total_timesteps    | 500      |\n",
            "| value_loss         | 6.46     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0.0258   |\n",
            "| fps                | 259      |\n",
            "| nupdates           | 200      |\n",
            "| policy_entropy     | 42.6     |\n",
            "| total_timesteps    | 1000     |\n",
            "| value_loss         | 6.48     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | -0.00526 |\n",
            "| fps                | 265      |\n",
            "| nupdates           | 300      |\n",
            "| policy_entropy     | 42.6     |\n",
            "| total_timesteps    | 1500     |\n",
            "| value_loss         | 3.82     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0.109    |\n",
            "| fps                | 268      |\n",
            "| nupdates           | 400      |\n",
            "| policy_entropy     | 42.6     |\n",
            "| total_timesteps    | 2000     |\n",
            "| value_loss         | 5.58     |\n",
            "---------------------------------\n",
            "----------------------------------\n",
            "| explained_variance | -1.19e-07 |\n",
            "| fps                | 268       |\n",
            "| nupdates           | 500       |\n",
            "| policy_entropy     | 42.6      |\n",
            "| total_timesteps    | 2500      |\n",
            "| value_loss         | 2.03      |\n",
            "----------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | -0.496   |\n",
            "| fps                | 271      |\n",
            "| nupdates           | 600      |\n",
            "| policy_entropy     | 42.6     |\n",
            "| total_timesteps    | 3000     |\n",
            "| value_loss         | 3.24     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0.075    |\n",
            "| fps                | 273      |\n",
            "| nupdates           | 700      |\n",
            "| policy_entropy     | 42.6     |\n",
            "| total_timesteps    | 3500     |\n",
            "| value_loss         | 21.3     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0.274    |\n",
            "| fps                | 274      |\n",
            "| nupdates           | 800      |\n",
            "| policy_entropy     | 42.6     |\n",
            "| total_timesteps    | 4000     |\n",
            "| value_loss         | 0.485    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0.0778   |\n",
            "| fps                | 275      |\n",
            "| nupdates           | 900      |\n",
            "| policy_entropy     | 42.6     |\n",
            "| total_timesteps    | 4500     |\n",
            "| value_loss         | 2.16     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0.129    |\n",
            "| fps                | 274      |\n",
            "| nupdates           | 1000     |\n",
            "| policy_entropy     | 42.6     |\n",
            "| total_timesteps    | 5000     |\n",
            "| value_loss         | 2.8      |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | -0.487   |\n",
            "| fps                | 276      |\n",
            "| nupdates           | 1100     |\n",
            "| policy_entropy     | 42.6     |\n",
            "| total_timesteps    | 5500     |\n",
            "| value_loss         | 2.32     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0.153    |\n",
            "| fps                | 277      |\n",
            "| nupdates           | 1200     |\n",
            "| policy_entropy     | 42.6     |\n",
            "| total_timesteps    | 6000     |\n",
            "| value_loss         | 11.5     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 1.19e-07 |\n",
            "| fps                | 278      |\n",
            "| nupdates           | 1300     |\n",
            "| policy_entropy     | 42.7     |\n",
            "| total_timesteps    | 6500     |\n",
            "| value_loss         | 1.06     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0.146    |\n",
            "| fps                | 279      |\n",
            "| nupdates           | 1400     |\n",
            "| policy_entropy     | 42.7     |\n",
            "| total_timesteps    | 7000     |\n",
            "| value_loss         | 2.52     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0.00133  |\n",
            "| fps                | 279      |\n",
            "| nupdates           | 1500     |\n",
            "| policy_entropy     | 42.7     |\n",
            "| total_timesteps    | 7500     |\n",
            "| value_loss         | 13.1     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0        |\n",
            "| fps                | 281      |\n",
            "| nupdates           | 1600     |\n",
            "| policy_entropy     | 42.7     |\n",
            "| total_timesteps    | 8000     |\n",
            "| value_loss         | 0.841    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | -0.0142  |\n",
            "| fps                | 282      |\n",
            "| nupdates           | 1700     |\n",
            "| policy_entropy     | 42.8     |\n",
            "| total_timesteps    | 8500     |\n",
            "| value_loss         | 2.1      |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0.226    |\n",
            "| fps                | 283      |\n",
            "| nupdates           | 1800     |\n",
            "| policy_entropy     | 42.7     |\n",
            "| total_timesteps    | 9000     |\n",
            "| value_loss         | 0.108    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | -0.0901  |\n",
            "| fps                | 283      |\n",
            "| nupdates           | 1900     |\n",
            "| policy_entropy     | 42.8     |\n",
            "| total_timesteps    | 9500     |\n",
            "| value_loss         | 6.15     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0.0311   |\n",
            "| fps                | 284      |\n",
            "| nupdates           | 2000     |\n",
            "| policy_entropy     | 42.8     |\n",
            "| total_timesteps    | 10000    |\n",
            "| value_loss         | 12.2     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0.0451   |\n",
            "| fps                | 285      |\n",
            "| nupdates           | 2100     |\n",
            "| policy_entropy     | 42.9     |\n",
            "| total_timesteps    | 10500    |\n",
            "| value_loss         | 0.27     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0.00233  |\n",
            "| fps                | 286      |\n",
            "| nupdates           | 2200     |\n",
            "| policy_entropy     | 42.9     |\n",
            "| total_timesteps    | 11000    |\n",
            "| value_loss         | 1.8      |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0.0317   |\n",
            "| fps                | 287      |\n",
            "| nupdates           | 2300     |\n",
            "| policy_entropy     | 42.9     |\n",
            "| total_timesteps    | 11500    |\n",
            "| value_loss         | 5.95     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0.242    |\n",
            "| fps                | 286      |\n",
            "| nupdates           | 2400     |\n",
            "| policy_entropy     | 43       |\n",
            "| total_timesteps    | 12000    |\n",
            "| value_loss         | 0.92     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0        |\n",
            "| fps                | 287      |\n",
            "| nupdates           | 2500     |\n",
            "| policy_entropy     | 43       |\n",
            "| total_timesteps    | 12500    |\n",
            "| value_loss         | 0.409    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0        |\n",
            "| fps                | 288      |\n",
            "| nupdates           | 2600     |\n",
            "| policy_entropy     | 43       |\n",
            "| total_timesteps    | 13000    |\n",
            "| value_loss         | 11.9     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0        |\n",
            "| fps                | 288      |\n",
            "| nupdates           | 2700     |\n",
            "| policy_entropy     | 43       |\n",
            "| total_timesteps    | 13500    |\n",
            "| value_loss         | 0.342    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0        |\n",
            "| fps                | 288      |\n",
            "| nupdates           | 2800     |\n",
            "| policy_entropy     | 43.1     |\n",
            "| total_timesteps    | 14000    |\n",
            "| value_loss         | 30.6     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0        |\n",
            "| fps                | 288      |\n",
            "| nupdates           | 2900     |\n",
            "| policy_entropy     | 43.1     |\n",
            "| total_timesteps    | 14500    |\n",
            "| value_loss         | 9.27     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0        |\n",
            "| fps                | 288      |\n",
            "| nupdates           | 3000     |\n",
            "| policy_entropy     | 43.2     |\n",
            "| total_timesteps    | 15000    |\n",
            "| value_loss         | 7.58     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0        |\n",
            "| fps                | 288      |\n",
            "| nupdates           | 3100     |\n",
            "| policy_entropy     | 43.1     |\n",
            "| total_timesteps    | 15500    |\n",
            "| value_loss         | 1.61     |\n",
            "---------------------------------\n",
            "----------------------------------\n",
            "| explained_variance | -2.38e-07 |\n",
            "| fps                | 289       |\n",
            "| nupdates           | 3200      |\n",
            "| policy_entropy     | 43.2      |\n",
            "| total_timesteps    | 16000     |\n",
            "| value_loss         | 10.1      |\n",
            "----------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 5.96e-08 |\n",
            "| fps                | 289      |\n",
            "| nupdates           | 3300     |\n",
            "| policy_entropy     | 43.2     |\n",
            "| total_timesteps    | 16500    |\n",
            "| value_loss         | 0.225    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0        |\n",
            "| fps                | 289      |\n",
            "| nupdates           | 3400     |\n",
            "| policy_entropy     | 43.1     |\n",
            "| total_timesteps    | 17000    |\n",
            "| value_loss         | 0.719    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0        |\n",
            "| fps                | 289      |\n",
            "| nupdates           | 3500     |\n",
            "| policy_entropy     | 43.1     |\n",
            "| total_timesteps    | 17500    |\n",
            "| value_loss         | 2.07     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0        |\n",
            "| fps                | 290      |\n",
            "| nupdates           | 3600     |\n",
            "| policy_entropy     | 43.3     |\n",
            "| total_timesteps    | 18000    |\n",
            "| value_loss         | 2.27     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0        |\n",
            "| fps                | 290      |\n",
            "| nupdates           | 3700     |\n",
            "| policy_entropy     | 43.2     |\n",
            "| total_timesteps    | 18500    |\n",
            "| value_loss         | 8.4      |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0.136    |\n",
            "| fps                | 289      |\n",
            "| nupdates           | 3800     |\n",
            "| policy_entropy     | 43.3     |\n",
            "| total_timesteps    | 19000    |\n",
            "| value_loss         | 0.569    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | -0.0849  |\n",
            "| fps                | 289      |\n",
            "| nupdates           | 3900     |\n",
            "| policy_entropy     | 43.3     |\n",
            "| total_timesteps    | 19500    |\n",
            "| value_loss         | 1.91     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0        |\n",
            "| fps                | 290      |\n",
            "| nupdates           | 4000     |\n",
            "| policy_entropy     | 43.4     |\n",
            "| total_timesteps    | 20000    |\n",
            "| value_loss         | 13.9     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0        |\n",
            "| fps                | 290      |\n",
            "| nupdates           | 4100     |\n",
            "| policy_entropy     | 43.3     |\n",
            "| total_timesteps    | 20500    |\n",
            "| value_loss         | 3.95     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0        |\n",
            "| fps                | 290      |\n",
            "| nupdates           | 4200     |\n",
            "| policy_entropy     | 43.4     |\n",
            "| total_timesteps    | 21000    |\n",
            "| value_loss         | 6.85     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 4.29e-06 |\n",
            "| fps                | 290      |\n",
            "| nupdates           | 4300     |\n",
            "| policy_entropy     | 43.4     |\n",
            "| total_timesteps    | 21500    |\n",
            "| value_loss         | 0.986    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0        |\n",
            "| fps                | 290      |\n",
            "| nupdates           | 4400     |\n",
            "| policy_entropy     | 43.4     |\n",
            "| total_timesteps    | 22000    |\n",
            "| value_loss         | 0.758    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0        |\n",
            "| fps                | 290      |\n",
            "| nupdates           | 4500     |\n",
            "| policy_entropy     | 43.5     |\n",
            "| total_timesteps    | 22500    |\n",
            "| value_loss         | 1.14     |\n",
            "---------------------------------\n",
            "----------------------------------\n",
            "| explained_variance | -1.19e-07 |\n",
            "| fps                | 290       |\n",
            "| nupdates           | 4600      |\n",
            "| policy_entropy     | 43.6      |\n",
            "| total_timesteps    | 23000     |\n",
            "| value_loss         | 0.89      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| explained_variance | -1.19e-07 |\n",
            "| fps                | 290       |\n",
            "| nupdates           | 4700      |\n",
            "| policy_entropy     | 43.5      |\n",
            "| total_timesteps    | 23500     |\n",
            "| value_loss         | 0.169     |\n",
            "----------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 5.96e-08 |\n",
            "| fps                | 290      |\n",
            "| nupdates           | 4800     |\n",
            "| policy_entropy     | 43.5     |\n",
            "| total_timesteps    | 24000    |\n",
            "| value_loss         | 0.714    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0.391    |\n",
            "| fps                | 290      |\n",
            "| nupdates           | 4900     |\n",
            "| policy_entropy     | 43.5     |\n",
            "| total_timesteps    | 24500    |\n",
            "| value_loss         | 3.32     |\n",
            "---------------------------------\n",
            "----------------------------------\n",
            "| explained_variance | -1.04e-05 |\n",
            "| fps                | 290       |\n",
            "| nupdates           | 5000      |\n",
            "| policy_entropy     | 43.5      |\n",
            "| total_timesteps    | 25000     |\n",
            "| value_loss         | 2.8       |\n",
            "----------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0        |\n",
            "| fps                | 290      |\n",
            "| nupdates           | 5100     |\n",
            "| policy_entropy     | 43.6     |\n",
            "| total_timesteps    | 25500    |\n",
            "| value_loss         | 0.213    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | -0.907   |\n",
            "| fps                | 290      |\n",
            "| nupdates           | 5200     |\n",
            "| policy_entropy     | 43.6     |\n",
            "| total_timesteps    | 26000    |\n",
            "| value_loss         | 0.971    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0.00186  |\n",
            "| fps                | 290      |\n",
            "| nupdates           | 5300     |\n",
            "| policy_entropy     | 43.6     |\n",
            "| total_timesteps    | 26500    |\n",
            "| value_loss         | 2.08     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0        |\n",
            "| fps                | 290      |\n",
            "| nupdates           | 5400     |\n",
            "| policy_entropy     | 43.6     |\n",
            "| total_timesteps    | 27000    |\n",
            "| value_loss         | 0.775    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0        |\n",
            "| fps                | 291      |\n",
            "| nupdates           | 5500     |\n",
            "| policy_entropy     | 43.6     |\n",
            "| total_timesteps    | 27500    |\n",
            "| value_loss         | 0.392    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0        |\n",
            "| fps                | 291      |\n",
            "| nupdates           | 5600     |\n",
            "| policy_entropy     | 43.6     |\n",
            "| total_timesteps    | 28000    |\n",
            "| value_loss         | 7.16     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | -0.303   |\n",
            "| fps                | 291      |\n",
            "| nupdates           | 5700     |\n",
            "| policy_entropy     | 43.7     |\n",
            "| total_timesteps    | 28500    |\n",
            "| value_loss         | 0.923    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0.149    |\n",
            "| fps                | 291      |\n",
            "| nupdates           | 5800     |\n",
            "| policy_entropy     | 43.7     |\n",
            "| total_timesteps    | 29000    |\n",
            "| value_loss         | 7.99     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0        |\n",
            "| fps                | 291      |\n",
            "| nupdates           | 5900     |\n",
            "| policy_entropy     | 43.7     |\n",
            "| total_timesteps    | 29500    |\n",
            "| value_loss         | 0.827    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0        |\n",
            "| fps                | 292      |\n",
            "| nupdates           | 6000     |\n",
            "| policy_entropy     | 43.7     |\n",
            "| total_timesteps    | 30000    |\n",
            "| value_loss         | 1.39     |\n",
            "---------------------------------\n",
            "Training time (A2C):  1.7234221895535786  minutes\n",
            "======A2C Validation from:  20190503 to  20190802\n",
            "A2C Sharpe Ratio:  0.2069808517108236\n",
            "======PPO Training========\n",
            "Training time (PPO):  5.94955823024114  minutes\n",
            "======PPO Validation from:  20190503 to  20190802\n",
            "PPO Sharpe Ratio:  0.047382194724296715\n",
            "======DDPG Training========\n",
            "Training time (DDPG):  1.0428127686182658  minutes\n",
            "======DDPG Validation from:  20190503 to  20190802\n",
            "======Trading from:  20190802 to  20191031\n",
            "previous_total_asset:1284811.4109282775\n",
            "end_total_asset:1251532.704959471\n",
            "total_reward:-33278.70596880652\n",
            "total_cost:  2049.5768412159405\n",
            "total trades:  288\n",
            "Sharpe:  -0.18686200676681028\n",
            "============================================\n",
            "turbulence_threshold:  109.91299670003775\n",
            "======Model training from:  20100000 to  20190802\n",
            "======A2C Training========\n",
            "--------------------------------------\n",
            "| explained_variance      | 0        |\n",
            "| fps                     | 18       |\n",
            "| nupdates                | 1        |\n",
            "| policy_entropy          | 42.6     |\n",
            "| reference_Q_mean        | 2.37     |\n",
            "| reference_Q_std         | 2.51     |\n",
            "| reference_action_mean   | -0.0531  |\n",
            "| reference_action_std    | 0.96     |\n",
            "| reference_actor_Q_mean  | 2.92     |\n",
            "| reference_actor_Q_std   | 2.58     |\n",
            "| rollout/Q_mean          | 1.52     |\n",
            "| rollout/actions_mean    | -0.0917  |\n",
            "| rollout/actions_std     | 0.811    |\n",
            "| rollout/episode_steps   | 2.35e+03 |\n",
            "| rollout/episodes        | 4        |\n",
            "| rollout/return          | 175      |\n",
            "| rollout/return_history  | 175      |\n",
            "| total/duration          | 61.8     |\n",
            "| total/episodes          | 4        |\n",
            "| total/epochs            | 1        |\n",
            "| total/steps             | 9998     |\n",
            "| total/steps_per_second  | 162      |\n",
            "| total_timesteps         | 5        |\n",
            "| train/loss_actor        | -2.97    |\n",
            "| train/loss_critic       | 1.21     |\n",
            "| train/param_noise_di... | 0        |\n",
            "| value_loss              | 0.00457  |\n",
            "--------------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0.0321   |\n",
            "| fps                | 246      |\n",
            "| nupdates           | 100      |\n",
            "| policy_entropy     | 42.6     |\n",
            "| total_timesteps    | 500      |\n",
            "| value_loss         | 7.91     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0.00765  |\n",
            "| fps                | 262      |\n",
            "| nupdates           | 200      |\n",
            "| policy_entropy     | 42.6     |\n",
            "| total_timesteps    | 1000     |\n",
            "| value_loss         | 9.44     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | -0.182   |\n",
            "| fps                | 265      |\n",
            "| nupdates           | 300      |\n",
            "| policy_entropy     | 42.6     |\n",
            "| total_timesteps    | 1500     |\n",
            "| value_loss         | 5.12     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | -0.578   |\n",
            "| fps                | 268      |\n",
            "| nupdates           | 400      |\n",
            "| policy_entropy     | 42.6     |\n",
            "| total_timesteps    | 2000     |\n",
            "| value_loss         | 9.88     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0        |\n",
            "| fps                | 265      |\n",
            "| nupdates           | 500      |\n",
            "| policy_entropy     | 42.6     |\n",
            "| total_timesteps    | 2500     |\n",
            "| value_loss         | 2.51     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | -1.19    |\n",
            "| fps                | 267      |\n",
            "| nupdates           | 600      |\n",
            "| policy_entropy     | 42.6     |\n",
            "| total_timesteps    | 3000     |\n",
            "| value_loss         | 4.27     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0.000453 |\n",
            "| fps                | 268      |\n",
            "| nupdates           | 700      |\n",
            "| policy_entropy     | 42.6     |\n",
            "| total_timesteps    | 3500     |\n",
            "| value_loss         | 1.09     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | -0.259   |\n",
            "| fps                | 270      |\n",
            "| nupdates           | 800      |\n",
            "| policy_entropy     | 42.6     |\n",
            "| total_timesteps    | 4000     |\n",
            "| value_loss         | 2.15     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | -0.0502  |\n",
            "| fps                | 273      |\n",
            "| nupdates           | 900      |\n",
            "| policy_entropy     | 42.7     |\n",
            "| total_timesteps    | 4500     |\n",
            "| value_loss         | 18.1     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0.243    |\n",
            "| fps                | 271      |\n",
            "| nupdates           | 1000     |\n",
            "| policy_entropy     | 42.6     |\n",
            "| total_timesteps    | 5000     |\n",
            "| value_loss         | 0.101    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0.147    |\n",
            "| fps                | 273      |\n",
            "| nupdates           | 1100     |\n",
            "| policy_entropy     | 42.7     |\n",
            "| total_timesteps    | 5500     |\n",
            "| value_loss         | 0.319    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0.0359   |\n",
            "| fps                | 274      |\n",
            "| nupdates           | 1200     |\n",
            "| policy_entropy     | 42.6     |\n",
            "| total_timesteps    | 6000     |\n",
            "| value_loss         | 1.99     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | -0.607   |\n",
            "| fps                | 275      |\n",
            "| nupdates           | 1300     |\n",
            "| policy_entropy     | 42.7     |\n",
            "| total_timesteps    | 6500     |\n",
            "| value_loss         | 0.54     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0.0828   |\n",
            "| fps                | 276      |\n",
            "| nupdates           | 1400     |\n",
            "| policy_entropy     | 42.7     |\n",
            "| total_timesteps    | 7000     |\n",
            "| value_loss         | 9.63     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0.178    |\n",
            "| fps                | 275      |\n",
            "| nupdates           | 1500     |\n",
            "| policy_entropy     | 42.7     |\n",
            "| total_timesteps    | 7500     |\n",
            "| value_loss         | 0.063    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0        |\n",
            "| fps                | 276      |\n",
            "| nupdates           | 1600     |\n",
            "| policy_entropy     | 42.7     |\n",
            "| total_timesteps    | 8000     |\n",
            "| value_loss         | 0.475    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | -0.0361  |\n",
            "| fps                | 277      |\n",
            "| nupdates           | 1700     |\n",
            "| policy_entropy     | 42.7     |\n",
            "| total_timesteps    | 8500     |\n",
            "| value_loss         | 17.2     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0        |\n",
            "| fps                | 278      |\n",
            "| nupdates           | 1800     |\n",
            "| policy_entropy     | 42.8     |\n",
            "| total_timesteps    | 9000     |\n",
            "| value_loss         | 4.46     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0        |\n",
            "| fps                | 279      |\n",
            "| nupdates           | 1900     |\n",
            "| policy_entropy     | 42.8     |\n",
            "| total_timesteps    | 9500     |\n",
            "| value_loss         | 17.7     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0        |\n",
            "| fps                | 278      |\n",
            "| nupdates           | 2000     |\n",
            "| policy_entropy     | 42.9     |\n",
            "| total_timesteps    | 10000    |\n",
            "| value_loss         | 1.5      |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0        |\n",
            "| fps                | 279      |\n",
            "| nupdates           | 2100     |\n",
            "| policy_entropy     | 42.8     |\n",
            "| total_timesteps    | 10500    |\n",
            "| value_loss         | 0.328    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0        |\n",
            "| fps                | 281      |\n",
            "| nupdates           | 2200     |\n",
            "| policy_entropy     | 42.9     |\n",
            "| total_timesteps    | 11000    |\n",
            "| value_loss         | 13       |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0        |\n",
            "| fps                | 281      |\n",
            "| nupdates           | 2300     |\n",
            "| policy_entropy     | 42.9     |\n",
            "| total_timesteps    | 11500    |\n",
            "| value_loss         | 14.6     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0        |\n",
            "| fps                | 282      |\n",
            "| nupdates           | 2400     |\n",
            "| policy_entropy     | 42.9     |\n",
            "| total_timesteps    | 12000    |\n",
            "| value_loss         | 2.39     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0.0361   |\n",
            "| fps                | 282      |\n",
            "| nupdates           | 2500     |\n",
            "| policy_entropy     | 43       |\n",
            "| total_timesteps    | 12500    |\n",
            "| value_loss         | 2.13     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | -0.00675 |\n",
            "| fps                | 282      |\n",
            "| nupdates           | 2600     |\n",
            "| policy_entropy     | 43       |\n",
            "| total_timesteps    | 13000    |\n",
            "| value_loss         | 0.618    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | -0.482   |\n",
            "| fps                | 283      |\n",
            "| nupdates           | 2700     |\n",
            "| policy_entropy     | 43       |\n",
            "| total_timesteps    | 13500    |\n",
            "| value_loss         | 6.96     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | -0.00367 |\n",
            "| fps                | 283      |\n",
            "| nupdates           | 2800     |\n",
            "| policy_entropy     | 42.9     |\n",
            "| total_timesteps    | 14000    |\n",
            "| value_loss         | 1.01     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0        |\n",
            "| fps                | 283      |\n",
            "| nupdates           | 2900     |\n",
            "| policy_entropy     | 42.9     |\n",
            "| total_timesteps    | 14500    |\n",
            "| value_loss         | 0.321    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 1.19e-07 |\n",
            "| fps                | 284      |\n",
            "| nupdates           | 3000     |\n",
            "| policy_entropy     | 43       |\n",
            "| total_timesteps    | 15000    |\n",
            "| value_loss         | 1.03     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0        |\n",
            "| fps                | 284      |\n",
            "| nupdates           | 3100     |\n",
            "| policy_entropy     | 43       |\n",
            "| total_timesteps    | 15500    |\n",
            "| value_loss         | 12.2     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0        |\n",
            "| fps                | 285      |\n",
            "| nupdates           | 3200     |\n",
            "| policy_entropy     | 43       |\n",
            "| total_timesteps    | 16000    |\n",
            "| value_loss         | 8.89     |\n",
            "---------------------------------\n",
            "----------------------------------\n",
            "| explained_variance | -1.19e-07 |\n",
            "| fps                | 285       |\n",
            "| nupdates           | 3300      |\n",
            "| policy_entropy     | 43        |\n",
            "| total_timesteps    | 16500     |\n",
            "| value_loss         | 5.93      |\n",
            "----------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | -0.0234  |\n",
            "| fps                | 285      |\n",
            "| nupdates           | 3400     |\n",
            "| policy_entropy     | 43       |\n",
            "| total_timesteps    | 17000    |\n",
            "| value_loss         | 10.2     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0        |\n",
            "| fps                | 285      |\n",
            "| nupdates           | 3500     |\n",
            "| policy_entropy     | 43       |\n",
            "| total_timesteps    | 17500    |\n",
            "| value_loss         | 3.82     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0        |\n",
            "| fps                | 286      |\n",
            "| nupdates           | 3600     |\n",
            "| policy_entropy     | 43.1     |\n",
            "| total_timesteps    | 18000    |\n",
            "| value_loss         | 4.08     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0        |\n",
            "| fps                | 286      |\n",
            "| nupdates           | 3700     |\n",
            "| policy_entropy     | 43.1     |\n",
            "| total_timesteps    | 18500    |\n",
            "| value_loss         | 3.22     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0        |\n",
            "| fps                | 286      |\n",
            "| nupdates           | 3800     |\n",
            "| policy_entropy     | 43.2     |\n",
            "| total_timesteps    | 19000    |\n",
            "| value_loss         | 2.87     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0.107    |\n",
            "| fps                | 286      |\n",
            "| nupdates           | 3900     |\n",
            "| policy_entropy     | 43.2     |\n",
            "| total_timesteps    | 19500    |\n",
            "| value_loss         | 12.1     |\n",
            "---------------------------------\n",
            "----------------------------------\n",
            "| explained_variance | -1.19e-07 |\n",
            "| fps                | 286       |\n",
            "| nupdates           | 4000      |\n",
            "| policy_entropy     | 43.2      |\n",
            "| total_timesteps    | 20000     |\n",
            "| value_loss         | 2.87      |\n",
            "----------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0        |\n",
            "| fps                | 287      |\n",
            "| nupdates           | 4100     |\n",
            "| policy_entropy     | 43.2     |\n",
            "| total_timesteps    | 20500    |\n",
            "| value_loss         | 12.1     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0        |\n",
            "| fps                | 287      |\n",
            "| nupdates           | 4200     |\n",
            "| policy_entropy     | 43.2     |\n",
            "| total_timesteps    | 21000    |\n",
            "| value_loss         | 4.89     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | -0.00979 |\n",
            "| fps                | 287      |\n",
            "| nupdates           | 4300     |\n",
            "| policy_entropy     | 43.3     |\n",
            "| total_timesteps    | 21500    |\n",
            "| value_loss         | 35.4     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0.112    |\n",
            "| fps                | 287      |\n",
            "| nupdates           | 4400     |\n",
            "| policy_entropy     | 43.4     |\n",
            "| total_timesteps    | 22000    |\n",
            "| value_loss         | 8.72     |\n",
            "---------------------------------\n",
            "----------------------------------\n",
            "| explained_variance | -1.19e-07 |\n",
            "| fps                | 287       |\n",
            "| nupdates           | 4500      |\n",
            "| policy_entropy     | 43.4      |\n",
            "| total_timesteps    | 22500     |\n",
            "| value_loss         | 0.109     |\n",
            "----------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0        |\n",
            "| fps                | 288      |\n",
            "| nupdates           | 4600     |\n",
            "| policy_entropy     | 43.4     |\n",
            "| total_timesteps    | 23000    |\n",
            "| value_loss         | 18       |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 1.19e-07 |\n",
            "| fps                | 288      |\n",
            "| nupdates           | 4700     |\n",
            "| policy_entropy     | 43.5     |\n",
            "| total_timesteps    | 23500    |\n",
            "| value_loss         | 13.8     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0.0121   |\n",
            "| fps                | 288      |\n",
            "| nupdates           | 4800     |\n",
            "| policy_entropy     | 43.6     |\n",
            "| total_timesteps    | 24000    |\n",
            "| value_loss         | 1.07     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | -0.128   |\n",
            "| fps                | 288      |\n",
            "| nupdates           | 4900     |\n",
            "| policy_entropy     | 43.5     |\n",
            "| total_timesteps    | 24500    |\n",
            "| value_loss         | 5.92     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | -0.305   |\n",
            "| fps                | 288      |\n",
            "| nupdates           | 5000     |\n",
            "| policy_entropy     | 43.6     |\n",
            "| total_timesteps    | 25000    |\n",
            "| value_loss         | 2.28     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0.0595   |\n",
            "| fps                | 289      |\n",
            "| nupdates           | 5100     |\n",
            "| policy_entropy     | 43.5     |\n",
            "| total_timesteps    | 25500    |\n",
            "| value_loss         | 3.31     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0        |\n",
            "| fps                | 289      |\n",
            "| nupdates           | 5200     |\n",
            "| policy_entropy     | 43.5     |\n",
            "| total_timesteps    | 26000    |\n",
            "| value_loss         | 1.97     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0        |\n",
            "| fps                | 289      |\n",
            "| nupdates           | 5300     |\n",
            "| policy_entropy     | 43.5     |\n",
            "| total_timesteps    | 26500    |\n",
            "| value_loss         | 3.74     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0        |\n",
            "| fps                | 288      |\n",
            "| nupdates           | 5400     |\n",
            "| policy_entropy     | 43.6     |\n",
            "| total_timesteps    | 27000    |\n",
            "| value_loss         | 18.5     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 1.79e-07 |\n",
            "| fps                | 289      |\n",
            "| nupdates           | 5500     |\n",
            "| policy_entropy     | 43.6     |\n",
            "| total_timesteps    | 27500    |\n",
            "| value_loss         | 0.863    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0        |\n",
            "| fps                | 289      |\n",
            "| nupdates           | 5600     |\n",
            "| policy_entropy     | 43.6     |\n",
            "| total_timesteps    | 28000    |\n",
            "| value_loss         | 6.31     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0.0041   |\n",
            "| fps                | 289      |\n",
            "| nupdates           | 5700     |\n",
            "| policy_entropy     | 43.6     |\n",
            "| total_timesteps    | 28500    |\n",
            "| value_loss         | 0.556    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0.521    |\n",
            "| fps                | 289      |\n",
            "| nupdates           | 5800     |\n",
            "| policy_entropy     | 43.7     |\n",
            "| total_timesteps    | 29000    |\n",
            "| value_loss         | 0.252    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0        |\n",
            "| fps                | 289      |\n",
            "| nupdates           | 5900     |\n",
            "| policy_entropy     | 43.7     |\n",
            "| total_timesteps    | 29500    |\n",
            "| value_loss         | 4.1      |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0        |\n",
            "| fps                | 290      |\n",
            "| nupdates           | 6000     |\n",
            "| policy_entropy     | 43.8     |\n",
            "| total_timesteps    | 30000    |\n",
            "| value_loss         | 4.8      |\n",
            "---------------------------------\n",
            "Training time (A2C):  1.735141404469808  minutes\n",
            "======A2C Validation from:  20190802 to  20191031\n",
            "A2C Sharpe Ratio:  -0.1846546998032241\n",
            "======PPO Training========\n",
            "Training time (PPO):  5.657868301868438  minutes\n",
            "======PPO Validation from:  20190802 to  20191031\n",
            "PPO Sharpe Ratio:  -0.14912069918520224\n",
            "======DDPG Training========\n",
            "Training time (DDPG):  0.9851995984713237  minutes\n",
            "======DDPG Validation from:  20190802 to  20191031\n",
            "======Trading from:  20191031 to  20200203\n",
            "previous_total_asset:1251532.704959471\n",
            "end_total_asset:1251700.3682099925\n",
            "total_reward:167.66325052152388\n",
            "total_cost:  2057.746058387094\n",
            "total trades:  438\n",
            "Sharpe:  0.009403400688565726\n",
            "============================================\n",
            "turbulence_threshold:  109.91299670003775\n",
            "======Model training from:  20100000 to  20191031\n",
            "======A2C Training========\n",
            "--------------------------------------\n",
            "| explained_variance      | 0        |\n",
            "| fps                     | 18       |\n",
            "| nupdates                | 1        |\n",
            "| policy_entropy          | 42.6     |\n",
            "| reference_Q_mean        | 1.81     |\n",
            "| reference_Q_std         | 1.81     |\n",
            "| reference_action_mean   | -0.0219  |\n",
            "| reference_action_std    | 0.97     |\n",
            "| reference_actor_Q_mean  | 2.27     |\n",
            "| reference_actor_Q_std   | 1.76     |\n",
            "| rollout/Q_mean          | 1.05     |\n",
            "| rollout/actions_mean    | -0.033   |\n",
            "| rollout/actions_std     | 0.816    |\n",
            "| rollout/episode_steps   | 2.41e+03 |\n",
            "| rollout/episodes        | 4        |\n",
            "| rollout/return          | 161      |\n",
            "| rollout/return_history  | 161      |\n",
            "| total/duration          | 58.3     |\n",
            "| total/episodes          | 4        |\n",
            "| total/epochs            | 1        |\n",
            "| total/steps             | 9998     |\n",
            "| total/steps_per_second  | 171      |\n",
            "| total_timesteps         | 5        |\n",
            "| train/loss_actor        | -2.35    |\n",
            "| train/loss_critic       | 1.13     |\n",
            "| train/param_noise_di... | 0        |\n",
            "| value_loss              | 0.00347  |\n",
            "--------------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | -0.209   |\n",
            "| fps                | 263      |\n",
            "| nupdates           | 100      |\n",
            "| policy_entropy     | 42.6     |\n",
            "| total_timesteps    | 500      |\n",
            "| value_loss         | 8.99     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0.074    |\n",
            "| fps                | 286      |\n",
            "| nupdates           | 200      |\n",
            "| policy_entropy     | 42.6     |\n",
            "| total_timesteps    | 1000     |\n",
            "| value_loss         | 5.36     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0.0351   |\n",
            "| fps                | 293      |\n",
            "| nupdates           | 300      |\n",
            "| policy_entropy     | 42.6     |\n",
            "| total_timesteps    | 1500     |\n",
            "| value_loss         | 4.96     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0        |\n",
            "| fps                | 297      |\n",
            "| nupdates           | 400      |\n",
            "| policy_entropy     | 42.6     |\n",
            "| total_timesteps    | 2000     |\n",
            "| value_loss         | 12.9     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0        |\n",
            "| fps                | 295      |\n",
            "| nupdates           | 500      |\n",
            "| policy_entropy     | 42.6     |\n",
            "| total_timesteps    | 2500     |\n",
            "| value_loss         | 0.0767   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0.277    |\n",
            "| fps                | 296      |\n",
            "| nupdates           | 600      |\n",
            "| policy_entropy     | 42.6     |\n",
            "| total_timesteps    | 3000     |\n",
            "| value_loss         | 0.839    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0.262    |\n",
            "| fps                | 296      |\n",
            "| nupdates           | 700      |\n",
            "| policy_entropy     | 42.6     |\n",
            "| total_timesteps    | 3500     |\n",
            "| value_loss         | 1.28     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0.191    |\n",
            "| fps                | 296      |\n",
            "| nupdates           | 800      |\n",
            "| policy_entropy     | 42.6     |\n",
            "| total_timesteps    | 4000     |\n",
            "| value_loss         | 5.58     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | -0.0238  |\n",
            "| fps                | 297      |\n",
            "| nupdates           | 900      |\n",
            "| policy_entropy     | 42.6     |\n",
            "| total_timesteps    | 4500     |\n",
            "| value_loss         | 3.71     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0        |\n",
            "| fps                | 294      |\n",
            "| nupdates           | 1000     |\n",
            "| policy_entropy     | 42.6     |\n",
            "| total_timesteps    | 5000     |\n",
            "| value_loss         | 0.0964   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | -0.00766 |\n",
            "| fps                | 294      |\n",
            "| nupdates           | 1100     |\n",
            "| policy_entropy     | 42.7     |\n",
            "| total_timesteps    | 5500     |\n",
            "| value_loss         | 6.94     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | -0.259   |\n",
            "| fps                | 296      |\n",
            "| nupdates           | 1200     |\n",
            "| policy_entropy     | 42.6     |\n",
            "| total_timesteps    | 6000     |\n",
            "| value_loss         | 0.212    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 5.96e-08 |\n",
            "| fps                | 297      |\n",
            "| nupdates           | 1300     |\n",
            "| policy_entropy     | 42.6     |\n",
            "| total_timesteps    | 6500     |\n",
            "| value_loss         | 24.9     |\n",
            "---------------------------------\n",
            "----------------------------------\n",
            "| explained_variance | -2.38e-07 |\n",
            "| fps                | 299       |\n",
            "| nupdates           | 1400      |\n",
            "| policy_entropy     | 42.6      |\n",
            "| total_timesteps    | 7000      |\n",
            "| value_loss         | 48.5      |\n",
            "----------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0.196    |\n",
            "| fps                | 298      |\n",
            "| nupdates           | 1500     |\n",
            "| policy_entropy     | 42.7     |\n",
            "| total_timesteps    | 7500     |\n",
            "| value_loss         | 2.14     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0.129    |\n",
            "| fps                | 298      |\n",
            "| nupdates           | 1600     |\n",
            "| policy_entropy     | 42.7     |\n",
            "| total_timesteps    | 8000     |\n",
            "| value_loss         | 0.859    |\n",
            "---------------------------------\n",
            "----------------------------------\n",
            "| explained_variance | -1.19e-07 |\n",
            "| fps                | 298       |\n",
            "| nupdates           | 1700      |\n",
            "| policy_entropy     | 42.7      |\n",
            "| total_timesteps    | 8500      |\n",
            "| value_loss         | 8.96      |\n",
            "----------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0        |\n",
            "| fps                | 299      |\n",
            "| nupdates           | 1800     |\n",
            "| policy_entropy     | 42.6     |\n",
            "| total_timesteps    | 9000     |\n",
            "| value_loss         | 4.78     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0        |\n",
            "| fps                | 300      |\n",
            "| nupdates           | 1900     |\n",
            "| policy_entropy     | 42.7     |\n",
            "| total_timesteps    | 9500     |\n",
            "| value_loss         | 16.1     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0.316    |\n",
            "| fps                | 299      |\n",
            "| nupdates           | 2000     |\n",
            "| policy_entropy     | 42.7     |\n",
            "| total_timesteps    | 10000    |\n",
            "| value_loss         | 0.977    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0.000402 |\n",
            "| fps                | 300      |\n",
            "| nupdates           | 2100     |\n",
            "| policy_entropy     | 42.7     |\n",
            "| total_timesteps    | 10500    |\n",
            "| value_loss         | 1.89     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | -0.0828  |\n",
            "| fps                | 301      |\n",
            "| nupdates           | 2200     |\n",
            "| policy_entropy     | 42.7     |\n",
            "| total_timesteps    | 11000    |\n",
            "| value_loss         | 3.24     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0.0166   |\n",
            "| fps                | 301      |\n",
            "| nupdates           | 2300     |\n",
            "| policy_entropy     | 42.7     |\n",
            "| total_timesteps    | 11500    |\n",
            "| value_loss         | 6.6      |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0        |\n",
            "| fps                | 303      |\n",
            "| nupdates           | 2400     |\n",
            "| policy_entropy     | 42.7     |\n",
            "| total_timesteps    | 12000    |\n",
            "| value_loss         | 17.7     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | -0.368   |\n",
            "| fps                | 302      |\n",
            "| nupdates           | 2500     |\n",
            "| policy_entropy     | 42.6     |\n",
            "| total_timesteps    | 12500    |\n",
            "| value_loss         | 8.09     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | -0.0141  |\n",
            "| fps                | 302      |\n",
            "| nupdates           | 2600     |\n",
            "| policy_entropy     | 42.7     |\n",
            "| total_timesteps    | 13000    |\n",
            "| value_loss         | 12.9     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0.252    |\n",
            "| fps                | 302      |\n",
            "| nupdates           | 2700     |\n",
            "| policy_entropy     | 42.7     |\n",
            "| total_timesteps    | 13500    |\n",
            "| value_loss         | 0.843    |\n",
            "---------------------------------\n",
            "----------------------------------\n",
            "| explained_variance | -1.19e-07 |\n",
            "| fps                | 303       |\n",
            "| nupdates           | 2800      |\n",
            "| policy_entropy     | 42.8      |\n",
            "| total_timesteps    | 14000     |\n",
            "| value_loss         | 16.9      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| explained_variance | -1.19e-07 |\n",
            "| fps                | 303       |\n",
            "| nupdates           | 2900      |\n",
            "| policy_entropy     | 42.7      |\n",
            "| total_timesteps    | 14500     |\n",
            "| value_loss         | 9.04      |\n",
            "----------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0.0271   |\n",
            "| fps                | 303      |\n",
            "| nupdates           | 3000     |\n",
            "| policy_entropy     | 42.8     |\n",
            "| total_timesteps    | 15000    |\n",
            "| value_loss         | 2.08     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | -0.0618  |\n",
            "| fps                | 304      |\n",
            "| nupdates           | 3100     |\n",
            "| policy_entropy     | 42.7     |\n",
            "| total_timesteps    | 15500    |\n",
            "| value_loss         | 1.12     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0        |\n",
            "| fps                | 304      |\n",
            "| nupdates           | 3200     |\n",
            "| policy_entropy     | 42.8     |\n",
            "| total_timesteps    | 16000    |\n",
            "| value_loss         | 2.92     |\n",
            "---------------------------------\n",
            "----------------------------------\n",
            "| explained_variance | -2.38e-07 |\n",
            "| fps                | 305       |\n",
            "| nupdates           | 3300      |\n",
            "| policy_entropy     | 42.7      |\n",
            "| total_timesteps    | 16500     |\n",
            "| value_loss         | 0.867     |\n",
            "----------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0        |\n",
            "| fps                | 305      |\n",
            "| nupdates           | 3400     |\n",
            "| policy_entropy     | 42.7     |\n",
            "| total_timesteps    | 17000    |\n",
            "| value_loss         | 6.84     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | -0.441   |\n",
            "| fps                | 305      |\n",
            "| nupdates           | 3500     |\n",
            "| policy_entropy     | 42.8     |\n",
            "| total_timesteps    | 17500    |\n",
            "| value_loss         | 0.814    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0.0482   |\n",
            "| fps                | 305      |\n",
            "| nupdates           | 3600     |\n",
            "| policy_entropy     | 42.8     |\n",
            "| total_timesteps    | 18000    |\n",
            "| value_loss         | 4.88     |\n",
            "---------------------------------\n",
            "----------------------------------\n",
            "| explained_variance | -1.19e-07 |\n",
            "| fps                | 305       |\n",
            "| nupdates           | 3700      |\n",
            "| policy_entropy     | 42.9      |\n",
            "| total_timesteps    | 18500     |\n",
            "| value_loss         | 1.97      |\n",
            "----------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0        |\n",
            "| fps                | 306      |\n",
            "| nupdates           | 3800     |\n",
            "| policy_entropy     | 42.9     |\n",
            "| total_timesteps    | 19000    |\n",
            "| value_loss         | 0.666    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0.173    |\n",
            "| fps                | 306      |\n",
            "| nupdates           | 3900     |\n",
            "| policy_entropy     | 43       |\n",
            "| total_timesteps    | 19500    |\n",
            "| value_loss         | 2.08     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | -0.584   |\n",
            "| fps                | 306      |\n",
            "| nupdates           | 4000     |\n",
            "| policy_entropy     | 42.9     |\n",
            "| total_timesteps    | 20000    |\n",
            "| value_loss         | 0.922    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0.0142   |\n",
            "| fps                | 306      |\n",
            "| nupdates           | 4100     |\n",
            "| policy_entropy     | 42.9     |\n",
            "| total_timesteps    | 20500    |\n",
            "| value_loss         | 15.6     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 1.19e-07 |\n",
            "| fps                | 306      |\n",
            "| nupdates           | 4200     |\n",
            "| policy_entropy     | 42.9     |\n",
            "| total_timesteps    | 21000    |\n",
            "| value_loss         | 6.62     |\n",
            "---------------------------------\n",
            "----------------------------------\n",
            "| explained_variance | -1.19e-07 |\n",
            "| fps                | 306       |\n",
            "| nupdates           | 4300      |\n",
            "| policy_entropy     | 42.9      |\n",
            "| total_timesteps    | 21500     |\n",
            "| value_loss         | 8.67      |\n",
            "----------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 4.77e-07 |\n",
            "| fps                | 306      |\n",
            "| nupdates           | 4400     |\n",
            "| policy_entropy     | 42.9     |\n",
            "| total_timesteps    | 22000    |\n",
            "| value_loss         | 120      |\n",
            "---------------------------------\n",
            "----------------------------------\n",
            "| explained_variance | -3.36e-05 |\n",
            "| fps                | 305       |\n",
            "| nupdates           | 4500      |\n",
            "| policy_entropy     | 42.9      |\n",
            "| total_timesteps    | 22500     |\n",
            "| value_loss         | 1.44      |\n",
            "----------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0        |\n",
            "| fps                | 305      |\n",
            "| nupdates           | 4600     |\n",
            "| policy_entropy     | 42.9     |\n",
            "| total_timesteps    | 23000    |\n",
            "| value_loss         | 1.29     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0        |\n",
            "| fps                | 305      |\n",
            "| nupdates           | 4700     |\n",
            "| policy_entropy     | 42.9     |\n",
            "| total_timesteps    | 23500    |\n",
            "| value_loss         | 0.996    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0        |\n",
            "| fps                | 305      |\n",
            "| nupdates           | 4800     |\n",
            "| policy_entropy     | 42.9     |\n",
            "| total_timesteps    | 24000    |\n",
            "| value_loss         | 1.52     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0        |\n",
            "| fps                | 306      |\n",
            "| nupdates           | 4900     |\n",
            "| policy_entropy     | 42.8     |\n",
            "| total_timesteps    | 24500    |\n",
            "| value_loss         | 1.06     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0        |\n",
            "| fps                | 305      |\n",
            "| nupdates           | 5000     |\n",
            "| policy_entropy     | 42.8     |\n",
            "| total_timesteps    | 25000    |\n",
            "| value_loss         | 1.26     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | -0.112   |\n",
            "| fps                | 306      |\n",
            "| nupdates           | 5100     |\n",
            "| policy_entropy     | 42.9     |\n",
            "| total_timesteps    | 25500    |\n",
            "| value_loss         | 0.367    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0        |\n",
            "| fps                | 306      |\n",
            "| nupdates           | 5200     |\n",
            "| policy_entropy     | 42.8     |\n",
            "| total_timesteps    | 26000    |\n",
            "| value_loss         | 6.48     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0        |\n",
            "| fps                | 307      |\n",
            "| nupdates           | 5300     |\n",
            "| policy_entropy     | 42.8     |\n",
            "| total_timesteps    | 26500    |\n",
            "| value_loss         | 1.27     |\n",
            "---------------------------------\n",
            "----------------------------------\n",
            "| explained_variance | -1.19e-07 |\n",
            "| fps                | 307       |\n",
            "| nupdates           | 5400      |\n",
            "| policy_entropy     | 42.8      |\n",
            "| total_timesteps    | 27000     |\n",
            "| value_loss         | 63.9      |\n",
            "----------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0.414    |\n",
            "| fps                | 307      |\n",
            "| nupdates           | 5500     |\n",
            "| policy_entropy     | 42.9     |\n",
            "| total_timesteps    | 27500    |\n",
            "| value_loss         | 0.417    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0        |\n",
            "| fps                | 307      |\n",
            "| nupdates           | 5600     |\n",
            "| policy_entropy     | 42.9     |\n",
            "| total_timesteps    | 28000    |\n",
            "| value_loss         | 0.641    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0        |\n",
            "| fps                | 307      |\n",
            "| nupdates           | 5700     |\n",
            "| policy_entropy     | 42.8     |\n",
            "| total_timesteps    | 28500    |\n",
            "| value_loss         | 24.3     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0.155    |\n",
            "| fps                | 307      |\n",
            "| nupdates           | 5800     |\n",
            "| policy_entropy     | 42.8     |\n",
            "| total_timesteps    | 29000    |\n",
            "| value_loss         | 2.4      |\n",
            "---------------------------------\n",
            "----------------------------------\n",
            "| explained_variance | -1.19e-07 |\n",
            "| fps                | 308       |\n",
            "| nupdates           | 5900      |\n",
            "| policy_entropy     | 42.9      |\n",
            "| total_timesteps    | 29500     |\n",
            "| value_loss         | 14.1      |\n",
            "----------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0        |\n",
            "| fps                | 307      |\n",
            "| nupdates           | 6000     |\n",
            "| policy_entropy     | 42.9     |\n",
            "| total_timesteps    | 30000    |\n",
            "| value_loss         | 3.43     |\n",
            "---------------------------------\n",
            "Training time (A2C):  1.6351536194483438  minutes\n",
            "======A2C Validation from:  20191031 to  20200203\n",
            "A2C Sharpe Ratio:  -0.006313045862146822\n",
            "======PPO Training========\n",
            "Training time (PPO):  5.385541927814484  minutes\n",
            "======PPO Validation from:  20191031 to  20200203\n",
            "PPO Sharpe Ratio:  0.06652720312380221\n",
            "======DDPG Training========\n",
            "Training time (DDPG):  0.971497110525767  minutes\n",
            "======DDPG Validation from:  20191031 to  20200203\n",
            "======Trading from:  20200203 to  20200504\n",
            "previous_total_asset:1251700.3682099925\n",
            "end_total_asset:1245039.3205187698\n",
            "total_reward:-6661.047691222746\n",
            "total_cost:  597.0002670546287\n",
            "total trades:  148\n",
            "Sharpe:  -0.20611978111243756\n",
            "============================================\n",
            "turbulence_threshold:  109.91299670003775\n",
            "======Model training from:  20100000 to  20200203\n",
            "======A2C Training========\n",
            "--------------------------------------\n",
            "| explained_variance      | 5.96e-08 |\n",
            "| fps                     | 20       |\n",
            "| nupdates                | 1        |\n",
            "| policy_entropy          | 42.6     |\n",
            "| reference_Q_mean        | 1.51     |\n",
            "| reference_Q_std         | 3.1      |\n",
            "| reference_action_mean   | 0.202    |\n",
            "| reference_action_std    | 0.923    |\n",
            "| reference_actor_Q_mean  | 2.08     |\n",
            "| reference_actor_Q_std   | 3.12     |\n",
            "| rollout/Q_mean          | 1.47     |\n",
            "| rollout/actions_mean    | 0.0976   |\n",
            "| rollout/actions_std     | 0.809    |\n",
            "| rollout/episode_steps   | 2.47e+03 |\n",
            "| rollout/episodes        | 4        |\n",
            "| rollout/return          | 250      |\n",
            "| rollout/return_history  | 250      |\n",
            "| total/duration          | 57.5     |\n",
            "| total/episodes          | 4        |\n",
            "| total/epochs            | 1        |\n",
            "| total/steps             | 9998     |\n",
            "| total/steps_per_second  | 174      |\n",
            "| total_timesteps         | 5        |\n",
            "| train/loss_actor        | -3.13    |\n",
            "| train/loss_critic       | 1.68     |\n",
            "| train/param_noise_di... | 0        |\n",
            "| value_loss              | 0.00034  |\n",
            "--------------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0.139    |\n",
            "| fps                | 259      |\n",
            "| nupdates           | 100      |\n",
            "| policy_entropy     | 42.6     |\n",
            "| total_timesteps    | 500      |\n",
            "| value_loss         | 4.52     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0.134    |\n",
            "| fps                | 275      |\n",
            "| nupdates           | 200      |\n",
            "| policy_entropy     | 42.6     |\n",
            "| total_timesteps    | 1000     |\n",
            "| value_loss         | 6        |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0.17     |\n",
            "| fps                | 282      |\n",
            "| nupdates           | 300      |\n",
            "| policy_entropy     | 42.6     |\n",
            "| total_timesteps    | 1500     |\n",
            "| value_loss         | 5.74     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | -0.126   |\n",
            "| fps                | 290      |\n",
            "| nupdates           | 400      |\n",
            "| policy_entropy     | 42.6     |\n",
            "| total_timesteps    | 2000     |\n",
            "| value_loss         | 10.1     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | -0.253   |\n",
            "| fps                | 291      |\n",
            "| nupdates           | 500      |\n",
            "| policy_entropy     | 42.6     |\n",
            "| total_timesteps    | 2500     |\n",
            "| value_loss         | 9.7      |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | -0.111   |\n",
            "| fps                | 289      |\n",
            "| nupdates           | 600      |\n",
            "| policy_entropy     | 42.6     |\n",
            "| total_timesteps    | 3000     |\n",
            "| value_loss         | 7.61     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 1.19e-07 |\n",
            "| fps                | 291      |\n",
            "| nupdates           | 700      |\n",
            "| policy_entropy     | 42.6     |\n",
            "| total_timesteps    | 3500     |\n",
            "| value_loss         | 1.03     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0.182    |\n",
            "| fps                | 292      |\n",
            "| nupdates           | 800      |\n",
            "| policy_entropy     | 42.6     |\n",
            "| total_timesteps    | 4000     |\n",
            "| value_loss         | 1.4      |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0.0738   |\n",
            "| fps                | 293      |\n",
            "| nupdates           | 900      |\n",
            "| policy_entropy     | 42.7     |\n",
            "| total_timesteps    | 4500     |\n",
            "| value_loss         | 9.99     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | -0.347   |\n",
            "| fps                | 294      |\n",
            "| nupdates           | 1000     |\n",
            "| policy_entropy     | 42.7     |\n",
            "| total_timesteps    | 5000     |\n",
            "| value_loss         | 18.1     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | -0.151   |\n",
            "| fps                | 292      |\n",
            "| nupdates           | 1100     |\n",
            "| policy_entropy     | 42.7     |\n",
            "| total_timesteps    | 5500     |\n",
            "| value_loss         | 9.09     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | -0.0692  |\n",
            "| fps                | 293      |\n",
            "| nupdates           | 1200     |\n",
            "| policy_entropy     | 42.7     |\n",
            "| total_timesteps    | 6000     |\n",
            "| value_loss         | 4.32     |\n",
            "---------------------------------\n",
            "----------------------------------\n",
            "| explained_variance | -1.19e-07 |\n",
            "| fps                | 294       |\n",
            "| nupdates           | 1300      |\n",
            "| policy_entropy     | 42.7      |\n",
            "| total_timesteps    | 6500      |\n",
            "| value_loss         | 6.22      |\n",
            "----------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0.0858   |\n",
            "| fps                | 296      |\n",
            "| nupdates           | 1400     |\n",
            "| policy_entropy     | 42.8     |\n",
            "| total_timesteps    | 7000     |\n",
            "| value_loss         | 10.1     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0        |\n",
            "| fps                | 298      |\n",
            "| nupdates           | 1500     |\n",
            "| policy_entropy     | 42.8     |\n",
            "| total_timesteps    | 7500     |\n",
            "| value_loss         | 182      |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0.137    |\n",
            "| fps                | 297      |\n",
            "| nupdates           | 1600     |\n",
            "| policy_entropy     | 42.8     |\n",
            "| total_timesteps    | 8000     |\n",
            "| value_loss         | 0.372    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0.263    |\n",
            "| fps                | 298      |\n",
            "| nupdates           | 1700     |\n",
            "| policy_entropy     | 42.8     |\n",
            "| total_timesteps    | 8500     |\n",
            "| value_loss         | 1.19     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | -0.208   |\n",
            "| fps                | 299      |\n",
            "| nupdates           | 1800     |\n",
            "| policy_entropy     | 42.7     |\n",
            "| total_timesteps    | 9000     |\n",
            "| value_loss         | 23.1     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 5.96e-08 |\n",
            "| fps                | 300      |\n",
            "| nupdates           | 1900     |\n",
            "| policy_entropy     | 42.8     |\n",
            "| total_timesteps    | 9500     |\n",
            "| value_loss         | 1.22     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0.0245   |\n",
            "| fps                | 301      |\n",
            "| nupdates           | 2000     |\n",
            "| policy_entropy     | 42.8     |\n",
            "| total_timesteps    | 10000    |\n",
            "| value_loss         | 34.9     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0.0391   |\n",
            "| fps                | 300      |\n",
            "| nupdates           | 2100     |\n",
            "| policy_entropy     | 42.8     |\n",
            "| total_timesteps    | 10500    |\n",
            "| value_loss         | 0.982    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | -0.0111  |\n",
            "| fps                | 301      |\n",
            "| nupdates           | 2200     |\n",
            "| policy_entropy     | 42.8     |\n",
            "| total_timesteps    | 11000    |\n",
            "| value_loss         | 0.231    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0        |\n",
            "| fps                | 301      |\n",
            "| nupdates           | 2300     |\n",
            "| policy_entropy     | 42.8     |\n",
            "| total_timesteps    | 11500    |\n",
            "| value_loss         | 9.24     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0.0174   |\n",
            "| fps                | 302      |\n",
            "| nupdates           | 2400     |\n",
            "| policy_entropy     | 42.7     |\n",
            "| total_timesteps    | 12000    |\n",
            "| value_loss         | 2.36     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 1.19e-07 |\n",
            "| fps                | 303      |\n",
            "| nupdates           | 2500     |\n",
            "| policy_entropy     | 42.7     |\n",
            "| total_timesteps    | 12500    |\n",
            "| value_loss         | 25.8     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | -0.108   |\n",
            "| fps                | 304      |\n",
            "| nupdates           | 2600     |\n",
            "| policy_entropy     | 42.7     |\n",
            "| total_timesteps    | 13000    |\n",
            "| value_loss         | 0.648    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | -0.636   |\n",
            "| fps                | 304      |\n",
            "| nupdates           | 2700     |\n",
            "| policy_entropy     | 42.7     |\n",
            "| total_timesteps    | 13500    |\n",
            "| value_loss         | 4.84     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | -0.0163  |\n",
            "| fps                | 304      |\n",
            "| nupdates           | 2800     |\n",
            "| policy_entropy     | 42.8     |\n",
            "| total_timesteps    | 14000    |\n",
            "| value_loss         | 23.9     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0        |\n",
            "| fps                | 305      |\n",
            "| nupdates           | 2900     |\n",
            "| policy_entropy     | 42.8     |\n",
            "| total_timesteps    | 14500    |\n",
            "| value_loss         | 7.03     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | -0.0506  |\n",
            "| fps                | 305      |\n",
            "| nupdates           | 3000     |\n",
            "| policy_entropy     | 42.8     |\n",
            "| total_timesteps    | 15000    |\n",
            "| value_loss         | 34.7     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | -1.17    |\n",
            "| fps                | 305      |\n",
            "| nupdates           | 3100     |\n",
            "| policy_entropy     | 42.9     |\n",
            "| total_timesteps    | 15500    |\n",
            "| value_loss         | 2.69     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | -0.0011  |\n",
            "| fps                | 306      |\n",
            "| nupdates           | 3200     |\n",
            "| policy_entropy     | 42.9     |\n",
            "| total_timesteps    | 16000    |\n",
            "| value_loss         | 1.89     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | -0.0528  |\n",
            "| fps                | 306      |\n",
            "| nupdates           | 3300     |\n",
            "| policy_entropy     | 42.9     |\n",
            "| total_timesteps    | 16500    |\n",
            "| value_loss         | 10.1     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | -0.0544  |\n",
            "| fps                | 307      |\n",
            "| nupdates           | 3400     |\n",
            "| policy_entropy     | 42.9     |\n",
            "| total_timesteps    | 17000    |\n",
            "| value_loss         | 0.225    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0        |\n",
            "| fps                | 307      |\n",
            "| nupdates           | 3500     |\n",
            "| policy_entropy     | 42.9     |\n",
            "| total_timesteps    | 17500    |\n",
            "| value_loss         | 26.3     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | -0.119   |\n",
            "| fps                | 308      |\n",
            "| nupdates           | 3600     |\n",
            "| policy_entropy     | 42.9     |\n",
            "| total_timesteps    | 18000    |\n",
            "| value_loss         | 0.0692   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0        |\n",
            "| fps                | 308      |\n",
            "| nupdates           | 3700     |\n",
            "| policy_entropy     | 42.9     |\n",
            "| total_timesteps    | 18500    |\n",
            "| value_loss         | 3.15     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0.436    |\n",
            "| fps                | 309      |\n",
            "| nupdates           | 3800     |\n",
            "| policy_entropy     | 42.9     |\n",
            "| total_timesteps    | 19000    |\n",
            "| value_loss         | 1.13     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0        |\n",
            "| fps                | 309      |\n",
            "| nupdates           | 3900     |\n",
            "| policy_entropy     | 43       |\n",
            "| total_timesteps    | 19500    |\n",
            "| value_loss         | 1.9      |\n",
            "---------------------------------\n",
            "----------------------------------\n",
            "| explained_variance | -1.19e-07 |\n",
            "| fps                | 309       |\n",
            "| nupdates           | 4000      |\n",
            "| policy_entropy     | 43        |\n",
            "| total_timesteps    | 20000     |\n",
            "| value_loss         | 6.97      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| explained_variance | -1.19e-07 |\n",
            "| fps                | 308       |\n",
            "| nupdates           | 4100      |\n",
            "| policy_entropy     | 43        |\n",
            "| total_timesteps    | 20500     |\n",
            "| value_loss         | 1.73      |\n",
            "----------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0        |\n",
            "| fps                | 309      |\n",
            "| nupdates           | 4200     |\n",
            "| policy_entropy     | 43       |\n",
            "| total_timesteps    | 21000    |\n",
            "| value_loss         | 7.41     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0        |\n",
            "| fps                | 309      |\n",
            "| nupdates           | 4300     |\n",
            "| policy_entropy     | 43       |\n",
            "| total_timesteps    | 21500    |\n",
            "| value_loss         | 22.7     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0.279    |\n",
            "| fps                | 309      |\n",
            "| nupdates           | 4400     |\n",
            "| policy_entropy     | 43.1     |\n",
            "| total_timesteps    | 22000    |\n",
            "| value_loss         | 1.47     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | -0.0481  |\n",
            "| fps                | 309      |\n",
            "| nupdates           | 4500     |\n",
            "| policy_entropy     | 43.1     |\n",
            "| total_timesteps    | 22500    |\n",
            "| value_loss         | 5.21     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0        |\n",
            "| fps                | 309      |\n",
            "| nupdates           | 4600     |\n",
            "| policy_entropy     | 43       |\n",
            "| total_timesteps    | 23000    |\n",
            "| value_loss         | 3.33     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | -1.02    |\n",
            "| fps                | 309      |\n",
            "| nupdates           | 4700     |\n",
            "| policy_entropy     | 43       |\n",
            "| total_timesteps    | 23500    |\n",
            "| value_loss         | 19.5     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0        |\n",
            "| fps                | 309      |\n",
            "| nupdates           | 4800     |\n",
            "| policy_entropy     | 43       |\n",
            "| total_timesteps    | 24000    |\n",
            "| value_loss         | 3.75     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0.0874   |\n",
            "| fps                | 310      |\n",
            "| nupdates           | 4900     |\n",
            "| policy_entropy     | 43       |\n",
            "| total_timesteps    | 24500    |\n",
            "| value_loss         | 2.8      |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | -0.00342 |\n",
            "| fps                | 310      |\n",
            "| nupdates           | 5000     |\n",
            "| policy_entropy     | 43       |\n",
            "| total_timesteps    | 25000    |\n",
            "| value_loss         | 55.1     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | -0.123   |\n",
            "| fps                | 309      |\n",
            "| nupdates           | 5100     |\n",
            "| policy_entropy     | 43       |\n",
            "| total_timesteps    | 25500    |\n",
            "| value_loss         | 9.85     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0        |\n",
            "| fps                | 309      |\n",
            "| nupdates           | 5200     |\n",
            "| policy_entropy     | 43       |\n",
            "| total_timesteps    | 26000    |\n",
            "| value_loss         | 11.5     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0.336    |\n",
            "| fps                | 310      |\n",
            "| nupdates           | 5300     |\n",
            "| policy_entropy     | 43.1     |\n",
            "| total_timesteps    | 26500    |\n",
            "| value_loss         | 0.425    |\n",
            "---------------------------------\n",
            "----------------------------------\n",
            "| explained_variance | -2.38e-07 |\n",
            "| fps                | 310       |\n",
            "| nupdates           | 5400      |\n",
            "| policy_entropy     | 43.1      |\n",
            "| total_timesteps    | 27000     |\n",
            "| value_loss         | 20.6      |\n",
            "----------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0        |\n",
            "| fps                | 310      |\n",
            "| nupdates           | 5500     |\n",
            "| policy_entropy     | 43.2     |\n",
            "| total_timesteps    | 27500    |\n",
            "| value_loss         | 10.4     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | -0.774   |\n",
            "| fps                | 310      |\n",
            "| nupdates           | 5600     |\n",
            "| policy_entropy     | 43.3     |\n",
            "| total_timesteps    | 28000    |\n",
            "| value_loss         | 1.3      |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0.139    |\n",
            "| fps                | 310      |\n",
            "| nupdates           | 5700     |\n",
            "| policy_entropy     | 43.2     |\n",
            "| total_timesteps    | 28500    |\n",
            "| value_loss         | 3.84     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | -0.298   |\n",
            "| fps                | 310      |\n",
            "| nupdates           | 5800     |\n",
            "| policy_entropy     | 43.3     |\n",
            "| total_timesteps    | 29000    |\n",
            "| value_loss         | 1.14     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | -0.244   |\n",
            "| fps                | 310      |\n",
            "| nupdates           | 5900     |\n",
            "| policy_entropy     | 43.3     |\n",
            "| total_timesteps    | 29500    |\n",
            "| value_loss         | 10       |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0.0183   |\n",
            "| fps                | 310      |\n",
            "| nupdates           | 6000     |\n",
            "| policy_entropy     | 43.3     |\n",
            "| total_timesteps    | 30000    |\n",
            "| value_loss         | 20.8     |\n",
            "---------------------------------\n",
            "Training time (A2C):  1.6227222045262655  minutes\n",
            "======A2C Validation from:  20200203 to  20200504\n",
            "A2C Sharpe Ratio:  -0.18920443110744847\n",
            "======PPO Training========\n",
            "Training time (PPO):  5.663937366008758  minutes\n",
            "======PPO Validation from:  20200203 to  20200504\n",
            "PPO Sharpe Ratio:  -0.20233067859738446\n",
            "======DDPG Training========\n",
            "Training time (DDPG):  1.0264471054077149  minutes\n",
            "======DDPG Validation from:  20200203 to  20200504\n",
            "======Trading from:  20200504 to  20200803\n",
            "previous_total_asset:1245039.3205187698\n",
            "end_total_asset:1280395.428469157\n",
            "total_reward:35356.10795038729\n",
            "total_cost:  2821.01098831766\n",
            "total trades:  361\n",
            "Sharpe:  0.17676325212118565\n",
            "============================================\n",
            "turbulence_threshold:  109.91299670003775\n",
            "======Model training from:  20100000 to  20200504\n",
            "======A2C Training========\n",
            "--------------------------------------\n",
            "| explained_variance      | 0        |\n",
            "| fps                     | 19       |\n",
            "| nupdates                | 1        |\n",
            "| policy_entropy          | 42.6     |\n",
            "| reference_Q_mean        | 3.28     |\n",
            "| reference_Q_std         | 2.45     |\n",
            "| reference_action_mean   | -0.0585  |\n",
            "| reference_action_std    | 0.984    |\n",
            "| reference_actor_Q_mean  | 3.96     |\n",
            "| reference_actor_Q_std   | 2.46     |\n",
            "| rollout/Q_mean          | 2.05     |\n",
            "| rollout/actions_mean    | 0.013    |\n",
            "| rollout/actions_std     | 0.811    |\n",
            "| rollout/episode_steps   | 2.54e+03 |\n",
            "| rollout/episodes        | 3        |\n",
            "| rollout/return          | 238      |\n",
            "| rollout/return_history  | 238      |\n",
            "| total/duration          | 60.8     |\n",
            "| total/episodes          | 3        |\n",
            "| total/epochs            | 1        |\n",
            "| total/steps             | 9998     |\n",
            "| total/steps_per_second  | 164      |\n",
            "| total_timesteps         | 5        |\n",
            "| train/loss_actor        | -3.89    |\n",
            "| train/loss_critic       | 1.56     |\n",
            "| train/param_noise_di... | 0        |\n",
            "| value_loss              | 0.00724  |\n",
            "--------------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | -0.0546  |\n",
            "| fps                | 248      |\n",
            "| nupdates           | 100      |\n",
            "| policy_entropy     | 42.6     |\n",
            "| total_timesteps    | 500      |\n",
            "| value_loss         | 5.73     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0.102    |\n",
            "| fps                | 264      |\n",
            "| nupdates           | 200      |\n",
            "| policy_entropy     | 42.6     |\n",
            "| total_timesteps    | 1000     |\n",
            "| value_loss         | 8.01     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | -0.0941  |\n",
            "| fps                | 270      |\n",
            "| nupdates           | 300      |\n",
            "| policy_entropy     | 42.6     |\n",
            "| total_timesteps    | 1500     |\n",
            "| value_loss         | 4.08     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0.798    |\n",
            "| fps                | 272      |\n",
            "| nupdates           | 400      |\n",
            "| policy_entropy     | 42.6     |\n",
            "| total_timesteps    | 2000     |\n",
            "| value_loss         | 2.93     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0.0609   |\n",
            "| fps                | 275      |\n",
            "| nupdates           | 500      |\n",
            "| policy_entropy     | 42.6     |\n",
            "| total_timesteps    | 2500     |\n",
            "| value_loss         | 6.08     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0.0212   |\n",
            "| fps                | 273      |\n",
            "| nupdates           | 600      |\n",
            "| policy_entropy     | 42.6     |\n",
            "| total_timesteps    | 3000     |\n",
            "| value_loss         | 38.1     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0        |\n",
            "| fps                | 275      |\n",
            "| nupdates           | 700      |\n",
            "| policy_entropy     | 42.6     |\n",
            "| total_timesteps    | 3500     |\n",
            "| value_loss         | 1.31     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | -0.281   |\n",
            "| fps                | 276      |\n",
            "| nupdates           | 800      |\n",
            "| policy_entropy     | 42.6     |\n",
            "| total_timesteps    | 4000     |\n",
            "| value_loss         | 7.18     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0        |\n",
            "| fps                | 278      |\n",
            "| nupdates           | 900      |\n",
            "| policy_entropy     | 42.6     |\n",
            "| total_timesteps    | 4500     |\n",
            "| value_loss         | 0.234    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0.0811   |\n",
            "| fps                | 280      |\n",
            "| nupdates           | 1000     |\n",
            "| policy_entropy     | 42.6     |\n",
            "| total_timesteps    | 5000     |\n",
            "| value_loss         | 2.02     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | -0.33    |\n",
            "| fps                | 278      |\n",
            "| nupdates           | 1100     |\n",
            "| policy_entropy     | 42.6     |\n",
            "| total_timesteps    | 5500     |\n",
            "| value_loss         | 1.56     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | -0.0031  |\n",
            "| fps                | 279      |\n",
            "| nupdates           | 1200     |\n",
            "| policy_entropy     | 42.6     |\n",
            "| total_timesteps    | 6000     |\n",
            "| value_loss         | 3.12     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0        |\n",
            "| fps                | 281      |\n",
            "| nupdates           | 1300     |\n",
            "| policy_entropy     | 42.7     |\n",
            "| total_timesteps    | 6500     |\n",
            "| value_loss         | 1.03     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0.0167   |\n",
            "| fps                | 282      |\n",
            "| nupdates           | 1400     |\n",
            "| policy_entropy     | 42.7     |\n",
            "| total_timesteps    | 7000     |\n",
            "| value_loss         | 0.513    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0.00852  |\n",
            "| fps                | 283      |\n",
            "| nupdates           | 1500     |\n",
            "| policy_entropy     | 42.7     |\n",
            "| total_timesteps    | 7500     |\n",
            "| value_loss         | 8.38     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | -0.253   |\n",
            "| fps                | 283      |\n",
            "| nupdates           | 1600     |\n",
            "| policy_entropy     | 42.8     |\n",
            "| total_timesteps    | 8000     |\n",
            "| value_loss         | 0.53     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 1.19e-07 |\n",
            "| fps                | 283      |\n",
            "| nupdates           | 1700     |\n",
            "| policy_entropy     | 42.9     |\n",
            "| total_timesteps    | 8500     |\n",
            "| value_loss         | 6.18     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | -0.148   |\n",
            "| fps                | 284      |\n",
            "| nupdates           | 1800     |\n",
            "| policy_entropy     | 42.9     |\n",
            "| total_timesteps    | 9000     |\n",
            "| value_loss         | 18.3     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0.0478   |\n",
            "| fps                | 285      |\n",
            "| nupdates           | 1900     |\n",
            "| policy_entropy     | 42.9     |\n",
            "| total_timesteps    | 9500     |\n",
            "| value_loss         | 9.06     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0.079    |\n",
            "| fps                | 286      |\n",
            "| nupdates           | 2000     |\n",
            "| policy_entropy     | 42.9     |\n",
            "| total_timesteps    | 10000    |\n",
            "| value_loss         | 5.35     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0        |\n",
            "| fps                | 285      |\n",
            "| nupdates           | 2100     |\n",
            "| policy_entropy     | 42.9     |\n",
            "| total_timesteps    | 10500    |\n",
            "| value_loss         | 0.944    |\n",
            "---------------------------------\n",
            "----------------------------------\n",
            "| explained_variance | -0.000408 |\n",
            "| fps                | 285       |\n",
            "| nupdates           | 2200      |\n",
            "| policy_entropy     | 42.8      |\n",
            "| total_timesteps    | 11000     |\n",
            "| value_loss         | 5.72      |\n",
            "----------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0.17     |\n",
            "| fps                | 286      |\n",
            "| nupdates           | 2300     |\n",
            "| policy_entropy     | 42.9     |\n",
            "| total_timesteps    | 11500    |\n",
            "| value_loss         | 3.35     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0.0343   |\n",
            "| fps                | 286      |\n",
            "| nupdates           | 2400     |\n",
            "| policy_entropy     | 42.9     |\n",
            "| total_timesteps    | 12000    |\n",
            "| value_loss         | 5.03     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0        |\n",
            "| fps                | 287      |\n",
            "| nupdates           | 2500     |\n",
            "| policy_entropy     | 42.9     |\n",
            "| total_timesteps    | 12500    |\n",
            "| value_loss         | 70.1     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0        |\n",
            "| fps                | 287      |\n",
            "| nupdates           | 2600     |\n",
            "| policy_entropy     | 43       |\n",
            "| total_timesteps    | 13000    |\n",
            "| value_loss         | 756      |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0.437    |\n",
            "| fps                | 287      |\n",
            "| nupdates           | 2700     |\n",
            "| policy_entropy     | 43       |\n",
            "| total_timesteps    | 13500    |\n",
            "| value_loss         | 2.91     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0.523    |\n",
            "| fps                | 286      |\n",
            "| nupdates           | 2800     |\n",
            "| policy_entropy     | 43       |\n",
            "| total_timesteps    | 14000    |\n",
            "| value_loss         | 19.9     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | -0.126   |\n",
            "| fps                | 286      |\n",
            "| nupdates           | 2900     |\n",
            "| policy_entropy     | 43       |\n",
            "| total_timesteps    | 14500    |\n",
            "| value_loss         | 6.38     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | -0.127   |\n",
            "| fps                | 286      |\n",
            "| nupdates           | 3000     |\n",
            "| policy_entropy     | 43       |\n",
            "| total_timesteps    | 15000    |\n",
            "| value_loss         | 12.2     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0.0999   |\n",
            "| fps                | 286      |\n",
            "| nupdates           | 3100     |\n",
            "| policy_entropy     | 42.9     |\n",
            "| total_timesteps    | 15500    |\n",
            "| value_loss         | 21.3     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0.11     |\n",
            "| fps                | 285      |\n",
            "| nupdates           | 3200     |\n",
            "| policy_entropy     | 43       |\n",
            "| total_timesteps    | 16000    |\n",
            "| value_loss         | 52.1     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | -0.0159  |\n",
            "| fps                | 285      |\n",
            "| nupdates           | 3300     |\n",
            "| policy_entropy     | 43       |\n",
            "| total_timesteps    | 16500    |\n",
            "| value_loss         | 2.06     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0.00839  |\n",
            "| fps                | 285      |\n",
            "| nupdates           | 3400     |\n",
            "| policy_entropy     | 43       |\n",
            "| total_timesteps    | 17000    |\n",
            "| value_loss         | 1.9      |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0.231    |\n",
            "| fps                | 285      |\n",
            "| nupdates           | 3500     |\n",
            "| policy_entropy     | 43       |\n",
            "| total_timesteps    | 17500    |\n",
            "| value_loss         | 4.77     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0        |\n",
            "| fps                | 286      |\n",
            "| nupdates           | 3600     |\n",
            "| policy_entropy     | 43       |\n",
            "| total_timesteps    | 18000    |\n",
            "| value_loss         | 2.19     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | -0.209   |\n",
            "| fps                | 285      |\n",
            "| nupdates           | 3700     |\n",
            "| policy_entropy     | 43       |\n",
            "| total_timesteps    | 18500    |\n",
            "| value_loss         | 3.21     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0.132    |\n",
            "| fps                | 286      |\n",
            "| nupdates           | 3800     |\n",
            "| policy_entropy     | 43.1     |\n",
            "| total_timesteps    | 19000    |\n",
            "| value_loss         | 5.49     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0        |\n",
            "| fps                | 286      |\n",
            "| nupdates           | 3900     |\n",
            "| policy_entropy     | 43.1     |\n",
            "| total_timesteps    | 19500    |\n",
            "| value_loss         | 3.72     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | -0.0841  |\n",
            "| fps                | 286      |\n",
            "| nupdates           | 4000     |\n",
            "| policy_entropy     | 43       |\n",
            "| total_timesteps    | 20000    |\n",
            "| value_loss         | 0.297    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | -0.142   |\n",
            "| fps                | 287      |\n",
            "| nupdates           | 4100     |\n",
            "| policy_entropy     | 43.1     |\n",
            "| total_timesteps    | 20500    |\n",
            "| value_loss         | 2.86     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0.0394   |\n",
            "| fps                | 287      |\n",
            "| nupdates           | 4200     |\n",
            "| policy_entropy     | 43.2     |\n",
            "| total_timesteps    | 21000    |\n",
            "| value_loss         | 1.23     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | -0.283   |\n",
            "| fps                | 287      |\n",
            "| nupdates           | 4300     |\n",
            "| policy_entropy     | 43.2     |\n",
            "| total_timesteps    | 21500    |\n",
            "| value_loss         | 4.62     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | -0.979   |\n",
            "| fps                | 287      |\n",
            "| nupdates           | 4400     |\n",
            "| policy_entropy     | 43.1     |\n",
            "| total_timesteps    | 22000    |\n",
            "| value_loss         | 33       |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 1.19e-07 |\n",
            "| fps                | 287      |\n",
            "| nupdates           | 4500     |\n",
            "| policy_entropy     | 43.2     |\n",
            "| total_timesteps    | 22500    |\n",
            "| value_loss         | 3.49     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | -0.00298 |\n",
            "| fps                | 288      |\n",
            "| nupdates           | 4600     |\n",
            "| policy_entropy     | 43.2     |\n",
            "| total_timesteps    | 23000    |\n",
            "| value_loss         | 70.3     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | -0.0509  |\n",
            "| fps                | 287      |\n",
            "| nupdates           | 4700     |\n",
            "| policy_entropy     | 43.2     |\n",
            "| total_timesteps    | 23500    |\n",
            "| value_loss         | 2.46     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0        |\n",
            "| fps                | 287      |\n",
            "| nupdates           | 4800     |\n",
            "| policy_entropy     | 43.2     |\n",
            "| total_timesteps    | 24000    |\n",
            "| value_loss         | 1.51     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0.0971   |\n",
            "| fps                | 287      |\n",
            "| nupdates           | 4900     |\n",
            "| policy_entropy     | 43.1     |\n",
            "| total_timesteps    | 24500    |\n",
            "| value_loss         | 7.32     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | -0.0141  |\n",
            "| fps                | 288      |\n",
            "| nupdates           | 5000     |\n",
            "| policy_entropy     | 43.2     |\n",
            "| total_timesteps    | 25000    |\n",
            "| value_loss         | 2.67     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | -0.0962  |\n",
            "| fps                | 288      |\n",
            "| nupdates           | 5100     |\n",
            "| policy_entropy     | 43.2     |\n",
            "| total_timesteps    | 25500    |\n",
            "| value_loss         | 23.4     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | -0.0127  |\n",
            "| fps                | 287      |\n",
            "| nupdates           | 5200     |\n",
            "| policy_entropy     | 43.1     |\n",
            "| total_timesteps    | 26000    |\n",
            "| value_loss         | 377      |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 1.19e-07 |\n",
            "| fps                | 287      |\n",
            "| nupdates           | 5300     |\n",
            "| policy_entropy     | 43.1     |\n",
            "| total_timesteps    | 26500    |\n",
            "| value_loss         | 5.92     |\n",
            "---------------------------------\n",
            "----------------------------------\n",
            "| explained_variance | -6.68e-06 |\n",
            "| fps                | 287       |\n",
            "| nupdates           | 5400      |\n",
            "| policy_entropy     | 43.2      |\n",
            "| total_timesteps    | 27000     |\n",
            "| value_loss         | 5.13      |\n",
            "----------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0.174    |\n",
            "| fps                | 288      |\n",
            "| nupdates           | 5500     |\n",
            "| policy_entropy     | 43.3     |\n",
            "| total_timesteps    | 27500    |\n",
            "| value_loss         | 6.11     |\n",
            "---------------------------------\n",
            "----------------------------------\n",
            "| explained_variance | -1.19e-07 |\n",
            "| fps                | 288       |\n",
            "| nupdates           | 5600      |\n",
            "| policy_entropy     | 43.3      |\n",
            "| total_timesteps    | 28000     |\n",
            "| value_loss         | 4.08      |\n",
            "----------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0        |\n",
            "| fps                | 288      |\n",
            "| nupdates           | 5700     |\n",
            "| policy_entropy     | 43.3     |\n",
            "| total_timesteps    | 28500    |\n",
            "| value_loss         | 4.54     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | -1.37    |\n",
            "| fps                | 288      |\n",
            "| nupdates           | 5800     |\n",
            "| policy_entropy     | 43.4     |\n",
            "| total_timesteps    | 29000    |\n",
            "| value_loss         | 45.6     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | -0.0935  |\n",
            "| fps                | 288      |\n",
            "| nupdates           | 5900     |\n",
            "| policy_entropy     | 43.5     |\n",
            "| total_timesteps    | 29500    |\n",
            "| value_loss         | 0.792    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0.0304   |\n",
            "| fps                | 288      |\n",
            "| nupdates           | 6000     |\n",
            "| policy_entropy     | 43.5     |\n",
            "| total_timesteps    | 30000    |\n",
            "| value_loss         | 6.92     |\n",
            "---------------------------------\n",
            "Training time (A2C):  1.741890557607015  minutes\n",
            "======A2C Validation from:  20200504 to  20200803\n",
            "A2C Sharpe Ratio:  0.2658180095229119\n",
            "======PPO Training========\n",
            "Training time (PPO):  5.765429997444153  minutes\n",
            "======PPO Validation from:  20200504 to  20200803\n",
            "PPO Sharpe Ratio:  0.3028200102906386\n",
            "======DDPG Training========\n",
            "Training time (DDPG):  1.019353453318278  minutes\n",
            "======DDPG Validation from:  20200504 to  20200803\n",
            "======Trading from:  20200803 to  20201030\n",
            "previous_total_asset:1280395.428469157\n",
            "end_total_asset:1242096.4038162164\n",
            "total_reward:-38299.02465294069\n",
            "total_cost:  2530.119610393311\n",
            "total trades:  281\n",
            "Sharpe:  -0.46386546709324084\n",
            "============================================\n",
            "turbulence_threshold:  109.91299670003775\n",
            "======Model training from:  20100000 to  20200803\n",
            "======A2C Training========\n",
            "--------------------------------------\n",
            "| explained_variance      | 0        |\n",
            "| fps                     | 18       |\n",
            "| nupdates                | 1        |\n",
            "| policy_entropy          | 42.6     |\n",
            "| reference_Q_mean        | 2.74     |\n",
            "| reference_Q_std         | 2.2      |\n",
            "| reference_action_mean   | -0.191   |\n",
            "| reference_action_std    | 0.953    |\n",
            "| reference_actor_Q_mean  | 3.53     |\n",
            "| reference_actor_Q_std   | 2.26     |\n",
            "| rollout/Q_mean          | 1.52     |\n",
            "| rollout/actions_mean    | -0.161   |\n",
            "| rollout/actions_std     | 0.803    |\n",
            "| rollout/episode_steps   | 2.6e+03  |\n",
            "| rollout/episodes        | 3        |\n",
            "| rollout/return          | 262      |\n",
            "| rollout/return_history  | 262      |\n",
            "| total/duration          | 60.4     |\n",
            "| total/episodes          | 3        |\n",
            "| total/epochs            | 1        |\n",
            "| total/steps             | 9998     |\n",
            "| total/steps_per_second  | 166      |\n",
            "| total_timesteps         | 5        |\n",
            "| train/loss_actor        | -3.48    |\n",
            "| train/loss_critic       | 5.31     |\n",
            "| train/param_noise_di... | 0        |\n",
            "| value_loss              | 0.00245  |\n",
            "--------------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0.115    |\n",
            "| fps                | 243      |\n",
            "| nupdates           | 100      |\n",
            "| policy_entropy     | 42.6     |\n",
            "| total_timesteps    | 500      |\n",
            "| value_loss         | 5.95     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 1.19e-07 |\n",
            "| fps                | 260      |\n",
            "| nupdates           | 200      |\n",
            "| policy_entropy     | 42.6     |\n",
            "| total_timesteps    | 1000     |\n",
            "| value_loss         | 11.1     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | -0.0921  |\n",
            "| fps                | 264      |\n",
            "| nupdates           | 300      |\n",
            "| policy_entropy     | 42.6     |\n",
            "| total_timesteps    | 1500     |\n",
            "| value_loss         | 4.15     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0        |\n",
            "| fps                | 267      |\n",
            "| nupdates           | 400      |\n",
            "| policy_entropy     | 42.6     |\n",
            "| total_timesteps    | 2000     |\n",
            "| value_loss         | 24.2     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | -0.377   |\n",
            "| fps                | 268      |\n",
            "| nupdates           | 500      |\n",
            "| policy_entropy     | 42.6     |\n",
            "| total_timesteps    | 2500     |\n",
            "| value_loss         | 4.74     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | -2.07    |\n",
            "| fps                | 266      |\n",
            "| nupdates           | 600      |\n",
            "| policy_entropy     | 42.6     |\n",
            "| total_timesteps    | 3000     |\n",
            "| value_loss         | 1.19     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0.0543   |\n",
            "| fps                | 268      |\n",
            "| nupdates           | 700      |\n",
            "| policy_entropy     | 42.6     |\n",
            "| total_timesteps    | 3500     |\n",
            "| value_loss         | 0.698    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | -0.384   |\n",
            "| fps                | 270      |\n",
            "| nupdates           | 800      |\n",
            "| policy_entropy     | 42.6     |\n",
            "| total_timesteps    | 4000     |\n",
            "| value_loss         | 4.52     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | -0.83    |\n",
            "| fps                | 270      |\n",
            "| nupdates           | 900      |\n",
            "| policy_entropy     | 42.6     |\n",
            "| total_timesteps    | 4500     |\n",
            "| value_loss         | 4.17     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | -0.105   |\n",
            "| fps                | 272      |\n",
            "| nupdates           | 1000     |\n",
            "| policy_entropy     | 42.6     |\n",
            "| total_timesteps    | 5000     |\n",
            "| value_loss         | 46       |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | -0.881   |\n",
            "| fps                | 271      |\n",
            "| nupdates           | 1100     |\n",
            "| policy_entropy     | 42.7     |\n",
            "| total_timesteps    | 5500     |\n",
            "| value_loss         | 1.89     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | -0.377   |\n",
            "| fps                | 273      |\n",
            "| nupdates           | 1200     |\n",
            "| policy_entropy     | 42.7     |\n",
            "| total_timesteps    | 6000     |\n",
            "| value_loss         | 1.93     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | -0.185   |\n",
            "| fps                | 273      |\n",
            "| nupdates           | 1300     |\n",
            "| policy_entropy     | 42.7     |\n",
            "| total_timesteps    | 6500     |\n",
            "| value_loss         | 0.628    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | -0.423   |\n",
            "| fps                | 274      |\n",
            "| nupdates           | 1400     |\n",
            "| policy_entropy     | 42.7     |\n",
            "| total_timesteps    | 7000     |\n",
            "| value_loss         | 14.6     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0.0638   |\n",
            "| fps                | 275      |\n",
            "| nupdates           | 1500     |\n",
            "| policy_entropy     | 42.7     |\n",
            "| total_timesteps    | 7500     |\n",
            "| value_loss         | 17.9     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0        |\n",
            "| fps                | 274      |\n",
            "| nupdates           | 1600     |\n",
            "| policy_entropy     | 42.7     |\n",
            "| total_timesteps    | 8000     |\n",
            "| value_loss         | 0.0176   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0        |\n",
            "| fps                | 275      |\n",
            "| nupdates           | 1700     |\n",
            "| policy_entropy     | 42.7     |\n",
            "| total_timesteps    | 8500     |\n",
            "| value_loss         | 6.62     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | -0.034   |\n",
            "| fps                | 276      |\n",
            "| nupdates           | 1800     |\n",
            "| policy_entropy     | 42.7     |\n",
            "| total_timesteps    | 9000     |\n",
            "| value_loss         | 1.84     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0.00589  |\n",
            "| fps                | 277      |\n",
            "| nupdates           | 1900     |\n",
            "| policy_entropy     | 42.7     |\n",
            "| total_timesteps    | 9500     |\n",
            "| value_loss         | 40.3     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0.00332  |\n",
            "| fps                | 278      |\n",
            "| nupdates           | 2000     |\n",
            "| policy_entropy     | 42.8     |\n",
            "| total_timesteps    | 10000    |\n",
            "| value_loss         | 2.55     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 5.96e-08 |\n",
            "| fps                | 279      |\n",
            "| nupdates           | 2100     |\n",
            "| policy_entropy     | 42.8     |\n",
            "| total_timesteps    | 10500    |\n",
            "| value_loss         | 7.3      |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0.16     |\n",
            "| fps                | 279      |\n",
            "| nupdates           | 2200     |\n",
            "| policy_entropy     | 42.8     |\n",
            "| total_timesteps    | 11000    |\n",
            "| value_loss         | 1.6      |\n",
            "---------------------------------\n",
            "----------------------------------\n",
            "| explained_variance | -1.19e-07 |\n",
            "| fps                | 280       |\n",
            "| nupdates           | 2300      |\n",
            "| policy_entropy     | 42.8      |\n",
            "| total_timesteps    | 11500     |\n",
            "| value_loss         | 1.02      |\n",
            "----------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | -0.755   |\n",
            "| fps                | 281      |\n",
            "| nupdates           | 2400     |\n",
            "| policy_entropy     | 42.8     |\n",
            "| total_timesteps    | 12000    |\n",
            "| value_loss         | 3.52     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | -0.673   |\n",
            "| fps                | 281      |\n",
            "| nupdates           | 2500     |\n",
            "| policy_entropy     | 42.8     |\n",
            "| total_timesteps    | 12500    |\n",
            "| value_loss         | 0.953    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | -0.0325  |\n",
            "| fps                | 281      |\n",
            "| nupdates           | 2600     |\n",
            "| policy_entropy     | 42.7     |\n",
            "| total_timesteps    | 13000    |\n",
            "| value_loss         | 3.97     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | -0.185   |\n",
            "| fps                | 281      |\n",
            "| nupdates           | 2700     |\n",
            "| policy_entropy     | 42.7     |\n",
            "| total_timesteps    | 13500    |\n",
            "| value_loss         | 0.869    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | -0.368   |\n",
            "| fps                | 281      |\n",
            "| nupdates           | 2800     |\n",
            "| policy_entropy     | 42.7     |\n",
            "| total_timesteps    | 14000    |\n",
            "| value_loss         | 0.0748   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | -2.62    |\n",
            "| fps                | 282      |\n",
            "| nupdates           | 2900     |\n",
            "| policy_entropy     | 42.7     |\n",
            "| total_timesteps    | 14500    |\n",
            "| value_loss         | 1.16     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 1.19e-07 |\n",
            "| fps                | 282      |\n",
            "| nupdates           | 3000     |\n",
            "| policy_entropy     | 42.7     |\n",
            "| total_timesteps    | 15000    |\n",
            "| value_loss         | 16.8     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0        |\n",
            "| fps                | 282      |\n",
            "| nupdates           | 3100     |\n",
            "| policy_entropy     | 42.7     |\n",
            "| total_timesteps    | 15500    |\n",
            "| value_loss         | 4.68     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0        |\n",
            "| fps                | 282      |\n",
            "| nupdates           | 3200     |\n",
            "| policy_entropy     | 42.7     |\n",
            "| total_timesteps    | 16000    |\n",
            "| value_loss         | 0.791    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | -0.0109  |\n",
            "| fps                | 282      |\n",
            "| nupdates           | 3300     |\n",
            "| policy_entropy     | 42.8     |\n",
            "| total_timesteps    | 16500    |\n",
            "| value_loss         | 0.956    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0        |\n",
            "| fps                | 282      |\n",
            "| nupdates           | 3400     |\n",
            "| policy_entropy     | 42.9     |\n",
            "| total_timesteps    | 17000    |\n",
            "| value_loss         | 21.4     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | -0.0023  |\n",
            "| fps                | 283      |\n",
            "| nupdates           | 3500     |\n",
            "| policy_entropy     | 42.9     |\n",
            "| total_timesteps    | 17500    |\n",
            "| value_loss         | 2.14     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0        |\n",
            "| fps                | 283      |\n",
            "| nupdates           | 3600     |\n",
            "| policy_entropy     | 42.9     |\n",
            "| total_timesteps    | 18000    |\n",
            "| value_loss         | 1.15     |\n",
            "---------------------------------\n",
            "----------------------------------\n",
            "| explained_variance | -1.61e-05 |\n",
            "| fps                | 284       |\n",
            "| nupdates           | 3700      |\n",
            "| policy_entropy     | 42.9      |\n",
            "| total_timesteps    | 18500     |\n",
            "| value_loss         | 18.7      |\n",
            "----------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | -0.00257 |\n",
            "| fps                | 284      |\n",
            "| nupdates           | 3800     |\n",
            "| policy_entropy     | 42.9     |\n",
            "| total_timesteps    | 19000    |\n",
            "| value_loss         | 3.85     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0        |\n",
            "| fps                | 284      |\n",
            "| nupdates           | 3900     |\n",
            "| policy_entropy     | 43       |\n",
            "| total_timesteps    | 19500    |\n",
            "| value_loss         | 6.94     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0.174    |\n",
            "| fps                | 285      |\n",
            "| nupdates           | 4000     |\n",
            "| policy_entropy     | 43       |\n",
            "| total_timesteps    | 20000    |\n",
            "| value_loss         | 0.36     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | -0.131   |\n",
            "| fps                | 286      |\n",
            "| nupdates           | 4100     |\n",
            "| policy_entropy     | 43.1     |\n",
            "| total_timesteps    | 20500    |\n",
            "| value_loss         | 0.966    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0        |\n",
            "| fps                | 286      |\n",
            "| nupdates           | 4200     |\n",
            "| policy_entropy     | 43.1     |\n",
            "| total_timesteps    | 21000    |\n",
            "| value_loss         | 5.1      |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0.316    |\n",
            "| fps                | 286      |\n",
            "| nupdates           | 4300     |\n",
            "| policy_entropy     | 43.1     |\n",
            "| total_timesteps    | 21500    |\n",
            "| value_loss         | 0.59     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0        |\n",
            "| fps                | 286      |\n",
            "| nupdates           | 4400     |\n",
            "| policy_entropy     | 43.1     |\n",
            "| total_timesteps    | 22000    |\n",
            "| value_loss         | 2.39     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0        |\n",
            "| fps                | 287      |\n",
            "| nupdates           | 4500     |\n",
            "| policy_entropy     | 43.1     |\n",
            "| total_timesteps    | 22500    |\n",
            "| value_loss         | 0.739    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 1.19e-07 |\n",
            "| fps                | 287      |\n",
            "| nupdates           | 4600     |\n",
            "| policy_entropy     | 43.2     |\n",
            "| total_timesteps    | 23000    |\n",
            "| value_loss         | 5.36     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0        |\n",
            "| fps                | 287      |\n",
            "| nupdates           | 4700     |\n",
            "| policy_entropy     | 43.2     |\n",
            "| total_timesteps    | 23500    |\n",
            "| value_loss         | 22.9     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0        |\n",
            "| fps                | 286      |\n",
            "| nupdates           | 4800     |\n",
            "| policy_entropy     | 43.2     |\n",
            "| total_timesteps    | 24000    |\n",
            "| value_loss         | 0.146    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 5.96e-08 |\n",
            "| fps                | 286      |\n",
            "| nupdates           | 4900     |\n",
            "| policy_entropy     | 43.2     |\n",
            "| total_timesteps    | 24500    |\n",
            "| value_loss         | 0.812    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0.139    |\n",
            "| fps                | 287      |\n",
            "| nupdates           | 5000     |\n",
            "| policy_entropy     | 43.3     |\n",
            "| total_timesteps    | 25000    |\n",
            "| value_loss         | 6.76     |\n",
            "---------------------------------\n",
            "----------------------------------\n",
            "| explained_variance | -1.19e-07 |\n",
            "| fps                | 287       |\n",
            "| nupdates           | 5100      |\n",
            "| policy_entropy     | 43.2      |\n",
            "| total_timesteps    | 25500     |\n",
            "| value_loss         | 75.2      |\n",
            "----------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0.0845   |\n",
            "| fps                | 287      |\n",
            "| nupdates           | 5200     |\n",
            "| policy_entropy     | 43.2     |\n",
            "| total_timesteps    | 26000    |\n",
            "| value_loss         | 10.1     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | -0.267   |\n",
            "| fps                | 287      |\n",
            "| nupdates           | 5300     |\n",
            "| policy_entropy     | 43.1     |\n",
            "| total_timesteps    | 26500    |\n",
            "| value_loss         | 42.4     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0.0179   |\n",
            "| fps                | 287      |\n",
            "| nupdates           | 5400     |\n",
            "| policy_entropy     | 43.1     |\n",
            "| total_timesteps    | 27000    |\n",
            "| value_loss         | 0.512    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0        |\n",
            "| fps                | 287      |\n",
            "| nupdates           | 5500     |\n",
            "| policy_entropy     | 43.1     |\n",
            "| total_timesteps    | 27500    |\n",
            "| value_loss         | 0.844    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | -0.0616  |\n",
            "| fps                | 287      |\n",
            "| nupdates           | 5600     |\n",
            "| policy_entropy     | 43       |\n",
            "| total_timesteps    | 28000    |\n",
            "| value_loss         | 2.39     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | -0.00762 |\n",
            "| fps                | 287      |\n",
            "| nupdates           | 5700     |\n",
            "| policy_entropy     | 43.1     |\n",
            "| total_timesteps    | 28500    |\n",
            "| value_loss         | 2.46     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0.0482   |\n",
            "| fps                | 287      |\n",
            "| nupdates           | 5800     |\n",
            "| policy_entropy     | 43.1     |\n",
            "| total_timesteps    | 29000    |\n",
            "| value_loss         | 18       |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | -1.75    |\n",
            "| fps                | 287      |\n",
            "| nupdates           | 5900     |\n",
            "| policy_entropy     | 43.1     |\n",
            "| total_timesteps    | 29500    |\n",
            "| value_loss         | 0.102    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| explained_variance | 0.000166 |\n",
            "| fps                | 287      |\n",
            "| nupdates           | 6000     |\n",
            "| policy_entropy     | 43.2     |\n",
            "| total_timesteps    | 30000    |\n",
            "| value_loss         | 0.706    |\n",
            "---------------------------------\n",
            "Training time (A2C):  1.7511675914128622  minutes\n",
            "======A2C Validation from:  20200803 to  20201030\n",
            "A2C Sharpe Ratio:  -0.38112068680325917\n",
            "======PPO Training========\n",
            "Training time (PPO):  5.721296966075897  minutes\n",
            "======PPO Validation from:  20200803 to  20201030\n",
            "PPO Sharpe Ratio:  -0.46194593182373017\n",
            "======DDPG Training========\n",
            "Training time (DDPG):  1.035412605603536  minutes\n",
            "======DDPG Validation from:  20200803 to  20201030\n",
            "======Trading from:  20201030 to  20210202\n",
            "previous_total_asset:1242096.4038162164\n",
            "end_total_asset:1247453.564464803\n",
            "total_reward:5357.160648586694\n",
            "total_cost:  2033.68610729702\n",
            "total trades:  353\n",
            "Sharpe:  0.21422165073320945\n",
            "Ensemble Strategy took:  152.48083308935165  minutes\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}